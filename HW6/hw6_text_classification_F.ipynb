{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HOMEWORK 5: TEXT CLASSIFICATION\n",
    "In this homework, you will create models to classify texts from TRUE call-center. There are two classification tasks:\n",
    "1. Action Classification: Identify which action the customer would like to take (e.g. enquire, report, cancle)\n",
    "2. Object Classification: Identify which object the customer is referring to (e.g. payment, truemoney, internet, roaming) \n",
    "\n",
    "In this homework, you are asked to do the following tasks:\n",
    "1. Data Cleaning\n",
    "2. Preprocessing data for keras\n",
    "3. Build and evaluate a model for \"action\" classification\n",
    "4. Build and evaluate a model for \"object\" classification\n",
    "5. Build and evaluate a multi-task model that does both \"action\" and \"object\" classifications in one-go \n",
    "\n",
    "\n",
    "Note: we have removed phone numbers from the dataset for privacy purposes. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Libs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "import sklearn\n",
    "import numpy as np\n",
    "from IPython.display import display\n",
    "\n",
    "import math\n",
    "import glob\n",
    "import re\n",
    "import random\n",
    "import collections\n",
    "import os\n",
    "import sys\n",
    "\n",
    "from keras.preprocessing import sequence\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import GRU, Dropout\n",
    "from keras.models import load_model\n",
    "from keras.layers import Embedding, Reshape, Activation, Input, Dense, Masking\n",
    "from keras.layers.merge import Dot\n",
    "from keras.utils import np_utils\n",
    "from keras.utils.data_utils import get_file\n",
    "from keras.utils.np_utils import to_categorical\n",
    "from keras.preprocessing.sequence import skipgrams\n",
    "from keras.preprocessing import sequence\n",
    "from keras import backend as K\n",
    "from keras.optimizers import Adam\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "random.seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading data\n",
    "First, we load the data from disk into a Dataframe.\n",
    "\n",
    "A Dataframe is essentially a table, or 2D-array/Matrix with a name for each column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_df = pd.read_csv('clean-phone-data-for-students.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's preview the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sentence Utterance</th>\n",
       "      <th>Action</th>\n",
       "      <th>Object</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>&lt;PHONE_NUMBER_REMOVED&gt; ผมไปจ่ายเงินที่ Counte...</td>\n",
       "      <td>enquire</td>\n",
       "      <td>payment</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>internet ยังความเร็วอยุ่เท่าไหร ครับ</td>\n",
       "      <td>enquire</td>\n",
       "      <td>package</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ตะกี้ไปชำระค่าบริการไปแล้ว แต่ยังใช้งานไม่ได้...</td>\n",
       "      <td>report</td>\n",
       "      <td>suspend</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>พี่ค่ะยังใช้ internet ไม่ได้เลยค่ะ เป็นเครื่อ...</td>\n",
       "      <td>enquire</td>\n",
       "      <td>internet</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ฮาโหล คะ พอดีว่าเมื่อวานเปิดซิมทรูมูฟ แต่มันโ...</td>\n",
       "      <td>report</td>\n",
       "      <td>phone_issues</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                  Sentence Utterance   Action        Object\n",
       "0   <PHONE_NUMBER_REMOVED> ผมไปจ่ายเงินที่ Counte...  enquire       payment\n",
       "1               internet ยังความเร็วอยุ่เท่าไหร ครับ  enquire       package\n",
       "2   ตะกี้ไปชำระค่าบริการไปแล้ว แต่ยังใช้งานไม่ได้...   report       suspend\n",
       "3   พี่ค่ะยังใช้ internet ไม่ได้เลยค่ะ เป็นเครื่อ...  enquire      internet\n",
       "4   ฮาโหล คะ พอดีว่าเมื่อวานเปิดซิมทรูมูฟ แต่มันโ...   report  phone_issues"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sentence Utterance</th>\n",
       "      <th>Action</th>\n",
       "      <th>Object</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>16175</td>\n",
       "      <td>16175</td>\n",
       "      <td>16175</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>13389</td>\n",
       "      <td>10</td>\n",
       "      <td>33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>บริการอื่นๆ</td>\n",
       "      <td>enquire</td>\n",
       "      <td>service</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>97</td>\n",
       "      <td>10377</td>\n",
       "      <td>2525</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Sentence Utterance   Action   Object\n",
       "count               16175    16175    16175\n",
       "unique              13389       10       33\n",
       "top           บริการอื่นๆ  enquire  service\n",
       "freq                   97    10377     2525"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Show the top 5 rows\n",
    "display(data_df.head())\n",
    "# Summarize the data\n",
    "data_df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data cleaning\n",
    "\n",
    "We call the DataFrame.describe() again.\n",
    "Notice that there are 33 unique labels/classes for object and 10 unique labels for action that the model will try to predict.\n",
    "But there are unwanted duplications e.g. Idd,idd,lotalty_card,Lotalty_card\n",
    "\n",
    "Also note that, there are 13389 unqiue sentence utterances from 16175 utterances. You have to clean that too!\n",
    "\n",
    "## #TODO 1: \n",
    "You will have to remove unwanted label duplications as well as duplications in text inputs. \n",
    "Also, you will have to trim out unwanted whitespaces from the text inputs. \n",
    "This shouldn't be too hard, as you have already seen it in the demo.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['payment', 'package', 'suspend', 'internet', 'phone_issues',\n",
       "       'service', 'nontruemove', 'balance', 'detail', 'bill', 'credit',\n",
       "       'promotion', 'mobile_setting', 'iservice', 'roaming', 'truemoney',\n",
       "       'information', 'lost_stolen', 'balance_minutes', 'idd', 'garbage',\n",
       "       'ringtone', 'rate', 'loyalty_card', 'contact', 'officer'],\n",
       "      dtype=object)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "array(['enquire', 'report', 'cancel', 'buy', 'activate', 'request',\n",
       "       'garbage', 'change'], dtype=object)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#TODO1\n",
    "data_df['clean_label_obj']=data_df['Object'].str.lower().copy()\n",
    "data_df['clean_label_act']=data_df['Action'].str.lower().copy()\n",
    "data_df.drop('Action', axis=1, inplace=True)\n",
    "data_df.drop('Object', axis=1, inplace=True)\n",
    "display(data_df.clean_label_obj.unique())\n",
    "display(data_df.clean_label_act.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sentence Utterance</th>\n",
       "      <th>clean_label_obj</th>\n",
       "      <th>clean_label_act</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>13389</td>\n",
       "      <td>13389</td>\n",
       "      <td>13389</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>13389</td>\n",
       "      <td>26</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>ประวัติการใช้งานค่ะ</td>\n",
       "      <td>service</td>\n",
       "      <td>enquire</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>1</td>\n",
       "      <td>2111</td>\n",
       "      <td>8658</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Sentence Utterance clean_label_obj clean_label_act\n",
       "count                 13389           13389           13389\n",
       "unique                13389              26               8\n",
       "top     ประวัติการใช้งานค่ะ         service         enquire\n",
       "freq                      1            2111            8658"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#TODO1\n",
    "data_df = data_df.drop_duplicates(\"Sentence Utterance\", keep=\"first\")\n",
    "display(data_df.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[' <PHONE_NUMBER_REMOVED> ผมไปจ่ายเงินที่ Counter Services เค้าเช็ต 3276.25 บาท เมื่อวานที่ผมเช็คที่ศูนย์บอกมียอด 3057.79 บาท'\n",
      " ' internet ยังความเร็วอยุ่เท่าไหร ครับ'\n",
      " ' ตะกี้ไปชำระค่าบริการไปแล้ว แต่ยังใช้งานไม่ได้ ค่ะ' ...\n",
      " 'ยอดเงินเหลือเท่าไหร่ค่ะ' 'ยอดเงินในระบบ'\n",
      " 'สอบถามโปรโมชั่นปัจจุบันที่ใช้อยู่ค่ะ']\n",
      "['payment' 'package' 'suspend' ... 'balance' 'balance' 'package']\n",
      "['enquire' 'enquire' 'report' ... 'enquire' 'enquire' 'enquire']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kok/anaconda3/envs/tf/lib/python3.6/site-packages/ipykernel_launcher.py:1: FutureWarning: Method .as_matrix will be removed in a future version. Use .values instead.\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "data = np.array(data_df.as_matrix(), copy=True)\n",
    "print(data[:,0])\n",
    "print(data[:,1])\n",
    "print(data[:,2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## #TODO 2: Preprocessing data for Keras\n",
    "You will be using Keras in this assignment. Please show us how you prepare your data for keras.\n",
    "Don't forget to split data into train and test sets (+ validation set if you want)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# TODO2: Preprocessing data for Keras\n",
    "#data 0 => input\n",
    "#data 1 => object\n",
    "#data 2 => action\n",
    "\n",
    "unique_label_obj = data_df.clean_label_obj.unique()\n",
    "label_2_num_map = dict(zip(unique_label_obj, range(len(unique_label_obj))))\n",
    "num_2_label_map = dict(zip(range(len(unique_label_obj)), unique_label_obj))\n",
    "data[:,1] = np.vectorize(label_2_num_map.get)(data[:,1])\n",
    "\n",
    "unique_label_act = data_df.clean_label_act.unique()\n",
    "label_2_num_map = dict(zip(unique_label_act, range(len(unique_label_act))))\n",
    "num_2_label_map = dict(zip(range(len(unique_label_act)), unique_label_act))\n",
    "data[:,2] = np.vectorize(label_2_num_map.get)(data[:,2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def strip_str(string):\n",
    "    return string.strip()\n",
    "# Trim of extra begining and trailing whitespace in the string\n",
    "data[:,0] = np.vectorize(strip_str)(data[:,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a character map\n",
    "CHARS = [\n",
    "  '\\n', ' ', '!', '\"', '#', '$', '%', '&', \"'\", '(', ')', '*', '+',\n",
    "  ',', '-', '.', '/', '0', '1', '2', '3', '4', '5', '6', '7', '8',\n",
    "  '9', ':', ';', '<', '=', '>', '?', '@', 'A', 'B', 'C', 'D', 'E',\n",
    "  'F', 'G', 'H', 'I', 'J', 'K', 'L', 'M', 'N', 'O', 'P', 'Q', 'R',\n",
    "  'S', 'T', 'U', 'V', 'W', 'X', 'Y', 'Z', '[', '\\\\', ']', '^', '_',\n",
    "  'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm',\n",
    "  'n', 'o', 'other', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y',\n",
    "  'z', '}', '~', 'ก', 'ข', 'ฃ', 'ค', 'ฅ', 'ฆ', 'ง', 'จ', 'ฉ', 'ช',\n",
    "  'ซ', 'ฌ', 'ญ', 'ฎ', 'ฏ', 'ฐ', 'ฑ', 'ฒ', 'ณ', 'ด', 'ต', 'ถ', 'ท',\n",
    "  'ธ', 'น', 'บ', 'ป', 'ผ', 'ฝ', 'พ', 'ฟ', 'ภ', 'ม', 'ย', 'ร', 'ฤ',\n",
    "  'ล', 'ว', 'ศ', 'ษ', 'ส', 'ห', 'ฬ', 'อ', 'ฮ', 'ฯ', 'ะ', 'ั', 'า',\n",
    "  'ำ', 'ิ', 'ี', 'ึ', 'ื', 'ุ', 'ู', 'ฺ', 'เ', 'แ', 'โ', 'ใ', 'ไ',\n",
    "  'ๅ', 'ๆ', '็', '่', '้', '๊', '๋', '์', 'ํ', '๐', '๑', '๒', '๓',\n",
    "  '๔', '๕', '๖', '๗', '๘', '๙', '‘', '’', '\\ufeff'\n",
    "]\n",
    "CHARS_MAP = {v: k for k, v in enumerate(CHARS)}\n",
    "char = np.array(CHARS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_n_gram_df(df, n_pad):\n",
    "  \"\"\"\n",
    "  Given an input dataframe, create a feature dataframe of shifted characters\n",
    "  Input:\n",
    "  df: timeseries of size (N)\n",
    "  n_pad: the number of context. For a given character at position [idx],\n",
    "    character at position [idx-n_pad/2 : idx+n_pad/2] will be used \n",
    "    as features for that character.\n",
    "  \n",
    "  Output:\n",
    "  dataframe of size (N * n_pad) which each row contains the character, \n",
    "    n_pad_2 characters to the left, and n_pad_2 characters to the right\n",
    "    of that character.\n",
    "  \"\"\"\n",
    "  n_pad_2 = int((n_pad - 1)/2)\n",
    "  for i in range(n_pad_2):\n",
    "      df['char-{}'.format(i+1)] = df['char'].shift(i + 1)\n",
    "      df['char{}'.format(i+1)] = df['char'].shift(-i - 1)\n",
    "  return df[n_pad_2: -n_pad_2]\n",
    "\n",
    "\n",
    "def prepare_wiki_feature(raw_text_input):\n",
    "    \"\"\"\n",
    "    Transform the path to a directory containing processed files \n",
    "    into a feature matrix and output array\n",
    "    \"\"\"\n",
    "    # we use padding equals 21 here to consider 10 characters to the left\n",
    "    # and 10 characters to the right as features for the character in the middle\n",
    "    n_pad = 21\n",
    "    n_pad_2 = int((n_pad - 1)/2)\n",
    "    pad = [{'char': ' ', 'target': True}]\n",
    "    df_pad = pd.DataFrame(pad * n_pad_2)\n",
    "\n",
    "    df = []\n",
    "\n",
    "    df.append(pd.DataFrame(  {'char': raw_text_input}))\n",
    "\n",
    "    df = pd.concat(df)\n",
    "    # pad with empty string feature\n",
    "    df = pd.concat((df_pad, df, df_pad))\n",
    "\n",
    "    # map characters to numbers, use 'other' if not in the predefined character set.\n",
    "    df['char'] = df['char'].map(lambda x: CHARS_MAP.get(x, 80))\n",
    "\n",
    "    # Use nearby characters as features\n",
    "    df_with_context = create_n_gram_df(df, n_pad=n_pad)\n",
    "\n",
    "    char_row = ['char' + str(i + 1) for i in range(n_pad_2)] + \\\n",
    "             ['char-' + str(i + 1) for i in range(n_pad_2)] + ['char']\n",
    "\n",
    "    # convert pandas dataframe to numpy array to feed to the model\n",
    "    x_char = df_with_context[char_row].as_matrix()\n",
    "\n",
    "    return x_char\n",
    "\n",
    "#A function for displaying our features in text\n",
    "def print_features(tfeature,index):\n",
    "    feature = np.array(tfeature[index],dtype=int).reshape(21,1)\n",
    "    #Convert to string\n",
    "    char_list = char[feature]\n",
    "    left = ''.join(reversed(char_list[10:20].reshape(10))).replace(\" \", \"\")\n",
    "    center = ''.join(char_list[20])\n",
    "    right =  ''.join(char_list[0:10].reshape(10)).replace(\" \", \"\")\n",
    "    word = ''.join([left,' ',center,' ',right])\n",
    "    print(center + ': ' + word )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Conv1D, MaxPooling1D, Embedding, TimeDistributed\n",
    "from keras.layers import Activation, Dropout, Flatten, Dense, Input,GRU, Bidirectional\n",
    "def get_your_nn():\n",
    "    max_features = len(CHARS)+1\n",
    "    max_len=21\n",
    "    #replace \"pass\" with code for your neural net\n",
    "    input1 = Input(shape=(21,))\n",
    "    x = Embedding(max_features, 32, input_length=max_len)(input1)\n",
    "    x = Conv1D(100, 5, strides = 1, padding='same', activation='relu')(x)\n",
    "    x = TimeDistributed(Dense(5, activation='relu'))(x)\n",
    "    x = Flatten()(x)\n",
    "    x = Dense(100, activation='relu')(x)\n",
    "    out = Dense(1, activation='sigmoid')(x)\n",
    "\n",
    "    model = Model(inputs=input1, outputs=out)\n",
    "    model.compile(optimizer=Adam(),\n",
    "                loss='binary_crossentropy',\n",
    "                metrics=['acc'])\n",
    "    return model\n",
    "\n",
    "\n",
    "model = get_your_nn()\n",
    "model.load_weights(\"/media/kok/New Volume/NLP/nlp_2019/HW5/model_conv1d_nn.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kok/anaconda3/envs/tf/lib/python3.6/site-packages/ipykernel_launcher.py:40: FutureWarning: Sorting because non-concatenation axis is not aligned. A future version\n",
      "of pandas will change to not sort by default.\n",
      "\n",
      "To accept the future behavior, pass 'sort=False'.\n",
      "\n",
      "To retain the current behavior and silence the warning, pass 'sort=True'.\n",
      "\n",
      "/home/kok/anaconda3/envs/tf/lib/python3.6/site-packages/ipykernel_launcher.py:52: FutureWarning: Method .as_matrix will be removed in a future version. Use .values instead.\n"
     ]
    }
   ],
   "source": [
    "x_char= []\n",
    "for ss in data[:,0]:\n",
    "    x_char.append(prepare_wiki_feature(list(ss)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def char_to_word(raw_text, y_pred):\n",
    "    \"\"\" add spaces between words in the raw text based on your prediction\n",
    "    \"\"\"\n",
    "    split_text=\"\"\n",
    "    for char, y in zip(raw_text,y_pred):\n",
    "        if y == 1:\n",
    "            split_text+=\" \"\n",
    "            split_text+=char\n",
    "        else:\n",
    "            split_text+=char\n",
    "    return split_text.split(\" \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " data lenght:  13389\n"
     ]
    }
   ],
   "source": [
    "print(' data lenght: ', len(x_char))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getTokens(x_char,data,model):\n",
    "    y_pred = model.predict(x_char)\n",
    "    prob_to_class = lambda p: 1 if p[0]>=0.5 else 0\n",
    "    y_pred = np.apply_along_axis(prob_to_class,1,y_pred)\n",
    "    return char_to_word(data, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenData=np.array(data)\n",
    "tokenData[:,0]=[getTokens(x_char[i],data[:,0][i],model) for i in range (len(data[:,0]))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[list(['', '<PHONE_NUMBER_REMOV', 'ED>', '', '', 'ผม', 'ไป', 'จ่าย', 'เงิน', 'ที่', '', '', 'Counter', '', '', 'Services', '', '', 'เค้า', 'เช็ต', '', '', '3276', '.', '25', '', '', 'บาท', '', '', 'เมื่อ', 'วาน', 'ที่', 'ผม', 'เช็ค', 'ที่', 'ศูนย์', 'บอก', 'มี', 'ยอด', '', '', '305', '7', '.', '79', '', '', 'บาท'])\n",
      "  0 0]\n",
      " [list(['', 'internet', '', '', 'ยัง', 'ความ', 'เร็ว', 'อยุ่เท่า', 'ไหร', '', '', 'ครับ'])\n",
      "  1 0]\n",
      " [list(['', 'ตะกี้', 'ไป', 'ชำระ', 'ค่า', 'บริการ', 'ไป', 'แล้ว', '', '', 'แต่', 'ยัง', 'ใช้', 'งาน', 'ไม่', 'ได้', '', '', 'ค่ะ'])\n",
      "  2 1]\n",
      " [list(['', 'พี่', 'ค่ะ', 'ยัง', 'ใช้', '', '', 'internet', '', '', 'ไม่', 'ได้', 'เลย', 'ค่ะ', '', '', 'เป็น', 'เครื่อง', '', '', 'โกล', 'ไล'])\n",
      "  3 0]\n",
      " [list(['', 'ฮาโหล', '', '', 'คะ', '', '', 'พอดี', 'ว่า', 'เมื่อ', 'วาน', 'เปิด', 'ซิม', 'ทรูมูฟ', '', '', 'แต่', 'มัน', 'โทร', 'ออก', 'ไม่', 'ได้', 'คะ', '', '', 'แต่', 'เล่น', 'เนต', 'ได้', 'คะ'])\n",
      "  4 1]]\n"
     ]
    }
   ],
   "source": [
    "print(tokenData[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max padding : 158\n"
     ]
    }
   ],
   "source": [
    "max_pad = max([len(i) for i in tokenData[:,0]])\n",
    "print('max padding :',max_pad)\n",
    "\n",
    "dictionary = dict()\n",
    "dictionary[\"for_keras_zero_padding\"] = 0\n",
    "dictionary[\"UNK\"] = 1\n",
    "for ss in tokenData[:,0]:\n",
    "    for w in ss:\n",
    "        if w in dictionary:\n",
    "            dictionary[w] = (dictionary[w][0],dictionary[w][1]+1)\n",
    "        else:\n",
    "            dictionary[w] = (len(dictionary),1)\n",
    "            \n",
    "def create_index(words,dictionary):\n",
    "    data = list()\n",
    "    for word in words:\n",
    "        if word in dictionary and dictionary[word][1]>1:\n",
    "            data.append(dictionary[word][0])\n",
    "        else:\n",
    "            data.append(dictionary[\"UNK\"])\n",
    "    return np.concatenate(([data],[[dictionary[\"for_keras_zero_padding\"]]*(max_pad-len(data)) if len(data)<max_pad else []]),axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "inData = np.array(tokenData)\n",
    "inData[:,0] = [create_index(i,dictionary)[0] for i in tokenData[:,0]]\n",
    "reverse_dictionary = dict(zip(dictionary.values(), dictionary.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 2  3  4  2  2  5  6  7  8  9  2  2  1  2  2 11  2  2 12 13  2  2  1 15\n",
      " 16  2  2 17  2  2 18 19  9  5 20  9 21 22 23 24  2  2  1 26 15 27  2  2\n",
      " 17  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n"
     ]
    }
   ],
   "source": [
    "print(inData[:,0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train : (10711, 158)\n",
      "X_test : (2678, 158)\n",
      "Y_train_act : (10711, 8)\n",
      "Y_train_obj : (10711, 26)\n",
      "Y_test_act : (2678, 8)\n",
      "Y_test_obj : (2678, 26)\n",
      "[  2 145  69   2   2  67  41 119 118 412   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0]\n",
      "[1 0 0 0 0 0 0 0]\n",
      "[0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n"
     ]
    }
   ],
   "source": [
    "from keras.utils import to_categorical\n",
    "np.random.shuffle(inData)\n",
    "act = to_categorical(inData[:,2],dtype=int)\n",
    "obj = to_categorical(inData[:,1],dtype=int)\n",
    "#train:test ratio\n",
    "ratio = 5\n",
    "x_train = np.array(list(inData[:-len(inData)//ratio,0]))\n",
    "x_test = np.array(list(inData[-len(inData)//ratio:,0]))\n",
    "\n",
    "y_train_obj = np.array(list(obj[:-len(inData)//ratio]))\n",
    "y_test_obj = np.array(list(obj[-len(inData)//ratio:]))\n",
    "\n",
    "y_train_act = np.array(list(act[:-len(inData)//ratio]))\n",
    "y_test_act = np.array(list(act[-len(inData)//ratio:]))\n",
    "\n",
    "print('X_train :',x_train.shape)\n",
    "print('X_test :',x_test.shape)\n",
    "print('Y_train_act :',y_train_act.shape)\n",
    "print('Y_train_obj :',y_train_obj.shape)\n",
    "print('Y_test_act :',y_test_act.shape)\n",
    "print('Y_test_obj :',y_test_obj.shape)\n",
    "print(x_train[0])\n",
    "print(y_train_act[0])\n",
    "print(y_train_obj[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## #TODO 3: Build and evaluate a model for \"action\" classification\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_6 (InputLayer)         (None, 158)               0         \n",
      "_________________________________________________________________\n",
      "embedding_6 (Embedding)      (None, 158, 32)           197408    \n",
      "_________________________________________________________________\n",
      "conv1d_6 (Conv1D)            (None, 158, 50)           4850      \n",
      "_________________________________________________________________\n",
      "time_distributed_6 (TimeDist (None, 158, 5)            255       \n",
      "_________________________________________________________________\n",
      "flatten_6 (Flatten)          (None, 790)               0         \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (None, 790)               0         \n",
      "_________________________________________________________________\n",
      "dense_17 (Dense)             (None, 50)                39550     \n",
      "_________________________________________________________________\n",
      "dense_18 (Dense)             (None, 8)                 408       \n",
      "=================================================================\n",
      "Total params: 242,471\n",
      "Trainable params: 242,471\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#TODO 3: Build and evaluate a model for \"action\" classification\n",
    "def get_your_action():\n",
    "    max_features = len(dictionary)+1\n",
    "    max_len=max_pad\n",
    "    #replace \"pass\" with code for your neural net\n",
    "    input1 = Input(shape=(max_len,))\n",
    "    x = Embedding(max_features, 32, input_length=max_len,trainable=True)(input1)\n",
    "    x = Conv1D(50, 3, strides = 1, padding='same', activation='relu')(x)\n",
    "    x = TimeDistributed(Dense(5, activation='relu'))(x)\n",
    "    x = Flatten()(x)\n",
    "    x = Dropout(0.1)(x)\n",
    "    x = Dense(50, activation='relu')(x)\n",
    "    out = Dense(len(data_df.clean_label_act.unique()), activation='sigmoid')(x)\n",
    "\n",
    "    model = Model(inputs=input1, outputs=out)\n",
    "    model.compile(optimizer=Adam(),\n",
    "                loss='binary_crossentropy',\n",
    "                metrics=['acc'])\n",
    "    return model\n",
    "\n",
    "\n",
    "action_model = get_your_action()\n",
    "action_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 10711 samples, validate on 2678 samples\n",
      "Epoch 1/30\n",
      "10711/10711 [==============================] - 1s 90us/step - loss: 0.0899 - acc: 0.9679 - val_loss: 0.1386 - val_acc: 0.9537\n",
      "Epoch 2/30\n",
      "10711/10711 [==============================] - 1s 83us/step - loss: 0.0861 - acc: 0.9695 - val_loss: 0.1476 - val_acc: 0.9535\n",
      "Epoch 3/30\n",
      "10711/10711 [==============================] - 1s 88us/step - loss: 0.0837 - acc: 0.9698 - val_loss: 0.1462 - val_acc: 0.9551\n",
      "Epoch 4/30\n",
      "10711/10711 [==============================] - 1s 82us/step - loss: 0.0807 - acc: 0.9709 - val_loss: 0.1477 - val_acc: 0.9545\n",
      "Epoch 5/30\n",
      "10711/10711 [==============================] - 1s 83us/step - loss: 0.0766 - acc: 0.9726 - val_loss: 0.1423 - val_acc: 0.9553\n",
      "Epoch 6/30\n",
      "10711/10711 [==============================] - 1s 79us/step - loss: 0.0752 - acc: 0.9729 - val_loss: 0.1488 - val_acc: 0.9543\n",
      "Epoch 7/30\n",
      "10711/10711 [==============================] - 1s 83us/step - loss: 0.0714 - acc: 0.9742 - val_loss: 0.1489 - val_acc: 0.9541\n",
      "Epoch 8/30\n",
      "10711/10711 [==============================] - 1s 86us/step - loss: 0.0691 - acc: 0.9757 - val_loss: 0.1584 - val_acc: 0.9545\n",
      "Epoch 9/30\n",
      "10711/10711 [==============================] - 1s 82us/step - loss: 0.0686 - acc: 0.9752 - val_loss: 0.1592 - val_acc: 0.9543\n",
      "Epoch 10/30\n",
      "10711/10711 [==============================] - 1s 85us/step - loss: 0.0658 - acc: 0.9760 - val_loss: 0.1561 - val_acc: 0.9534\n",
      "Epoch 11/30\n",
      "10711/10711 [==============================] - 1s 84us/step - loss: 0.0636 - acc: 0.9766 - val_loss: 0.1672 - val_acc: 0.9544\n",
      "Epoch 12/30\n",
      "10711/10711 [==============================] - 1s 84us/step - loss: 0.0619 - acc: 0.9775 - val_loss: 0.1600 - val_acc: 0.9549\n",
      "Epoch 13/30\n",
      "10711/10711 [==============================] - 1s 84us/step - loss: 0.0610 - acc: 0.9782 - val_loss: 0.1733 - val_acc: 0.9538\n",
      "Epoch 14/30\n",
      "10711/10711 [==============================] - 1s 86us/step - loss: 0.0581 - acc: 0.9791 - val_loss: 0.1734 - val_acc: 0.9540\n",
      "Epoch 15/30\n",
      "10711/10711 [==============================] - 1s 84us/step - loss: 0.0566 - acc: 0.9798 - val_loss: 0.1768 - val_acc: 0.9537\n",
      "Epoch 16/30\n",
      "10711/10711 [==============================] - 1s 83us/step - loss: 0.0551 - acc: 0.9807 - val_loss: 0.1730 - val_acc: 0.9533\n",
      "Epoch 17/30\n",
      "10711/10711 [==============================] - 1s 90us/step - loss: 0.0544 - acc: 0.9805 - val_loss: 0.1743 - val_acc: 0.9539\n",
      "Epoch 18/30\n",
      "10711/10711 [==============================] - 1s 85us/step - loss: 0.0531 - acc: 0.9810 - val_loss: 0.1779 - val_acc: 0.9539\n",
      "Epoch 19/30\n",
      "10711/10711 [==============================] - 1s 84us/step - loss: 0.0521 - acc: 0.9814 - val_loss: 0.1851 - val_acc: 0.9534\n",
      "Epoch 20/30\n",
      "10711/10711 [==============================] - 1s 84us/step - loss: 0.0497 - acc: 0.9820 - val_loss: 0.1805 - val_acc: 0.9528\n",
      "Epoch 21/30\n",
      "10711/10711 [==============================] - 1s 83us/step - loss: 0.0492 - acc: 0.9822 - val_loss: 0.1918 - val_acc: 0.9535\n",
      "Epoch 22/30\n",
      "10711/10711 [==============================] - 1s 83us/step - loss: 0.0505 - acc: 0.9819 - val_loss: 0.1826 - val_acc: 0.9524\n",
      "Epoch 23/30\n",
      "10711/10711 [==============================] - 1s 84us/step - loss: 0.0473 - acc: 0.9832 - val_loss: 0.2023 - val_acc: 0.9524\n",
      "Epoch 24/30\n",
      "10711/10711 [==============================] - 1s 89us/step - loss: 0.0460 - acc: 0.9840 - val_loss: 0.2066 - val_acc: 0.9536\n",
      "Epoch 25/30\n",
      "10711/10711 [==============================] - 1s 91us/step - loss: 0.0454 - acc: 0.9842 - val_loss: 0.2082 - val_acc: 0.9528\n",
      "Epoch 26/30\n",
      "10711/10711 [==============================] - 1s 93us/step - loss: 0.0447 - acc: 0.9838 - val_loss: 0.2049 - val_acc: 0.9530\n",
      "Epoch 27/30\n",
      "10711/10711 [==============================] - 1s 93us/step - loss: 0.0431 - acc: 0.9848 - val_loss: 0.2078 - val_acc: 0.9520\n",
      "Epoch 28/30\n",
      "10711/10711 [==============================] - 1s 92us/step - loss: 0.0418 - acc: 0.9850 - val_loss: 0.2117 - val_acc: 0.9522\n",
      "Epoch 29/30\n",
      "10711/10711 [==============================] - 1s 93us/step - loss: 0.0416 - acc: 0.9847 - val_loss: 0.2218 - val_acc: 0.9524\n",
      "Epoch 30/30\n",
      "10711/10711 [==============================] - 1s 93us/step - loss: 0.0415 - acc: 0.9850 - val_loss: 0.2330 - val_acc: 0.9519\n",
      "CPU times: user 28.3 s, sys: 4.86 s, total: 33.2 s\n",
      "Wall time: 27.7 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f169739c5f8>"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "action_model.fit(x_train,y_train_act,validation_data=(x_test,y_test_act),batch_size=128,epochs=30,verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "     enquire       0.83      0.91      0.87      1686\n",
      "      report       0.76      0.57      0.66       327\n",
      "      cancel       0.91      0.82      0.86       222\n",
      "         buy       0.74      0.56      0.63       154\n",
      "    activate       0.76      0.50      0.61       107\n",
      "     request       0.50      0.13      0.20        70\n",
      "     garbage       0.00      0.00      0.00         7\n",
      "      change       0.65      0.66      0.65       105\n",
      "\n",
      "   micro avg       0.82      0.79      0.81      2678\n",
      "   macro avg       0.64      0.52      0.56      2678\n",
      "weighted avg       0.80      0.79      0.79      2678\n",
      " samples avg       0.79      0.79      0.79      2678\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "y_pred = action_model.predict(x_test)\n",
    "y_pred = (y_pred > 0.5)\n",
    "print(classification_report(y_test_act,y_pred,target_names=data_df.clean_label_act.unique()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## #TODO 4: Build and evaluate a model for \"object\" classification\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_7 (InputLayer)         (None, 158)               0         \n",
      "_________________________________________________________________\n",
      "embedding_7 (Embedding)      (None, 158, 32)           197408    \n",
      "_________________________________________________________________\n",
      "conv1d_7 (Conv1D)            (None, 158, 100)          16100     \n",
      "_________________________________________________________________\n",
      "time_distributed_7 (TimeDist (None, 158, 5)            505       \n",
      "_________________________________________________________________\n",
      "flatten_7 (Flatten)          (None, 790)               0         \n",
      "_________________________________________________________________\n",
      "dropout_6 (Dropout)          (None, 790)               0         \n",
      "_________________________________________________________________\n",
      "dense_20 (Dense)             (None, 100)               79100     \n",
      "_________________________________________________________________\n",
      "dense_21 (Dense)             (None, 26)                2626      \n",
      "=================================================================\n",
      "Total params: 295,739\n",
      "Trainable params: 295,739\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#TODO 4: Build and evaluate a model for \"object\" classification\n",
    "def get_your_object():\n",
    "    max_features = len(dictionary)+1\n",
    "    max_len=max_pad\n",
    "    #replace \"pass\" with code for your neural net\n",
    "    input1 = Input(shape=(max_len,))\n",
    "    x = Embedding(max_features, 32, input_length=max_len,trainable=True)(input1)\n",
    "    x = Conv1D(100, 5, strides = 1, padding='same', activation='relu')(x)\n",
    "    x = TimeDistributed(Dense(5, activation='relu'))(x)\n",
    "    x = Flatten()(x)\n",
    "    x = Dropout(0.1)(x)\n",
    "    x = Dense(100, activation='relu')(x)\n",
    "    out = Dense(len(data_df.clean_label_obj.unique()), activation='sigmoid')(x)\n",
    "\n",
    "    model = Model(inputs=input1, outputs=out)\n",
    "    model.compile(optimizer=Adam(),\n",
    "                loss='binary_crossentropy',\n",
    "                metrics=['acc'])\n",
    "    return model\n",
    "\n",
    "\n",
    "obj_model = get_your_object()\n",
    "obj_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 10711 samples, validate on 2678 samples\n",
      "Epoch 1/50\n",
      "10711/10711 [==============================] - 2s 186us/step - loss: 0.2399 - acc: 0.9344 - val_loss: 0.1381 - val_acc: 0.9615\n",
      "Epoch 2/50\n",
      "10711/10711 [==============================] - 1s 125us/step - loss: 0.1308 - acc: 0.9624 - val_loss: 0.1231 - val_acc: 0.9638\n",
      "Epoch 3/50\n",
      "10711/10711 [==============================] - 1s 122us/step - loss: 0.1173 - acc: 0.9648 - val_loss: 0.1138 - val_acc: 0.9657\n",
      "Epoch 4/50\n",
      "10711/10711 [==============================] - 1s 122us/step - loss: 0.1064 - acc: 0.9677 - val_loss: 0.1035 - val_acc: 0.9686\n",
      "Epoch 5/50\n",
      "10711/10711 [==============================] - 1s 129us/step - loss: 0.0972 - acc: 0.9696 - val_loss: 0.0981 - val_acc: 0.9695\n",
      "Epoch 6/50\n",
      "10711/10711 [==============================] - 1s 125us/step - loss: 0.0905 - acc: 0.9708 - val_loss: 0.0938 - val_acc: 0.9698\n",
      "Epoch 7/50\n",
      "10711/10711 [==============================] - 1s 125us/step - loss: 0.0851 - acc: 0.9720 - val_loss: 0.0904 - val_acc: 0.9710\n",
      "Epoch 8/50\n",
      "10711/10711 [==============================] - 1s 124us/step - loss: 0.0800 - acc: 0.9734 - val_loss: 0.0872 - val_acc: 0.9720\n",
      "Epoch 9/50\n",
      "10711/10711 [==============================] - 1s 123us/step - loss: 0.0755 - acc: 0.9744 - val_loss: 0.0855 - val_acc: 0.9720\n",
      "Epoch 10/50\n",
      "10711/10711 [==============================] - 1s 123us/step - loss: 0.0712 - acc: 0.9758 - val_loss: 0.0849 - val_acc: 0.9725\n",
      "Epoch 11/50\n",
      "10711/10711 [==============================] - 1s 123us/step - loss: 0.0679 - acc: 0.9767 - val_loss: 0.0843 - val_acc: 0.9729\n",
      "Epoch 12/50\n",
      "10711/10711 [==============================] - 1s 123us/step - loss: 0.0647 - acc: 0.9773 - val_loss: 0.0833 - val_acc: 0.9735\n",
      "Epoch 13/50\n",
      "10711/10711 [==============================] - 1s 124us/step - loss: 0.0617 - acc: 0.9786 - val_loss: 0.0835 - val_acc: 0.9729\n",
      "Epoch 14/50\n",
      "10711/10711 [==============================] - 1s 127us/step - loss: 0.0587 - acc: 0.9796 - val_loss: 0.0817 - val_acc: 0.9744\n",
      "Epoch 15/50\n",
      "10711/10711 [==============================] - 1s 125us/step - loss: 0.0557 - acc: 0.9806 - val_loss: 0.0825 - val_acc: 0.9744\n",
      "Epoch 16/50\n",
      "10711/10711 [==============================] - 1s 124us/step - loss: 0.0534 - acc: 0.9816 - val_loss: 0.0822 - val_acc: 0.9744\n",
      "Epoch 17/50\n",
      "10711/10711 [==============================] - 1s 125us/step - loss: 0.0515 - acc: 0.9822 - val_loss: 0.0821 - val_acc: 0.9750\n",
      "Epoch 18/50\n",
      "10711/10711 [==============================] - 1s 125us/step - loss: 0.0493 - acc: 0.9828 - val_loss: 0.0825 - val_acc: 0.9750\n",
      "Epoch 19/50\n",
      "10711/10711 [==============================] - 1s 130us/step - loss: 0.0474 - acc: 0.9838 - val_loss: 0.0832 - val_acc: 0.9751\n",
      "Epoch 20/50\n",
      "10711/10711 [==============================] - 1s 130us/step - loss: 0.0459 - acc: 0.9841 - val_loss: 0.0847 - val_acc: 0.9747\n",
      "Epoch 21/50\n",
      "10711/10711 [==============================] - 1s 134us/step - loss: 0.0446 - acc: 0.9847 - val_loss: 0.0852 - val_acc: 0.9753\n",
      "Epoch 22/50\n",
      "10711/10711 [==============================] - 1s 132us/step - loss: 0.0425 - acc: 0.9854 - val_loss: 0.0863 - val_acc: 0.9746\n",
      "Epoch 23/50\n",
      "10711/10711 [==============================] - 1s 129us/step - loss: 0.0413 - acc: 0.9859 - val_loss: 0.0873 - val_acc: 0.9748\n",
      "Epoch 24/50\n",
      "10711/10711 [==============================] - 1s 133us/step - loss: 0.0402 - acc: 0.9862 - val_loss: 0.0887 - val_acc: 0.9750\n",
      "Epoch 25/50\n",
      "10711/10711 [==============================] - 1s 131us/step - loss: 0.0395 - acc: 0.9863 - val_loss: 0.0904 - val_acc: 0.9748\n",
      "Epoch 26/50\n",
      "10711/10711 [==============================] - 1s 132us/step - loss: 0.0378 - acc: 0.9869 - val_loss: 0.0913 - val_acc: 0.9746\n",
      "Epoch 27/50\n",
      "10711/10711 [==============================] - 1s 131us/step - loss: 0.0372 - acc: 0.9871 - val_loss: 0.0919 - val_acc: 0.9748\n",
      "Epoch 28/50\n",
      "10711/10711 [==============================] - 1s 131us/step - loss: 0.0357 - acc: 0.9875 - val_loss: 0.0933 - val_acc: 0.9748\n",
      "Epoch 29/50\n",
      "10711/10711 [==============================] - 1s 132us/step - loss: 0.0349 - acc: 0.9878 - val_loss: 0.0930 - val_acc: 0.9746\n",
      "Epoch 30/50\n",
      "10711/10711 [==============================] - 1s 133us/step - loss: 0.0340 - acc: 0.9882 - val_loss: 0.0952 - val_acc: 0.9750\n",
      "Epoch 31/50\n",
      "10711/10711 [==============================] - 1s 133us/step - loss: 0.0332 - acc: 0.9885 - val_loss: 0.0955 - val_acc: 0.9740\n",
      "Epoch 32/50\n",
      "10711/10711 [==============================] - 1s 133us/step - loss: 0.0325 - acc: 0.9889 - val_loss: 0.0978 - val_acc: 0.9748\n",
      "Epoch 33/50\n",
      "10711/10711 [==============================] - 1s 132us/step - loss: 0.0314 - acc: 0.9892 - val_loss: 0.0993 - val_acc: 0.9746\n",
      "Epoch 34/50\n",
      "10711/10711 [==============================] - 1s 131us/step - loss: 0.0305 - acc: 0.9896 - val_loss: 0.0998 - val_acc: 0.9743\n",
      "Epoch 35/50\n",
      "10711/10711 [==============================] - 1s 132us/step - loss: 0.0293 - acc: 0.9898 - val_loss: 0.1006 - val_acc: 0.9747\n",
      "Epoch 36/50\n",
      "10711/10711 [==============================] - 1s 131us/step - loss: 0.0288 - acc: 0.9899 - val_loss: 0.1022 - val_acc: 0.9747\n",
      "Epoch 37/50\n",
      "10711/10711 [==============================] - 1s 131us/step - loss: 0.0279 - acc: 0.9903 - val_loss: 0.1045 - val_acc: 0.9746\n",
      "Epoch 38/50\n",
      "10711/10711 [==============================] - 1s 132us/step - loss: 0.0272 - acc: 0.9906 - val_loss: 0.1062 - val_acc: 0.9741\n",
      "Epoch 39/50\n",
      "10711/10711 [==============================] - 1s 132us/step - loss: 0.0268 - acc: 0.9904 - val_loss: 0.1075 - val_acc: 0.9747\n",
      "Epoch 40/50\n",
      "10711/10711 [==============================] - 1s 134us/step - loss: 0.0261 - acc: 0.9910 - val_loss: 0.1079 - val_acc: 0.9742\n",
      "Epoch 41/50\n",
      "10711/10711 [==============================] - 1s 133us/step - loss: 0.0250 - acc: 0.9911 - val_loss: 0.1091 - val_acc: 0.9744\n",
      "Epoch 42/50\n",
      "10711/10711 [==============================] - 1s 133us/step - loss: 0.0246 - acc: 0.9915 - val_loss: 0.1123 - val_acc: 0.9742\n",
      "Epoch 43/50\n",
      "10711/10711 [==============================] - 1s 133us/step - loss: 0.0239 - acc: 0.9916 - val_loss: 0.1119 - val_acc: 0.9743\n",
      "Epoch 44/50\n",
      "10711/10711 [==============================] - 1s 133us/step - loss: 0.0233 - acc: 0.9918 - val_loss: 0.1157 - val_acc: 0.9735\n",
      "Epoch 45/50\n",
      "10711/10711 [==============================] - 1s 129us/step - loss: 0.0231 - acc: 0.9921 - val_loss: 0.1145 - val_acc: 0.9738\n",
      "Epoch 46/50\n",
      "10711/10711 [==============================] - 1s 131us/step - loss: 0.0225 - acc: 0.9920 - val_loss: 0.1194 - val_acc: 0.9739\n",
      "Epoch 47/50\n",
      "10711/10711 [==============================] - 1s 131us/step - loss: 0.0221 - acc: 0.9923 - val_loss: 0.1178 - val_acc: 0.9740\n",
      "Epoch 48/50\n",
      "10711/10711 [==============================] - 1s 131us/step - loss: 0.0214 - acc: 0.9926 - val_loss: 0.1210 - val_acc: 0.9738\n",
      "Epoch 49/50\n",
      "10711/10711 [==============================] - 1s 132us/step - loss: 0.0211 - acc: 0.9927 - val_loss: 0.1205 - val_acc: 0.9741\n",
      "Epoch 50/50\n",
      "10711/10711 [==============================] - 1s 131us/step - loss: 0.0207 - acc: 0.9927 - val_loss: 0.1230 - val_acc: 0.9742\n",
      "CPU times: user 1min 3s, sys: 12.4 s, total: 1min 15s\n",
      "Wall time: 1min 10s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f16973cd940>"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "obj_model.fit(x_train,y_train_obj,validation_data=(x_test,y_test_obj),batch_size=128,epochs=50,verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 precision    recall  f1-score   support\n",
      "\n",
      "        payment       0.50      0.48      0.49       130\n",
      "        package       0.71      0.62      0.66       346\n",
      "        suspend       0.76      0.66      0.71       152\n",
      "       internet       0.75      0.63      0.68       368\n",
      "   phone_issues       0.64      0.42      0.51       136\n",
      "        service       0.79      0.70      0.74       418\n",
      "    nontruemove       0.24      0.13      0.17        45\n",
      "        balance       0.78      0.74      0.76       282\n",
      "         detail       0.40      0.26      0.32        61\n",
      "           bill       0.50      0.58      0.54        97\n",
      "         credit       0.80      0.41      0.54        39\n",
      "      promotion       0.65      0.63      0.64       237\n",
      " mobile_setting       0.44      0.35      0.39        48\n",
      "       iservice       0.00      0.00      0.00         5\n",
      "        roaming       0.82      0.64      0.72        50\n",
      "      truemoney       0.58      0.64      0.61        44\n",
      "    information       0.44      0.23      0.30        69\n",
      "    lost_stolen       0.89      0.70      0.78        57\n",
      "balance_minutes       0.00      0.00      0.00        11\n",
      "            idd       0.81      0.61      0.69        41\n",
      "        garbage       0.00      0.00      0.00         7\n",
      "       ringtone       0.90      0.60      0.72        15\n",
      "           rate       0.00      0.00      0.00        11\n",
      "   loyalty_card       0.33      0.50      0.40         6\n",
      "        contact       0.00      0.00      0.00         0\n",
      "        officer       0.00      0.00      0.00         3\n",
      "\n",
      "      micro avg       0.69      0.59      0.64      2678\n",
      "      macro avg       0.49      0.41      0.44      2678\n",
      "   weighted avg       0.68      0.59      0.63      2678\n",
      "    samples avg       0.58      0.59      0.58      2678\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_pred = obj_model.predict(x_test)\n",
    "y_pred = (y_pred > 0.5)\n",
    "print(classification_report(y_test_obj,y_pred,target_names=data_df.clean_label_obj.unique()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## #TODO 5: Build and evaluate a multi-task model that does both \"action\" and \"object\" classifications in one-go \n",
    "\n",
    "This can be a bit tricky, if you are not familiar with the Keras functional API. PLEASE READ this webpage(https://keras.io/getting-started/functional-api-guide/) before you start this task.   \n",
    "\n",
    "Your model will have 2 separate output layers one for action classification task and another for object classification task. \n",
    "\n",
    "This is a rough sketch of what your model might look like:\n",
    "![image](https://raw.githubusercontent.com/ekapolc/nlp_course/master/HW5/multitask_sketch.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_8 (InputLayer)            (None, 158)          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_8 (Embedding)         (None, 158, 32)      197408      input_8[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_8 (Conv1D)               (None, 158, 100)     16100       embedding_8[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_8 (TimeDistrib (None, 158, 5)       505         conv1d_8[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "flatten_8 (Flatten)             (None, 790)          0           time_distributed_8[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "dropout_7 (Dropout)             (None, 790)          0           flatten_8[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_23 (Dense)                (None, 100)          79100       dropout_7[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_24 (Dense)                (None, 26)           2626        dense_23[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_25 (Dense)                (None, 8)            808         dense_23[0][0]                   \n",
      "==================================================================================================\n",
      "Total params: 296,547\n",
      "Trainable params: 296,547\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#TODO 5: Build and evaluate a multi-task model that does both \"action\" and \"object\" classifications in one-go\n",
    "def get_your_mix():\n",
    "    max_features = len(dictionary)+1\n",
    "    max_len=max_pad\n",
    "    #replace \"pass\" with code for your neural net\n",
    "    input1 = Input(shape=(max_len,))\n",
    "    x = Embedding(max_features, 32, input_length=max_len,trainable=True)(input1)\n",
    "    x = Conv1D(100, 5, strides = 1, padding='same', activation='relu')(x)\n",
    "    x = TimeDistributed(Dense(5, activation='relu'))(x)\n",
    "    x = Flatten()(x)\n",
    "    x = Dropout(0.1)(x)\n",
    "    x = Dense(100, activation='relu')(x)\n",
    "    out1 = Dense(len(data_df.clean_label_obj.unique()), activation='sigmoid')(x)\n",
    "    out2 = Dense(len(data_df.clean_label_act.unique()), activation='sigmoid')(x)\n",
    "\n",
    "    model = Model(inputs=input1, outputs=[out1,out2])\n",
    "    model.compile(optimizer=Adam(),\n",
    "                loss='binary_crossentropy',\n",
    "                metrics=['acc'])\n",
    "    return model\n",
    "\n",
    "\n",
    "mix_model = get_your_mix()\n",
    "mix_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 10711 samples, validate on 2678 samples\n",
      "Epoch 1/50\n",
      "10711/10711 [==============================] - 2s 213us/step - loss: 0.5186 - dense_24_loss: 0.2237 - dense_25_loss: 0.2949 - dense_24_acc: 0.9280 - dense_25_acc: 0.9075 - val_loss: 0.3810 - val_dense_24_loss: 0.1388 - val_dense_25_loss: 0.2421 - val_dense_24_acc: 0.9615 - val_dense_25_acc: 0.9126\n",
      "Epoch 2/50\n",
      "10711/10711 [==============================] - 1s 135us/step - loss: 0.3310 - dense_24_loss: 0.1341 - dense_25_loss: 0.1969 - dense_24_acc: 0.9621 - dense_25_acc: 0.9337 - val_loss: 0.3105 - val_dense_24_loss: 0.1268 - val_dense_25_loss: 0.1838 - val_dense_24_acc: 0.9640 - val_dense_25_acc: 0.9355\n",
      "Epoch 3/50\n",
      "10711/10711 [==============================] - 1s 139us/step - loss: 0.2797 - dense_24_loss: 0.1221 - dense_25_loss: 0.1576 - dense_24_acc: 0.9642 - dense_25_acc: 0.9442 - val_loss: 0.2843 - val_dense_24_loss: 0.1195 - val_dense_25_loss: 0.1648 - val_dense_24_acc: 0.9648 - val_dense_25_acc: 0.9390\n",
      "Epoch 4/50\n",
      "10711/10711 [==============================] - 1s 133us/step - loss: 0.2539 - dense_24_loss: 0.1158 - dense_25_loss: 0.1381 - dense_24_acc: 0.9649 - dense_25_acc: 0.9494 - val_loss: 0.2717 - val_dense_24_loss: 0.1152 - val_dense_25_loss: 0.1566 - val_dense_24_acc: 0.9655 - val_dense_25_acc: 0.9437\n",
      "Epoch 5/50\n",
      "10711/10711 [==============================] - 1s 132us/step - loss: 0.2334 - dense_24_loss: 0.1096 - dense_25_loss: 0.1237 - dense_24_acc: 0.9662 - dense_25_acc: 0.9544 - val_loss: 0.2553 - val_dense_24_loss: 0.1103 - val_dense_25_loss: 0.1450 - val_dense_24_acc: 0.9660 - val_dense_25_acc: 0.9489\n",
      "Epoch 6/50\n",
      "10711/10711 [==============================] - 1s 132us/step - loss: 0.2184 - dense_24_loss: 0.1045 - dense_25_loss: 0.1139 - dense_24_acc: 0.9672 - dense_25_acc: 0.9583 - val_loss: 0.2460 - val_dense_24_loss: 0.1057 - val_dense_25_loss: 0.1403 - val_dense_24_acc: 0.9670 - val_dense_25_acc: 0.9501\n",
      "Epoch 7/50\n",
      "10711/10711 [==============================] - 1s 132us/step - loss: 0.2059 - dense_24_loss: 0.0992 - dense_25_loss: 0.1067 - dense_24_acc: 0.9684 - dense_25_acc: 0.9609 - val_loss: 0.2384 - val_dense_24_loss: 0.1021 - val_dense_25_loss: 0.1363 - val_dense_24_acc: 0.9684 - val_dense_25_acc: 0.9519\n",
      "Epoch 8/50\n",
      "10711/10711 [==============================] - 1s 133us/step - loss: 0.1936 - dense_24_loss: 0.0943 - dense_25_loss: 0.0993 - dense_24_acc: 0.9697 - dense_25_acc: 0.9635 - val_loss: 0.2346 - val_dense_24_loss: 0.1005 - val_dense_25_loss: 0.1341 - val_dense_24_acc: 0.9687 - val_dense_25_acc: 0.9527\n",
      "Epoch 9/50\n",
      "10711/10711 [==============================] - 1s 133us/step - loss: 0.1834 - dense_24_loss: 0.0904 - dense_25_loss: 0.0930 - dense_24_acc: 0.9707 - dense_25_acc: 0.9664 - val_loss: 0.2360 - val_dense_24_loss: 0.0961 - val_dense_25_loss: 0.1399 - val_dense_24_acc: 0.9699 - val_dense_25_acc: 0.9531\n",
      "Epoch 10/50\n",
      "10711/10711 [==============================] - 1s 132us/step - loss: 0.1759 - dense_24_loss: 0.0868 - dense_25_loss: 0.0891 - dense_24_acc: 0.9716 - dense_25_acc: 0.9679 - val_loss: 0.2276 - val_dense_24_loss: 0.0937 - val_dense_25_loss: 0.1339 - val_dense_24_acc: 0.9704 - val_dense_25_acc: 0.9550\n",
      "Epoch 11/50\n",
      "10711/10711 [==============================] - 1s 136us/step - loss: 0.1663 - dense_24_loss: 0.0835 - dense_25_loss: 0.0828 - dense_24_acc: 0.9726 - dense_25_acc: 0.9700 - val_loss: 0.2238 - val_dense_24_loss: 0.0917 - val_dense_25_loss: 0.1321 - val_dense_24_acc: 0.9710 - val_dense_25_acc: 0.9554\n",
      "Epoch 12/50\n",
      "10711/10711 [==============================] - 1s 135us/step - loss: 0.1594 - dense_24_loss: 0.0806 - dense_25_loss: 0.0788 - dense_24_acc: 0.9731 - dense_25_acc: 0.9715 - val_loss: 0.2312 - val_dense_24_loss: 0.0918 - val_dense_25_loss: 0.1395 - val_dense_24_acc: 0.9711 - val_dense_25_acc: 0.9558\n",
      "Epoch 13/50\n",
      "10711/10711 [==============================] - 1s 137us/step - loss: 0.1530 - dense_24_loss: 0.0783 - dense_25_loss: 0.0747 - dense_24_acc: 0.9741 - dense_25_acc: 0.9732 - val_loss: 0.2286 - val_dense_24_loss: 0.0905 - val_dense_25_loss: 0.1381 - val_dense_24_acc: 0.9715 - val_dense_25_acc: 0.9567\n",
      "Epoch 14/50\n",
      "10711/10711 [==============================] - 1s 140us/step - loss: 0.1481 - dense_24_loss: 0.0762 - dense_25_loss: 0.0719 - dense_24_acc: 0.9746 - dense_25_acc: 0.9741 - val_loss: 0.2312 - val_dense_24_loss: 0.0903 - val_dense_25_loss: 0.1409 - val_dense_24_acc: 0.9712 - val_dense_25_acc: 0.9558\n",
      "Epoch 15/50\n",
      "10711/10711 [==============================] - 1s 139us/step - loss: 0.1419 - dense_24_loss: 0.0740 - dense_25_loss: 0.0679 - dense_24_acc: 0.9750 - dense_25_acc: 0.9760 - val_loss: 0.2353 - val_dense_24_loss: 0.0903 - val_dense_25_loss: 0.1450 - val_dense_24_acc: 0.9720 - val_dense_25_acc: 0.9560\n",
      "Epoch 16/50\n",
      "10711/10711 [==============================] - 1s 137us/step - loss: 0.1378 - dense_24_loss: 0.0722 - dense_25_loss: 0.0656 - dense_24_acc: 0.9753 - dense_25_acc: 0.9766 - val_loss: 0.2345 - val_dense_24_loss: 0.0897 - val_dense_25_loss: 0.1448 - val_dense_24_acc: 0.9725 - val_dense_25_acc: 0.9572\n",
      "Epoch 17/50\n",
      "10711/10711 [==============================] - 1s 138us/step - loss: 0.1332 - dense_24_loss: 0.0704 - dense_25_loss: 0.0628 - dense_24_acc: 0.9759 - dense_25_acc: 0.9778 - val_loss: 0.2320 - val_dense_24_loss: 0.0893 - val_dense_25_loss: 0.1427 - val_dense_24_acc: 0.9723 - val_dense_25_acc: 0.9565\n",
      "Epoch 18/50\n",
      "10711/10711 [==============================] - 2s 149us/step - loss: 0.1283 - dense_24_loss: 0.0682 - dense_25_loss: 0.0601 - dense_24_acc: 0.9766 - dense_25_acc: 0.9786 - val_loss: 0.2447 - val_dense_24_loss: 0.0908 - val_dense_25_loss: 0.1539 - val_dense_24_acc: 0.9718 - val_dense_25_acc: 0.9554\n",
      "Epoch 19/50\n",
      "10711/10711 [==============================] - 2s 156us/step - loss: 0.1247 - dense_24_loss: 0.0670 - dense_25_loss: 0.0577 - dense_24_acc: 0.9770 - dense_25_acc: 0.9797 - val_loss: 0.2386 - val_dense_24_loss: 0.0902 - val_dense_25_loss: 0.1484 - val_dense_24_acc: 0.9720 - val_dense_25_acc: 0.9564\n",
      "Epoch 20/50\n",
      "10711/10711 [==============================] - 2s 155us/step - loss: 0.1219 - dense_24_loss: 0.0657 - dense_25_loss: 0.0563 - dense_24_acc: 0.9772 - dense_25_acc: 0.9807 - val_loss: 0.2452 - val_dense_24_loss: 0.0905 - val_dense_25_loss: 0.1546 - val_dense_24_acc: 0.9721 - val_dense_25_acc: 0.9559\n",
      "Epoch 21/50\n",
      "10711/10711 [==============================] - 2s 155us/step - loss: 0.1187 - dense_24_loss: 0.0647 - dense_25_loss: 0.0541 - dense_24_acc: 0.9777 - dense_25_acc: 0.9810 - val_loss: 0.2479 - val_dense_24_loss: 0.0908 - val_dense_25_loss: 0.1572 - val_dense_24_acc: 0.9721 - val_dense_25_acc: 0.9559\n",
      "Epoch 22/50\n",
      "10711/10711 [==============================] - 2s 158us/step - loss: 0.1156 - dense_24_loss: 0.0632 - dense_25_loss: 0.0524 - dense_24_acc: 0.9781 - dense_25_acc: 0.9814 - val_loss: 0.2459 - val_dense_24_loss: 0.0913 - val_dense_25_loss: 0.1546 - val_dense_24_acc: 0.9721 - val_dense_25_acc: 0.9556\n",
      "Epoch 23/50\n",
      "10711/10711 [==============================] - 2s 156us/step - loss: 0.1124 - dense_24_loss: 0.0617 - dense_25_loss: 0.0507 - dense_24_acc: 0.9784 - dense_25_acc: 0.9823 - val_loss: 0.2520 - val_dense_24_loss: 0.0919 - val_dense_25_loss: 0.1601 - val_dense_24_acc: 0.9725 - val_dense_25_acc: 0.9552\n",
      "Epoch 24/50\n",
      "10711/10711 [==============================] - 2s 161us/step - loss: 0.1101 - dense_24_loss: 0.0608 - dense_25_loss: 0.0493 - dense_24_acc: 0.9787 - dense_25_acc: 0.9830 - val_loss: 0.2514 - val_dense_24_loss: 0.0909 - val_dense_25_loss: 0.1605 - val_dense_24_acc: 0.9726 - val_dense_25_acc: 0.9559\n",
      "Epoch 25/50\n",
      "10711/10711 [==============================] - 2s 184us/step - loss: 0.1055 - dense_24_loss: 0.0589 - dense_25_loss: 0.0466 - dense_24_acc: 0.9793 - dense_25_acc: 0.9838 - val_loss: 0.2525 - val_dense_24_loss: 0.0916 - val_dense_25_loss: 0.1609 - val_dense_24_acc: 0.9724 - val_dense_25_acc: 0.9547\n",
      "Epoch 26/50\n",
      "10711/10711 [==============================] - 1s 136us/step - loss: 0.1045 - dense_24_loss: 0.0582 - dense_25_loss: 0.0463 - dense_24_acc: 0.9794 - dense_25_acc: 0.9833 - val_loss: 0.2668 - val_dense_24_loss: 0.0926 - val_dense_25_loss: 0.1742 - val_dense_24_acc: 0.9722 - val_dense_25_acc: 0.9544\n",
      "Epoch 27/50\n",
      "10711/10711 [==============================] - 2s 143us/step - loss: 0.1012 - dense_24_loss: 0.0570 - dense_25_loss: 0.0442 - dense_24_acc: 0.9799 - dense_25_acc: 0.9846 - val_loss: 0.2595 - val_dense_24_loss: 0.0924 - val_dense_25_loss: 0.1670 - val_dense_24_acc: 0.9726 - val_dense_25_acc: 0.9545\n",
      "Epoch 28/50\n",
      "10711/10711 [==============================] - 2s 147us/step - loss: 0.0989 - dense_24_loss: 0.0562 - dense_25_loss: 0.0427 - dense_24_acc: 0.9801 - dense_25_acc: 0.9852 - val_loss: 0.2723 - val_dense_24_loss: 0.0930 - val_dense_25_loss: 0.1793 - val_dense_24_acc: 0.9726 - val_dense_25_acc: 0.9551\n",
      "Epoch 29/50\n",
      "10711/10711 [==============================] - 1s 134us/step - loss: 0.0965 - dense_24_loss: 0.0552 - dense_25_loss: 0.0413 - dense_24_acc: 0.9804 - dense_25_acc: 0.9855 - val_loss: 0.2743 - val_dense_24_loss: 0.0934 - val_dense_25_loss: 0.1809 - val_dense_24_acc: 0.9727 - val_dense_25_acc: 0.9553\n",
      "Epoch 30/50\n",
      "10711/10711 [==============================] - 1s 126us/step - loss: 0.0930 - dense_24_loss: 0.0539 - dense_25_loss: 0.0390 - dense_24_acc: 0.9810 - dense_25_acc: 0.9863 - val_loss: 0.2836 - val_dense_24_loss: 0.0947 - val_dense_25_loss: 0.1889 - val_dense_24_acc: 0.9732 - val_dense_25_acc: 0.9552\n",
      "Epoch 31/50\n",
      "10711/10711 [==============================] - 1s 128us/step - loss: 0.0923 - dense_24_loss: 0.0536 - dense_25_loss: 0.0387 - dense_24_acc: 0.9812 - dense_25_acc: 0.9860 - val_loss: 0.2797 - val_dense_24_loss: 0.0955 - val_dense_25_loss: 0.1843 - val_dense_24_acc: 0.9721 - val_dense_25_acc: 0.9543\n",
      "Epoch 32/50\n",
      "10711/10711 [==============================] - 1s 137us/step - loss: 0.0901 - dense_24_loss: 0.0523 - dense_25_loss: 0.0378 - dense_24_acc: 0.9816 - dense_25_acc: 0.9867 - val_loss: 0.2812 - val_dense_24_loss: 0.0945 - val_dense_25_loss: 0.1867 - val_dense_24_acc: 0.9725 - val_dense_25_acc: 0.9546\n",
      "Epoch 33/50\n",
      "10711/10711 [==============================] - 1s 136us/step - loss: 0.0862 - dense_24_loss: 0.0508 - dense_25_loss: 0.0355 - dense_24_acc: 0.9822 - dense_25_acc: 0.9876 - val_loss: 0.2871 - val_dense_24_loss: 0.0963 - val_dense_25_loss: 0.1908 - val_dense_24_acc: 0.9724 - val_dense_25_acc: 0.9541\n",
      "Epoch 34/50\n",
      "10711/10711 [==============================] - 1s 139us/step - loss: 0.0842 - dense_24_loss: 0.0503 - dense_25_loss: 0.0339 - dense_24_acc: 0.9821 - dense_25_acc: 0.9879 - val_loss: 0.3024 - val_dense_24_loss: 0.0975 - val_dense_25_loss: 0.2049 - val_dense_24_acc: 0.9726 - val_dense_25_acc: 0.9558\n",
      "Epoch 35/50\n",
      "10711/10711 [==============================] - 2s 152us/step - loss: 0.0825 - dense_24_loss: 0.0492 - dense_25_loss: 0.0334 - dense_24_acc: 0.9827 - dense_25_acc: 0.9882 - val_loss: 0.2997 - val_dense_24_loss: 0.0976 - val_dense_25_loss: 0.2021 - val_dense_24_acc: 0.9723 - val_dense_25_acc: 0.9537\n",
      "Epoch 36/50\n",
      "10711/10711 [==============================] - 2s 151us/step - loss: 0.0808 - dense_24_loss: 0.0482 - dense_25_loss: 0.0326 - dense_24_acc: 0.9829 - dense_25_acc: 0.9886 - val_loss: 0.2932 - val_dense_24_loss: 0.0972 - val_dense_25_loss: 0.1960 - val_dense_24_acc: 0.9728 - val_dense_25_acc: 0.9540\n",
      "Epoch 37/50\n",
      "10711/10711 [==============================] - 2s 142us/step - loss: 0.0798 - dense_24_loss: 0.0481 - dense_25_loss: 0.0317 - dense_24_acc: 0.9829 - dense_25_acc: 0.9888 - val_loss: 0.3076 - val_dense_24_loss: 0.0986 - val_dense_25_loss: 0.2090 - val_dense_24_acc: 0.9728 - val_dense_25_acc: 0.9555\n",
      "Epoch 38/50\n",
      "10711/10711 [==============================] - 2s 151us/step - loss: 0.0772 - dense_24_loss: 0.0468 - dense_25_loss: 0.0304 - dense_24_acc: 0.9833 - dense_25_acc: 0.9894 - val_loss: 0.3153 - val_dense_24_loss: 0.0989 - val_dense_25_loss: 0.2164 - val_dense_24_acc: 0.9729 - val_dense_25_acc: 0.9544\n",
      "Epoch 39/50\n",
      "10711/10711 [==============================] - 1s 135us/step - loss: 0.0756 - dense_24_loss: 0.0458 - dense_25_loss: 0.0298 - dense_24_acc: 0.9838 - dense_25_acc: 0.9895 - val_loss: 0.3162 - val_dense_24_loss: 0.0996 - val_dense_25_loss: 0.2166 - val_dense_24_acc: 0.9726 - val_dense_25_acc: 0.9531\n",
      "Epoch 40/50\n",
      "10711/10711 [==============================] - 1s 136us/step - loss: 0.0738 - dense_24_loss: 0.0448 - dense_25_loss: 0.0289 - dense_24_acc: 0.9842 - dense_25_acc: 0.9900 - val_loss: 0.3271 - val_dense_24_loss: 0.1010 - val_dense_25_loss: 0.2261 - val_dense_24_acc: 0.9728 - val_dense_25_acc: 0.9550\n",
      "Epoch 41/50\n",
      "10711/10711 [==============================] - 1s 133us/step - loss: 0.0721 - dense_24_loss: 0.0446 - dense_25_loss: 0.0276 - dense_24_acc: 0.9843 - dense_25_acc: 0.9902 - val_loss: 0.3249 - val_dense_24_loss: 0.1010 - val_dense_25_loss: 0.2239 - val_dense_24_acc: 0.9731 - val_dense_25_acc: 0.9544\n",
      "Epoch 42/50\n",
      "10711/10711 [==============================] - 1s 134us/step - loss: 0.0718 - dense_24_loss: 0.0441 - dense_25_loss: 0.0278 - dense_24_acc: 0.9847 - dense_25_acc: 0.9902 - val_loss: 0.3216 - val_dense_24_loss: 0.1007 - val_dense_25_loss: 0.2208 - val_dense_24_acc: 0.9732 - val_dense_25_acc: 0.9543\n",
      "Epoch 43/50\n",
      "10711/10711 [==============================] - 1s 135us/step - loss: 0.0684 - dense_24_loss: 0.0428 - dense_25_loss: 0.0256 - dense_24_acc: 0.9849 - dense_25_acc: 0.9910 - val_loss: 0.3375 - val_dense_24_loss: 0.1032 - val_dense_25_loss: 0.2343 - val_dense_24_acc: 0.9731 - val_dense_25_acc: 0.9552\n",
      "Epoch 44/50\n",
      "10711/10711 [==============================] - 1s 135us/step - loss: 0.0686 - dense_24_loss: 0.0427 - dense_25_loss: 0.0260 - dense_24_acc: 0.9850 - dense_25_acc: 0.9908 - val_loss: 0.3504 - val_dense_24_loss: 0.1038 - val_dense_25_loss: 0.2466 - val_dense_24_acc: 0.9732 - val_dense_25_acc: 0.9562\n",
      "Epoch 45/50\n",
      "10711/10711 [==============================] - 1s 136us/step - loss: 0.0664 - dense_24_loss: 0.0415 - dense_25_loss: 0.0249 - dense_24_acc: 0.9852 - dense_25_acc: 0.9912 - val_loss: 0.3439 - val_dense_24_loss: 0.1049 - val_dense_25_loss: 0.2390 - val_dense_24_acc: 0.9725 - val_dense_25_acc: 0.9532\n",
      "Epoch 46/50\n",
      "10711/10711 [==============================] - 2s 141us/step - loss: 0.0654 - dense_24_loss: 0.0407 - dense_25_loss: 0.0247 - dense_24_acc: 0.9855 - dense_25_acc: 0.9915 - val_loss: 0.3381 - val_dense_24_loss: 0.1040 - val_dense_25_loss: 0.2341 - val_dense_24_acc: 0.9730 - val_dense_25_acc: 0.9548\n",
      "Epoch 47/50\n",
      "10711/10711 [==============================] - 1s 135us/step - loss: 0.0647 - dense_24_loss: 0.0406 - dense_25_loss: 0.0241 - dense_24_acc: 0.9856 - dense_25_acc: 0.9916 - val_loss: 0.3459 - val_dense_24_loss: 0.1054 - val_dense_25_loss: 0.2405 - val_dense_24_acc: 0.9734 - val_dense_25_acc: 0.9544\n",
      "Epoch 48/50\n",
      "10711/10711 [==============================] - 2s 164us/step - loss: 0.0635 - dense_24_loss: 0.0398 - dense_25_loss: 0.0236 - dense_24_acc: 0.9858 - dense_25_acc: 0.9917 - val_loss: 0.3638 - val_dense_24_loss: 0.1082 - val_dense_25_loss: 0.2556 - val_dense_24_acc: 0.9722 - val_dense_25_acc: 0.9530\n",
      "Epoch 49/50\n",
      "10711/10711 [==============================] - 2s 160us/step - loss: 0.0624 - dense_24_loss: 0.0393 - dense_25_loss: 0.0230 - dense_24_acc: 0.9859 - dense_25_acc: 0.9921 - val_loss: 0.3511 - val_dense_24_loss: 0.1059 - val_dense_25_loss: 0.2452 - val_dense_24_acc: 0.9730 - val_dense_25_acc: 0.9544\n",
      "Epoch 50/50\n",
      "10711/10711 [==============================] - 2s 159us/step - loss: 0.0593 - dense_24_loss: 0.0381 - dense_25_loss: 0.0212 - dense_24_acc: 0.9865 - dense_25_acc: 0.9923 - val_loss: 0.3679 - val_dense_24_loss: 0.1085 - val_dense_25_loss: 0.2593 - val_dense_24_acc: 0.9729 - val_dense_25_acc: 0.9543\n",
      "CPU times: user 1min 20s, sys: 15.2 s, total: 1min 35s\n",
      "Wall time: 1min 17s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f16969eac50>"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "mix_model.fit(x_train,[y_train_obj,y_train_act],validation_data=(x_test,[y_test_obj,y_test_act]),batch_size=128,epochs=50,verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 precision    recall  f1-score   support\n",
      "\n",
      "        payment       0.49      0.41      0.44       130\n",
      "        package       0.69      0.53      0.60       346\n",
      "        suspend       0.69      0.55      0.61       152\n",
      "       internet       0.69      0.70      0.69       368\n",
      "   phone_issues       0.56      0.35      0.43       136\n",
      "        service       0.78      0.64      0.71       418\n",
      "    nontruemove       0.43      0.07      0.12        45\n",
      "        balance       0.82      0.66      0.73       282\n",
      "         detail       0.57      0.26      0.36        61\n",
      "           bill       0.47      0.29      0.36        97\n",
      "         credit       0.88      0.36      0.51        39\n",
      "      promotion       0.67      0.52      0.59       237\n",
      " mobile_setting       0.44      0.33      0.38        48\n",
      "       iservice       0.00      0.00      0.00         5\n",
      "        roaming       0.74      0.52      0.61        50\n",
      "      truemoney       0.89      0.77      0.83        44\n",
      "    information       0.80      0.29      0.43        69\n",
      "    lost_stolen       0.88      0.37      0.52        57\n",
      "balance_minutes       0.00      0.00      0.00        11\n",
      "            idd       0.75      0.51      0.61        41\n",
      "        garbage       0.00      0.00      0.00         7\n",
      "       ringtone       0.75      0.20      0.32        15\n",
      "           rate       0.00      0.00      0.00        11\n",
      "   loyalty_card       0.12      0.17      0.14         6\n",
      "        contact       0.00      0.00      0.00         0\n",
      "        officer       0.00      0.00      0.00         3\n",
      "\n",
      "      micro avg       0.70      0.52      0.60      2678\n",
      "      macro avg       0.50      0.33      0.38      2678\n",
      "   weighted avg       0.68      0.52      0.59      2678\n",
      "    samples avg       0.51      0.52      0.52      2678\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     enquire       0.85      0.90      0.87      1686\n",
      "      report       0.75      0.58      0.66       327\n",
      "      cancel       0.91      0.86      0.88       222\n",
      "         buy       0.74      0.56      0.64       154\n",
      "    activate       0.66      0.61      0.63       107\n",
      "     request       0.83      0.29      0.43        70\n",
      "     garbage       0.00      0.00      0.00         7\n",
      "      change       0.76      0.68      0.71       105\n",
      "\n",
      "   micro avg       0.83      0.80      0.81      2678\n",
      "   macro avg       0.69      0.56      0.60      2678\n",
      "weighted avg       0.82      0.80      0.81      2678\n",
      " samples avg       0.79      0.80      0.80      2678\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_pred1,y_pred2 = mix_model.predict(x_test)\n",
    "y_pred1 = (y_pred1 > 0.5)\n",
    "y_pred2 = (y_pred2 > 0.5)\n",
    "print(classification_report(y_test_obj,y_pred1,target_names=data_df.clean_label_obj.unique()))\n",
    "print(classification_report(y_test_act,y_pred2,target_names=data_df.clean_label_act.unique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
