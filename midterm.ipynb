{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "from pythainlp.tokenize import word_tokenize\n",
    "from keras.utils import to_categorical\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "import torch.optim as optim\n",
    "from sklearn.metrics import accuracy_score\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((24345,), (24345,))"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f = open(\"./train.txt\", \"r\")\n",
    "x_train = np.array([word_tokenize(line.strip(),'newmm') for line in f.readlines()])\n",
    "f.close()\n",
    "f = open(\"./train_label.txt\", \"r\")\n",
    "y_train = pd.Series([line.strip() for line in f.readlines()])\n",
    "f.close()\n",
    "x_train.shape,y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['10',\n",
       "  ' ',\n",
       "  'ประโยชน์',\n",
       "  'ของ',\n",
       "  'ฮับ',\n",
       "  'มะกอก',\n",
       "  ' ',\n",
       "  'เกรด',\n",
       "  ' ',\n",
       "  'A',\n",
       "  ' ',\n",
       "  'จาก',\n",
       "  'ตุรกี',\n",
       "  ' ',\n",
       "  '1.',\n",
       "  ' ',\n",
       "  'ช่วย',\n",
       "  'รักษา',\n",
       "  'โรคเบาหวาน',\n",
       "  'และ',\n",
       "  'ความดัน',\n",
       "  ' ',\n",
       "  '2.',\n",
       "  ' ',\n",
       "  'ช่วย',\n",
       "  'ป้องกัน',\n",
       "  ' ',\n",
       "  'และ',\n",
       "  'รักษา',\n",
       "  'โรคหัวใจ',\n",
       "  ' ',\n",
       "  '3.',\n",
       "  ' ',\n",
       "  'ช่วย',\n",
       "  'ป้องกัน',\n",
       "  ' ',\n",
       "  'และ',\n",
       "  'รักษา',\n",
       "  'โรคมะเร็ง',\n",
       "  ' ',\n",
       "  '4.',\n",
       "  ' ',\n",
       "  'ช่วย',\n",
       "  'บำรุง',\n",
       "  'ผิวพรรณ',\n",
       "  'แบบ',\n",
       "  ' ',\n",
       "  'Inside-Out',\n",
       "  ' ',\n",
       "  '5.',\n",
       "  ' ',\n",
       "  'ช่วย',\n",
       "  'บำรุง',\n",
       "  'สมอง',\n",
       "  ' ',\n",
       "  'และ',\n",
       "  'ป้องกัน',\n",
       "  'โรค',\n",
       "  'อัลไซเมอร์',\n",
       "  ' ',\n",
       "  '6.',\n",
       "  ' ',\n",
       "  'ช่วย',\n",
       "  'ละลาย',\n",
       "  'ไขมัน',\n",
       "  'ใน',\n",
       "  'ร่างกาย',\n",
       "  ' ',\n",
       "  '7.',\n",
       "  ' ',\n",
       "  'ช่วย',\n",
       "  'กำจัด',\n",
       "  'แบคทีเรีย',\n",
       "  'และ',\n",
       "  'เชื้อรา',\n",
       "  'ใน',\n",
       "  'ร่างกาย',\n",
       "  ' ',\n",
       "  '8.',\n",
       "  ' ',\n",
       "  'ช่วย',\n",
       "  'รักษาโรค',\n",
       "  'ใน',\n",
       "  'ท้อง',\n",
       "  ' ',\n",
       "  'เช่น',\n",
       "  'ท้องเสีย',\n",
       "  ' ',\n",
       "  'หรือ',\n",
       "  'อาหาร',\n",
       "  'เป็นพิษ',\n",
       "  ' ',\n",
       "  '9.',\n",
       "  ' ',\n",
       "  'ช่วย',\n",
       "  'บรรเทา',\n",
       "  'อาการ',\n",
       "  'ปวดเมื่อย',\n",
       "  ' ',\n",
       "  'และ',\n",
       "  'รักษา',\n",
       "  'โรคเหน็บชา',\n",
       "  ' ',\n",
       "  '10.',\n",
       "  ' ',\n",
       "  'ช่วย',\n",
       "  'รักษา',\n",
       "  'อาการ',\n",
       "  'ภูมิแพ้',\n",
       "  ' ',\n",
       "  'และ',\n",
       "  'โรค',\n",
       "  'ไซนัส'],\n",
       " 'neu')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train[0],y_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['neu', 'neg', 'pos', 'q']\n",
      "[0, 1, 0]\n"
     ]
    }
   ],
   "source": [
    "label=list(pd.factorize(y_train)[1])\n",
    "#y_train = to_categorical(pd.factorize(y_train)[0])\n",
    "print(label)\n",
    "y_train=[label.index(i) for i in y_train]\n",
    "print(y_train[:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "749"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ind2word = dict()\n",
    "word2ind = dict()\n",
    "word2ind['UNK'] = 0\n",
    "ind = 1\n",
    "for ss in x_train:\n",
    "    for word in ss:\n",
    "        if word not in word2ind:\n",
    "            ind2word[ind] = word\n",
    "            word2ind[word] = ind\n",
    "            ind+= 1\n",
    "max_len = max([len(i) for i in x_train])\n",
    "max_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(24345, 2)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_=[]\n",
    "for x,y in zip(x_train,y_train):\n",
    "    tmp =[word2ind[word] for word in x]\n",
    "    if len(tmp) < max_len:\n",
    "        tmp +=[0]*(max_len-len(tmp))\n",
    "    data_.append([tmp,y])\n",
    "data_=np.array(data_)\n",
    "#np.random.shuffle(data_)\n",
    "data_.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "neu: 14243 neg: 5713 pos: 3917 q: 472\n"
     ]
    }
   ],
   "source": [
    "del tmp\n",
    "tmp = dict({label[0]:[],label[1]:[],label[2]:[],label[3]:[]})\n",
    "for i in data_:\n",
    "    if i[1]==0:\n",
    "        tmp[label[0]].append(i)\n",
    "    elif i[1]==1:\n",
    "        tmp[label[1]].append(i)\n",
    "    elif i[1]==2:\n",
    "        tmp[label[2]].append(i)\n",
    "    elif i[1]==3:\n",
    "        tmp[label[3]].append(i)\n",
    "print(label[0]+':',len(tmp[label[0]]),label[1]+':',len(tmp[label[1]]),label[2]+':',len(tmp[label[2]]),label[3]+':',len(tmp[label[3]]))"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "np.random.shuffle(tmp[label[0]])\n",
    "np.random.shuffle(tmp[label[1]])\n",
    "np.random.shuffle(tmp[label[2]])\n",
    "np.random.shuffle(tmp[label[3]])\n",
    "min_data = min([len(tmp[label[i]]) for i in range(len(label))])\n",
    "data = tmp[label[0]][:min_data]+tmp[label[1]][:min_data]+tmp[label[2]][:min_data]+tmp[label[3]][:min_data]\n",
    "data = np.array(data)\n",
    "print(data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Net(\n",
      "  (embeddings): Embedding(31207, 32)\n",
      "  (conv1): Conv1d(749, 10, kernel_size=(2,), stride=(1,))\n",
      "  (gru1): GRU(7, 10, num_layers=3)\n",
      "  (fc1): Linear(in_features=100, out_features=50, bias=True)\n",
      "  (fc2): Linear(in_features=50, out_features=4, bias=True)\n",
      "  (fc3): Softmax()\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "class Net(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        # 1 input image channel, 6 output channels, 5x5 square convolution\n",
    "        # kernel\n",
    "        self.embeddings = nn.Embedding(len(ind2word)+1,32)\n",
    "        self.conv1 = nn.Conv1d(max_len,10, 2)\n",
    "        self.gru1 = nn.GRU(7,10,3)\n",
    "        self.fc1 = nn.Linear(10*10 ,50)\n",
    "        self.fc2 = nn.Linear(50, len(label))\n",
    "        self.fc3 = nn.Softmax()\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Max pooling over a (2, 2) window\n",
    "        embed = self.embeddings(x)\n",
    "        x = F.dropout(F.max_pool1d(F.relu(self.conv1(embed)), 4),p=0.5)\n",
    "        # If the size is a square you can only specify a single number\n",
    "        x,_ = self.gru1(x)\n",
    "        x = x.view(-1, self.num_flat_features(x))\n",
    "        x = F.dropout(F.relu(self.fc1(x)),p=0.3)\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = F.softmax(x)\n",
    "        return x\n",
    "\n",
    "    def num_flat_features(self, x):\n",
    "        size = x.size()[1:]  # all dimensions except the batch dimension\n",
    "        num_features = 1\n",
    "        for s in size:\n",
    "            num_features *= s\n",
    "        return num_features\n",
    "\n",
    "\n",
    "net = Net()\n",
    "#net = net.to(device)\n",
    "print(net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([24345, 749])\n",
      "tensor([[0.2394, 0.2394, 0.2770, 0.2442],\n",
      "        [0.2446, 0.2443, 0.2636, 0.2475],\n",
      "        [0.2453, 0.2380, 0.2675, 0.2492],\n",
      "        ...,\n",
      "        [0.2499, 0.2450, 0.2601, 0.2450],\n",
      "        [0.2558, 0.2422, 0.2577, 0.2443],\n",
      "        [0.2590, 0.2466, 0.2536, 0.2408]], grad_fn=<SoftmaxBackward>)\n",
      "torch.Size([24345]) torch.Size([24345, 4]) torch.Size([24345, 749])\n",
      "tensor(1.3866, grad_fn=<NllLossBackward>) torch.Size([24345]) torch.Size([24345, 749])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kok/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:23: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
     ]
    }
   ],
   "source": [
    "input= torch.tensor(list(data[:,0]))\n",
    "print(input.shape)\n",
    "output = net(input)\n",
    "print(output)\n",
    "target =torch.tensor(list(data[:,1])).long()\n",
    "#target = target.view(1, -1)  # make it the same shape as output\n",
    "weight=torch.tensor([1/len(tmp[label[0]]),1/len(tmp[label[1]]),1/len(tmp[label[2]]),1/len(tmp[label[3]])])\n",
    "criterion = nn.CrossEntropyLoss(weight=weight)\n",
    "print(target.shape,output.shape,input.shape)\n",
    "loss = criterion(output, target)\n",
    "print(loss,target.shape,input.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "conv1.bias.grad before backward\n",
      "None\n",
      "conv1.bias.grad after backward\n",
      "tensor([-4.0526e-06,  2.1001e-05,  2.3641e-05,  1.1044e-05, -3.6718e-05,\n",
      "         1.7018e-05, -8.2706e-06,  2.1105e-06,  1.3785e-05,  3.0937e-05])\n"
     ]
    }
   ],
   "source": [
    "net.zero_grad()     # zeroes the gradient buffers of all parameters\n",
    "#out.backward(torch.randn(len(x_train), len(y_train[0])))\n",
    "print('conv1.bias.grad before backward')\n",
    "print(net.conv1.bias.grad)\n",
    "\n",
    "loss.backward()\n",
    "\n",
    "print('conv1.bias.grad after backward')\n",
    "print(net.conv1.bias.grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kok/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:23: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
     ]
    }
   ],
   "source": [
    "# create your optimizer\n",
    "optimizer = optim.Adam(net.parameters(), lr=0.01)\n",
    "\n",
    "# in your training loop:\n",
    "optimizer.zero_grad()   # zero the gradient buffers\n",
    "output = net(input)\n",
    "loss = criterion(output, target)\n",
    "loss.backward()\n",
    "optimizer.step()    # Does the update"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def aroundResult(out):\n",
    "    y_pred=[]\n",
    "    for i in output:\n",
    "        mx = max(i)\n",
    "        y_pred = y_pred+[list(i).index(mx)]\n",
    "    #y_pred = np.array(y_pred)\n",
    "    return y_pred\n",
    "y_pred = aroundResult(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1.3867, grad_fn=<NllLossBackward>)\n",
      "0.275374820291641\n"
     ]
    }
   ],
   "source": [
    "y_true = list(data[:len(y_pred),1])\n",
    "print(loss)\n",
    "print(accuracy_score(y_pred,y_true))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2, 2, 2, 2, 2, 3, 2, 2, 0, 3, 3, 2, 0, 0, 2, 0, 2, 2, 2, 2] \n",
      " [0, 1, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 1, 2, 3, 1, 0, 0]\n"
     ]
    }
   ],
   "source": [
    "print(y_pred[:20],'\\n',y_true[:20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kok/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:23: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1.3867, grad_fn=<NllLossBackward>)\n",
      "0.475374820291641\n",
      "tensor(1.3866, grad_fn=<NllLossBackward>)\n",
      "0.3886218936126515\n",
      "tensor(1.3864, grad_fn=<NllLossBackward>)\n",
      "0.1318956664612857\n",
      "tensor(1.3870, grad_fn=<NllLossBackward>)\n",
      "0.049003902238652704\n",
      "tensor(1.3864, grad_fn=<NllLossBackward>)\n",
      "0.2831792975970425\n",
      "tensor(1.3864, grad_fn=<NllLossBackward>)\n",
      "0.5101663585951941\n",
      "tensor(1.3864, grad_fn=<NllLossBackward>)\n",
      "0.5272951324707332\n",
      "tensor(1.3865, grad_fn=<NllLossBackward>)\n",
      "0.5132470733210105\n",
      "tensor(1.3864, grad_fn=<NllLossBackward>)\n",
      "0.5247484082973917\n",
      "tensor(1.3865, grad_fn=<NllLossBackward>)\n",
      "0.5055658246046416\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(10):  # loop over the dataset multiple times\n",
    "    optimizer.zero_grad()   # zero the gradient buffers\n",
    "    output = net(input)\n",
    "    loss = criterion(output, target)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    print(loss)\n",
    "    y_pred = aroundResult(output)\n",
    "    y_true=list(data[:len(y_pred),1])\n",
    "    print(accuracy_score(y_pred,y_true))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kok/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:23: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5116040254672417\n",
      "20517 1746 227 1855\n",
      "14243 5713 3917 472\n"
     ]
    }
   ],
   "source": [
    "output = net( torch.tensor(list(data_[:,0])))\n",
    "y_pred = aroundResult(output)\n",
    "y_true = list(data_[:,1])\n",
    "print(accuracy_score(y_pred,y_true))\n",
    "print(y_pred.count(0),y_pred.count(1),y_pred.count(2),y_pred.count(3))\n",
    "print(y_true.count(0),y_true.count(1),y_true.count(2),y_true.count(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#rnn = nn.GRU(10, 20, 2)\n",
    "#torch.randn(5, 3, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open(\"./test.txt\", \"r\")\n",
    "x_test = np.array([word_tokenize(line.strip(),'newmm') for line in f.readlines()])\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kok/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:23: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
     ]
    }
   ],
   "source": [
    "test_data=[]\n",
    "for x in x_test:\n",
    "    tmp =[word2ind[word] if word in word2ind else word2ind['UNK'] for word in x]\n",
    "    if len(tmp) < max_len:\n",
    "        tmp +=[0]*(max_len-len(tmp))\n",
    "    test_data.append(tmp)\n",
    "output = net( torch.tensor(test_data))\n",
    "y_pred=[]\n",
    "for i in output:\n",
    "    mx = max(i)\n",
    "    y_pred.append(label[list(i).index(mx)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['neu', 'neu', 'neu', 'neu', 'neu', 'neu', 'neu', 'q', 'neu', 'neu']"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "with open('file.csv', mode='w') as file:\n",
    "    writer = csv.writer(file, delimiter=',', quotechar='\"', quoting=csv.QUOTE_MINIMAL)\n",
    "    writer.writerow(['Id','Class'])\n",
    "    [writer.writerow([i+1,j]) for i,j in enumerate(y_pred)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "read = pd.read_csv('file.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>neu</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>neu</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>neu</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>neu</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>neu</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>neu</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>neu</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>q</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>neu</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>neu</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>11</td>\n",
       "      <td>neg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>12</td>\n",
       "      <td>neu</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>13</td>\n",
       "      <td>neu</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>14</td>\n",
       "      <td>neu</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>15</td>\n",
       "      <td>neu</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>16</td>\n",
       "      <td>neu</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>17</td>\n",
       "      <td>neu</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>18</td>\n",
       "      <td>q</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>19</td>\n",
       "      <td>neu</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>20</td>\n",
       "      <td>neg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>21</td>\n",
       "      <td>q</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>22</td>\n",
       "      <td>neu</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>23</td>\n",
       "      <td>neu</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>24</td>\n",
       "      <td>neu</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>25</td>\n",
       "      <td>neu</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>26</td>\n",
       "      <td>neu</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>27</td>\n",
       "      <td>neu</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>28</td>\n",
       "      <td>neu</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>29</td>\n",
       "      <td>neu</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>30</td>\n",
       "      <td>neu</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3916</th>\n",
       "      <td>3917</td>\n",
       "      <td>neg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3917</th>\n",
       "      <td>3918</td>\n",
       "      <td>neu</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3918</th>\n",
       "      <td>3919</td>\n",
       "      <td>neu</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3919</th>\n",
       "      <td>3920</td>\n",
       "      <td>neu</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3920</th>\n",
       "      <td>3921</td>\n",
       "      <td>neu</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3921</th>\n",
       "      <td>3922</td>\n",
       "      <td>neu</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3922</th>\n",
       "      <td>3923</td>\n",
       "      <td>neu</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3923</th>\n",
       "      <td>3924</td>\n",
       "      <td>neu</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3924</th>\n",
       "      <td>3925</td>\n",
       "      <td>neu</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3925</th>\n",
       "      <td>3926</td>\n",
       "      <td>neu</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3926</th>\n",
       "      <td>3927</td>\n",
       "      <td>neu</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3927</th>\n",
       "      <td>3928</td>\n",
       "      <td>neu</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3928</th>\n",
       "      <td>3929</td>\n",
       "      <td>neu</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3929</th>\n",
       "      <td>3930</td>\n",
       "      <td>neu</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3930</th>\n",
       "      <td>3931</td>\n",
       "      <td>neu</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3931</th>\n",
       "      <td>3932</td>\n",
       "      <td>neg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3932</th>\n",
       "      <td>3933</td>\n",
       "      <td>neu</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3933</th>\n",
       "      <td>3934</td>\n",
       "      <td>neu</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3934</th>\n",
       "      <td>3935</td>\n",
       "      <td>neu</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3935</th>\n",
       "      <td>3936</td>\n",
       "      <td>neu</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3936</th>\n",
       "      <td>3937</td>\n",
       "      <td>neu</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3937</th>\n",
       "      <td>3938</td>\n",
       "      <td>neu</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3938</th>\n",
       "      <td>3939</td>\n",
       "      <td>neu</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3939</th>\n",
       "      <td>3940</td>\n",
       "      <td>neu</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3940</th>\n",
       "      <td>3941</td>\n",
       "      <td>q</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3941</th>\n",
       "      <td>3942</td>\n",
       "      <td>neu</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3942</th>\n",
       "      <td>3943</td>\n",
       "      <td>neu</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3943</th>\n",
       "      <td>3944</td>\n",
       "      <td>neu</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3944</th>\n",
       "      <td>3945</td>\n",
       "      <td>neu</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3945</th>\n",
       "      <td>3946</td>\n",
       "      <td>neu</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3946 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Id Class\n",
       "0        1   neu\n",
       "1        2   neu\n",
       "2        3   neu\n",
       "3        4   neu\n",
       "4        5   neu\n",
       "5        6   neu\n",
       "6        7   neu\n",
       "7        8     q\n",
       "8        9   neu\n",
       "9       10   neu\n",
       "10      11   neg\n",
       "11      12   neu\n",
       "12      13   neu\n",
       "13      14   neu\n",
       "14      15   neu\n",
       "15      16   neu\n",
       "16      17   neu\n",
       "17      18     q\n",
       "18      19   neu\n",
       "19      20   neg\n",
       "20      21     q\n",
       "21      22   neu\n",
       "22      23   neu\n",
       "23      24   neu\n",
       "24      25   neu\n",
       "25      26   neu\n",
       "26      27   neu\n",
       "27      28   neu\n",
       "28      29   neu\n",
       "29      30   neu\n",
       "...    ...   ...\n",
       "3916  3917   neg\n",
       "3917  3918   neu\n",
       "3918  3919   neu\n",
       "3919  3920   neu\n",
       "3920  3921   neu\n",
       "3921  3922   neu\n",
       "3922  3923   neu\n",
       "3923  3924   neu\n",
       "3924  3925   neu\n",
       "3925  3926   neu\n",
       "3926  3927   neu\n",
       "3927  3928   neu\n",
       "3928  3929   neu\n",
       "3929  3930   neu\n",
       "3930  3931   neu\n",
       "3931  3932   neg\n",
       "3932  3933   neu\n",
       "3933  3934   neu\n",
       "3934  3935   neu\n",
       "3935  3936   neu\n",
       "3936  3937   neu\n",
       "3937  3938   neu\n",
       "3938  3939   neu\n",
       "3939  3940   neu\n",
       "3940  3941     q\n",
       "3941  3942   neu\n",
       "3942  3943   neu\n",
       "3943  3944   neu\n",
       "3944  3945   neu\n",
       "3945  3946   neu\n",
       "\n",
       "[3946 rows x 2 columns]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "read"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.0675, -0.0730,  0.5266,  ...,  0.3738, -0.2293, -0.6310],\n",
      "        [ 0.7282,  0.3335,  0.6140,  ..., -0.3985, -1.2357,  2.4647],\n",
      "        [ 0.8003,  1.0186, -0.3347,  ...,  1.0051, -0.0489, -0.8657],\n",
      "        ...,\n",
      "        [ 0.7255, -0.7106,  1.2964,  ..., -1.2586,  1.2612,  0.4618],\n",
      "        [ 1.0606,  0.8302, -0.1485,  ...,  0.1834, -0.0694,  0.2561],\n",
      "        [-1.2713,  0.1460, -0.6519,  ..., -1.2410,  0.9144,  0.8616]])\n",
      "tensor([117,  17,  54, 107,  56,  17,  40,  94,  74,  35])\n",
      "torch.Size([10, 120]) torch.Size([10])\n"
     ]
    }
   ],
   "source": [
    "output = Variable(torch.randn(10, 120).float())\n",
    "target = Variable(torch.FloatTensor(10).uniform_(0, 120).long())\n",
    "print(output)\n",
    "print(target)\n",
    "print(output.shape,target.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
