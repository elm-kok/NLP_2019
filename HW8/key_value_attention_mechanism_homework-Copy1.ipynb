{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Key-Value Attention Mechanism Homework on Keras: Character-level Machine Translation (Many-to-Many, encoder-decoder)\n",
    "\n",
    "In this homework, you will create an MT model with key-value attention mechnism that coverts names of constituency MP candidates in the 2019 Thai general election from Thai script to Roman(Latin) script. E.g. นิยม-->niyom "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.layers import Bidirectional, Concatenate, Permute, Dot, Input, LSTM, Multiply\n",
    "from keras.layers import RepeatVector, Dense, Activation, Lambda\n",
    "from keras.optimizers import Adam\n",
    "from keras.utils import to_categorical\n",
    "from keras.models import load_model, Model\n",
    "import keras.backend as K\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Dataset\n",
    "We have generated a toy dataset using names of constituency MP candidates in 2019 Thai General Election from elect.in.th's github(https://github.com/codeforthailand/dataset-election-62-candidates) and tltk (https://pypi.org/project/tltk/) library to convert them into Roman script.\n",
    "\n",
    "<img src=\"https://raw.githubusercontent.com/ekapolc/nlp_2019/master/HW8/images/dataset_diagram.png\" alt=\"Drawing\" style=\"width: 500px;\"/>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "with open('mp_name_th_en.csv') as csvfile:\n",
    "    readCSV = csv.reader(csvfile, delimiter=',')\n",
    "    name_th = []\n",
    "    name_en = []\n",
    "    for row in readCSV:\n",
    "        name_th.append(row[0])\n",
    "        name_en.append(row[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ไกรสีห์ kraisi\n",
      "พัชรี phatri\n",
      "ธีระ thira\n",
      "วุฒิกร wutthikon\n",
      "ไสว sawai\n",
      "สัมภาษณ์  samphat\n",
      "วศิน wasin\n",
      "ทินวัฒน์ thinwat\n",
      "ศักดินัย sakdinai\n",
      "สุรศักดิ์ surasak\n"
     ]
    }
   ],
   "source": [
    "for th, en in zip(name_th[:10],name_en[:10]):\n",
    "    print(th,en)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task1: Preprocess dataset for Keras (1 point)\n",
    "* 2 dictionaries for indexing (1 for input and another for output)\n",
    "* DON'T FORGET TO INCLUDE special token for padding\n",
    "* DON'T FORGET TO INCLUDE special token for the end of word symbol (output)\n",
    "* Be mindful of your pad_sequences \"padding\" hyperparameter. Choose wisely (post-padding vs pre-padding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data size: 10887\n",
      "Vocab size: 66\n",
      "Max input lenght: 20 \n",
      "\n",
      "Output vocab size: 24\n",
      "Max output lenght: 19 \n",
      "\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 1 2 3 4 5 4] kraisi\n",
      "[[1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "{0: '<PAD>', 1: 'k', 2: 'r', 3: 'a', 4: 'i', 5: 's', 6: 'p', 7: 'h', 8: 't', 9: 'w', 10: 'u', 11: 'o', 12: 'n', 13: 'm', 14: 'd', 15: 'e', 16: 'c', 17: 'l', 18: 'g', 19: 'y', 20: 'b', 21: 'f', 22: '-'}\n",
      "(10887, 20, 66) (10887, 19, 24)\n"
     ]
    }
   ],
   "source": [
    "#FILL YOUR CODE HERE\n",
    "input_dict = dict()\n",
    "output_dict = dict()\n",
    "input_dict['<PAD>'] = 0\n",
    "output_dict['<PAD>'] = 0\n",
    "\n",
    "rev_input = dict()\n",
    "rev_output = dict()\n",
    "\n",
    "for word in name_th:\n",
    "    for char in word:\n",
    "        if char not in input_dict:\n",
    "            input_dict[char] = len(input_dict)\n",
    "\n",
    "for word in name_en:\n",
    "    for char in word:\n",
    "        if char not in output_dict:\n",
    "            output_dict[char] = len(output_dict)\n",
    "\n",
    "for char in input_dict:\n",
    "    rev_input[input_dict[char]] = char\n",
    "for char in output_dict:\n",
    "    rev_output[output_dict[char]] = char\n",
    "    \n",
    "data_size, vocab_size = len(name_th), len(input_dict)+1 \n",
    "output_vocab_size = len(output_dict)+1\n",
    "input_word2char = []\n",
    "output_word2char = []\n",
    "for word in name_th:\n",
    "    input_word2char.append([w for w in word])\n",
    "for word in name_en:\n",
    "    output_word2char.append([w for w in word])\n",
    "max_len = max([len(i) for i in input_word2char])\n",
    "output_max_len = max([len(i) for i in output_word2char])\n",
    "print('Data size:',data_size)\n",
    "print('Vocab size:',vocab_size)\n",
    "print('Max input lenght:',max_len,'\\n')\n",
    "print('Output vocab size:',output_vocab_size)\n",
    "print('Max output lenght:',output_max_len,'\\n')\n",
    "\n",
    "X = []\n",
    "for word in name_th:\n",
    "    tmp = []\n",
    "    for char in word:\n",
    "        tmp.append(input_dict[char])\n",
    "    X.append(tmp)\n",
    "Y = []\n",
    "for word in name_en:\n",
    "    tmp = []\n",
    "    for char in word:\n",
    "        tmp.append(output_dict[char])\n",
    "    Y.append(tmp)\n",
    "X = pad_sequences(X,maxlen=max_len)\n",
    "Y = pad_sequences(Y,maxlen=output_max_len)\n",
    "\n",
    "print(Y[0],name_en[0])\n",
    "\n",
    "X= to_categorical(X,vocab_size)\n",
    "X=X.reshape(data_size,max_len ,vocab_size)\n",
    "\n",
    "Y= to_categorical(Y,output_vocab_size)\n",
    "Y=Y.reshape(data_size,output_max_len ,output_vocab_size)\n",
    "\n",
    "print(Y[0][-8:])\n",
    "print(rev_output)\n",
    "print(X.shape,Y.shape)\n",
    "\n",
    "m=data_size\n",
    "Tx=max_len\n",
    "Ty=output_max_len"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Attention Mechanism\n",
    "## Task 2: Code your own (key-value) attention mechnism (1 point)\n",
    "* PLEASE READ: you DO NOT have to follow all the details in (Daniluk, et al. 2017). You just need to create a key-value attention mechanism where the \"key\" part of the mechanism is used for attention score calculation, and the \"value\" part of the mechanism is used to encode information to create a context vector.  \n",
    "* Define global variables\n",
    "* fill code for one_step_attention function\n",
    "* Hint: use keras.layers.Lambda \n",
    "* HINT: you will probably need more hidden dimmensions than what you've seen in the demo\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.activations import softmax\n",
    "from keras.layers import Lambda\n",
    "def softMaxAxis1(x):\n",
    "    return softmax(x,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#These are global variables (shared layers)\n",
    "## Fill your code here\n",
    "repeator = RepeatVector(Tx)\n",
    "concatenator = Concatenate(axis=-1)\n",
    "#Attention function###\n",
    "fattn_1 = Dense(100, activation = \"tanh\")\n",
    "fattn_2 = Dense(1, activation = \"relu\")\n",
    "###\n",
    "activator = Activation(softMaxAxis1, name='attention_scores') \n",
    "dotor = Dot(axes = 1)\n",
    "## you are allowed to use code in the demo as your template.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_step_attention(a, s_prev):\n",
    "\n",
    "    #Fill code here\n",
    "    # Repeat the decoder hidden state to concat with encoder hidden states\n",
    "    #key, con = tf.split(a,2,1)\n",
    "    key = Lambda(lambda x: x[:,:,:128])(a)\n",
    "    con = Lambda(lambda x: x[:,:,128:])(a)\n",
    "    #s_prev = repeator(s_prev)\n",
    "    #concat = concatenator([key,s_prev])\n",
    "    concat = key\n",
    "    # attention function\n",
    "    e = fattn_1(concat)\n",
    "    energies =fattn_2(e)\n",
    "    # calculate attention_scores (softmax)\n",
    "    attention_scores = activator(energies)\n",
    "    #calculate a context vector\n",
    "    context = dotor([attention_scores,con])\n",
    "    return context"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task3: Create and train your encoder/decoder model here (1 point)\n",
    "* HINT: you will probably need more hidden dimmensions than what you've seen in the demo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#FILL CODE HERE\n",
    "n_h = 128 #hidden dimensions for encoder \n",
    "n_s = 128 #hidden dimensions for decoder\n",
    "decoder_LSTM_cell = LSTM(n_s, return_state = True) #decoder_LSTM_cell\n",
    "output_layer = Dense(output_vocab_size, activation=\"softmax\") #softmax output layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#FIT YOUR MODEL HERE\n",
    "def model(Tx, Ty, n_h, n_s, vocab_size, machine_vocab_size):\n",
    "    \"\"\"\n",
    "    Arguments:\n",
    "    Tx -- length of the input sequence\n",
    "    Ty -- length of the output sequence\n",
    "    n_h -- hidden state size of the Bi-LSTM\n",
    "    n_s -- hidden state size of the post-attention LSTM\n",
    "    vocab_size -- size of the input vocab\n",
    "    output_vocab_size -- size of the output vocab\n",
    "\n",
    "    Returns:\n",
    "    model -- Keras model instance\n",
    "    \"\"\"\n",
    "    \n",
    "    # Define the input of your model\n",
    "    X = Input(shape=(Tx, vocab_size))\n",
    "    # Define hidden state and cell state for decoder_LSTM_Cell\n",
    "    s0 = Input(shape=(n_s,), name='s0')\n",
    "    c0 = Input(shape=(n_s,), name='c0')\n",
    "    s = s0\n",
    "    c = c0\n",
    "    \n",
    "    # Initialize empty list of outputs\n",
    "    outputs = list()\n",
    "\n",
    "    #Encoder Bi-LSTM\n",
    "    h = Bidirectional(LSTM(n_h, return_sequences=True),input_shape=(m, Tx, n_h*2))(X)\n",
    "  \n",
    "    #Iterate for Ty steps (Decoding)\n",
    "    for t in range(Ty):\n",
    "    \n",
    "        #Perform one step of the attention mechanism to calculate the context vector at timestep t\n",
    "        context = one_step_attention(h, s)\n",
    "       \n",
    "        # Feed the context vector to the decoder LSTM cell\n",
    "        s, _, c = decoder_LSTM_cell(context,initial_state=[s,c])\n",
    "           \n",
    "        # Pass the decoder hidden output to the output layer (softmax)\n",
    "        out = output_layer(s)\n",
    "        \n",
    "        # Append an output list with the current output\n",
    "        outputs.append(out)\n",
    "    \n",
    "    #Create model instance\n",
    "    model = Model(inputs=[X,s0,c0],outputs=outputs)\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model = model(Tx, Ty, n_h, n_s, vocab_size, output_vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt = Adam(lr= 0.01, decay = 0.01)\n",
    "model.compile(loss='categorical_crossentropy',optimizer=opt,metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "s0 = np.zeros((m, n_s))\n",
    "c0 = np.zeros((m, n_s))\n",
    "outputs = list(Y.swapaxes(0,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "10887/10887 [==============================] - 31s 3ms/step - loss: 25.6777 - dense_3_loss: 2.7033 - dense_3_acc: 0.9889 - dense_3_acc_1: 0.9888 - dense_3_acc_2: 0.9881 - dense_3_acc_3: 0.9871 - dense_3_acc_4: 0.9858 - dense_3_acc_5: 0.9815 - dense_3_acc_6: 0.9738 - dense_3_acc_7: 0.9561 - dense_3_acc_8: 0.9202 - dense_3_acc_9: 0.8482 - dense_3_acc_10: 0.7386 - dense_3_acc_11: 0.5888 - dense_3_acc_12: 0.3829 - dense_3_acc_13: 0.2215 - dense_3_acc_14: 0.1341 - dense_3_acc_15: 0.1347 - dense_3_acc_16: 0.0414 - dense_3_acc_17: 0.2105 - dense_3_acc_18: 0.0856\n",
      "Epoch 2/100\n",
      "10887/10887 [==============================] - 13s 1ms/step - loss: 20.2941 - dense_3_loss: 2.2095 - dense_3_acc: 0.9998 - dense_3_acc_1: 0.9997 - dense_3_acc_2: 0.9990 - dense_3_acc_3: 0.9981 - dense_3_acc_4: 0.9967 - dense_3_acc_5: 0.9926 - dense_3_acc_6: 0.9844 - dense_3_acc_7: 0.9663 - dense_3_acc_8: 0.9360 - dense_3_acc_9: 0.8714 - dense_3_acc_10: 0.7715 - dense_3_acc_11: 0.6270 - dense_3_acc_12: 0.4353 - dense_3_acc_13: 0.2836 - dense_3_acc_14: 0.2039 - dense_3_acc_15: 0.2259 - dense_3_acc_16: 0.0766 - dense_3_acc_17: 0.3226 - dense_3_acc_18: 0.2127\n",
      "Epoch 3/100\n",
      "10887/10887 [==============================] - 13s 1ms/step - loss: 19.3011 - dense_3_loss: 1.9757 - dense_3_acc: 0.9998 - dense_3_acc_1: 0.9997 - dense_3_acc_2: 0.9990 - dense_3_acc_3: 0.9981 - dense_3_acc_4: 0.9967 - dense_3_acc_5: 0.9925 - dense_3_acc_6: 0.9850 - dense_3_acc_7: 0.9670 - dense_3_acc_8: 0.9370 - dense_3_acc_9: 0.8730 - dense_3_acc_10: 0.7723 - dense_3_acc_11: 0.6327 - dense_3_acc_12: 0.4507 - dense_3_acc_13: 0.2934 - dense_3_acc_14: 0.2030 - dense_3_acc_15: 0.2206 - dense_3_acc_16: 0.1083 - dense_3_acc_17: 0.3141 - dense_3_acc_18: 0.3105\n",
      "Epoch 4/100\n",
      "10887/10887 [==============================] - 13s 1ms/step - loss: 18.1862 - dense_3_loss: 1.6902 - dense_3_acc: 0.9998 - dense_3_acc_1: 0.9997 - dense_3_acc_2: 0.9990 - dense_3_acc_3: 0.9981 - dense_3_acc_4: 0.9967 - dense_3_acc_5: 0.9927 - dense_3_acc_6: 0.9847 - dense_3_acc_7: 0.9669 - dense_3_acc_8: 0.9373 - dense_3_acc_9: 0.8752 - dense_3_acc_10: 0.7757 - dense_3_acc_11: 0.6348 - dense_3_acc_12: 0.4651 - dense_3_acc_13: 0.3021 - dense_3_acc_14: 0.1981 - dense_3_acc_15: 0.2273 - dense_3_acc_16: 0.1874 - dense_3_acc_17: 0.3557 - dense_3_acc_18: 0.4101\n",
      "Epoch 5/100\n",
      "10887/10887 [==============================] - 13s 1ms/step - loss: 17.2573 - dense_3_loss: 1.5119 - dense_3_acc: 0.9998 - dense_3_acc_1: 0.9997 - dense_3_acc_2: 0.9990 - dense_3_acc_3: 0.9981 - dense_3_acc_4: 0.9967 - dense_3_acc_5: 0.9927 - dense_3_acc_6: 0.9843 - dense_3_acc_7: 0.9679 - dense_3_acc_8: 0.9390 - dense_3_acc_9: 0.8760 - dense_3_acc_10: 0.7819 - dense_3_acc_11: 0.6440 - dense_3_acc_12: 0.4883 - dense_3_acc_13: 0.3353 - dense_3_acc_14: 0.2370 - dense_3_acc_15: 0.2500 - dense_3_acc_16: 0.2178 - dense_3_acc_17: 0.4006 - dense_3_acc_18: 0.4932\n",
      "Epoch 6/100\n",
      "10887/10887 [==============================] - 13s 1ms/step - loss: 16.4143 - dense_3_loss: 1.3575 - dense_3_acc: 0.9998 - dense_3_acc_1: 0.9997 - dense_3_acc_2: 0.9990 - dense_3_acc_3: 0.9981 - dense_3_acc_4: 0.9968 - dense_3_acc_5: 0.9928 - dense_3_acc_6: 0.9850 - dense_3_acc_7: 0.9684 - dense_3_acc_8: 0.9396 - dense_3_acc_9: 0.8808 - dense_3_acc_10: 0.7890 - dense_3_acc_11: 0.6546 - dense_3_acc_12: 0.5088 - dense_3_acc_13: 0.3606 - dense_3_acc_14: 0.2736 - dense_3_acc_15: 0.2967 - dense_3_acc_16: 0.2344 - dense_3_acc_17: 0.4409 - dense_3_acc_18: 0.5541\n",
      "Epoch 7/100\n",
      "10887/10887 [==============================] - 13s 1ms/step - loss: 15.5176 - dense_3_loss: 1.2189 - dense_3_acc: 0.9998 - dense_3_acc_1: 0.9997 - dense_3_acc_2: 0.9990 - dense_3_acc_3: 0.9981 - dense_3_acc_4: 0.9968 - dense_3_acc_5: 0.9929 - dense_3_acc_6: 0.9850 - dense_3_acc_7: 0.9689 - dense_3_acc_8: 0.9409 - dense_3_acc_9: 0.8811 - dense_3_acc_10: 0.7940 - dense_3_acc_11: 0.6683 - dense_3_acc_12: 0.5310 - dense_3_acc_13: 0.3801 - dense_3_acc_14: 0.3014 - dense_3_acc_15: 0.3209 - dense_3_acc_16: 0.2867 - dense_3_acc_17: 0.4698 - dense_3_acc_18: 0.6058\n",
      "Epoch 8/100\n",
      "10887/10887 [==============================] - 13s 1ms/step - loss: 14.6583 - dense_3_loss: 1.0731 - dense_3_acc: 0.9998 - dense_3_acc_1: 0.9997 - dense_3_acc_2: 0.9990 - dense_3_acc_3: 0.9981 - dense_3_acc_4: 0.9968 - dense_3_acc_5: 0.9929 - dense_3_acc_6: 0.9846 - dense_3_acc_7: 0.9696 - dense_3_acc_8: 0.9412 - dense_3_acc_9: 0.8826 - dense_3_acc_10: 0.7952 - dense_3_acc_11: 0.6791 - dense_3_acc_12: 0.5578 - dense_3_acc_13: 0.4040 - dense_3_acc_14: 0.3351 - dense_3_acc_15: 0.3594 - dense_3_acc_16: 0.3337 - dense_3_acc_17: 0.5211 - dense_3_acc_18: 0.6759\n",
      "Epoch 9/100\n",
      "10887/10887 [==============================] - 13s 1ms/step - loss: 13.8579 - dense_3_loss: 0.9483 - dense_3_acc: 0.9998 - dense_3_acc_1: 0.9997 - dense_3_acc_2: 0.9990 - dense_3_acc_3: 0.9981 - dense_3_acc_4: 0.9968 - dense_3_acc_5: 0.9928 - dense_3_acc_6: 0.9848 - dense_3_acc_7: 0.9686 - dense_3_acc_8: 0.9416 - dense_3_acc_9: 0.8858 - dense_3_acc_10: 0.8005 - dense_3_acc_11: 0.6896 - dense_3_acc_12: 0.5698 - dense_3_acc_13: 0.4282 - dense_3_acc_14: 0.3648 - dense_3_acc_15: 0.3916 - dense_3_acc_16: 0.3691 - dense_3_acc_17: 0.5671 - dense_3_acc_18: 0.7208\n",
      "Epoch 10/100\n",
      "10887/10887 [==============================] - 13s 1ms/step - loss: 13.1582 - dense_3_loss: 0.8536 - dense_3_acc: 0.9998 - dense_3_acc_1: 0.9997 - dense_3_acc_2: 0.9990 - dense_3_acc_3: 0.9981 - dense_3_acc_4: 0.9968 - dense_3_acc_5: 0.9927 - dense_3_acc_6: 0.9852 - dense_3_acc_7: 0.9696 - dense_3_acc_8: 0.9428 - dense_3_acc_9: 0.8903 - dense_3_acc_10: 0.8106 - dense_3_acc_11: 0.7019 - dense_3_acc_12: 0.5767 - dense_3_acc_13: 0.4526 - dense_3_acc_14: 0.3919 - dense_3_acc_15: 0.4137 - dense_3_acc_16: 0.4164 - dense_3_acc_17: 0.6052 - dense_3_acc_18: 0.7511\n",
      "Epoch 11/100\n",
      "10887/10887 [==============================] - 13s 1ms/step - loss: 12.5053 - dense_3_loss: 0.7667 - dense_3_acc: 0.9998 - dense_3_acc_1: 0.9997 - dense_3_acc_2: 0.9990 - dense_3_acc_3: 0.9981 - dense_3_acc_4: 0.9968 - dense_3_acc_5: 0.9929 - dense_3_acc_6: 0.9850 - dense_3_acc_7: 0.9704 - dense_3_acc_8: 0.9435 - dense_3_acc_9: 0.8920 - dense_3_acc_10: 0.8194 - dense_3_acc_11: 0.7068 - dense_3_acc_12: 0.5902 - dense_3_acc_13: 0.4707 - dense_3_acc_14: 0.4110 - dense_3_acc_15: 0.4446 - dense_3_acc_16: 0.4653 - dense_3_acc_17: 0.6480 - dense_3_acc_18: 0.7773\n",
      "Epoch 12/100\n",
      "10887/10887 [==============================] - 13s 1ms/step - loss: 11.9114 - dense_3_loss: 0.7045 - dense_3_acc: 0.9998 - dense_3_acc_1: 0.9997 - dense_3_acc_2: 0.9990 - dense_3_acc_3: 0.9981 - dense_3_acc_4: 0.9969 - dense_3_acc_5: 0.9927 - dense_3_acc_6: 0.9855 - dense_3_acc_7: 0.9712 - dense_3_acc_8: 0.9434 - dense_3_acc_9: 0.8957 - dense_3_acc_10: 0.8251 - dense_3_acc_11: 0.7238 - dense_3_acc_12: 0.6095 - dense_3_acc_13: 0.4901 - dense_3_acc_14: 0.4290 - dense_3_acc_15: 0.4755 - dense_3_acc_16: 0.5088 - dense_3_acc_17: 0.6883 - dense_3_acc_18: 0.7903\n",
      "Epoch 13/100\n",
      "10887/10887 [==============================] - 13s 1ms/step - loss: 11.3166 - dense_3_loss: 0.6267 - dense_3_acc: 0.9998 - dense_3_acc_1: 0.9997 - dense_3_acc_2: 0.9990 - dense_3_acc_3: 0.9981 - dense_3_acc_4: 0.9968 - dense_3_acc_5: 0.9930 - dense_3_acc_6: 0.9855 - dense_3_acc_7: 0.9713 - dense_3_acc_8: 0.9432 - dense_3_acc_9: 0.8994 - dense_3_acc_10: 0.8311 - dense_3_acc_11: 0.7371 - dense_3_acc_12: 0.6240 - dense_3_acc_13: 0.5044 - dense_3_acc_14: 0.4478 - dense_3_acc_15: 0.5014 - dense_3_acc_16: 0.5495 - dense_3_acc_17: 0.7243 - dense_3_acc_18: 0.8199\n",
      "Epoch 14/100\n",
      "10887/10887 [==============================] - 13s 1ms/step - loss: 10.9760 - dense_3_loss: 0.5990 - dense_3_acc: 0.9998 - dense_3_acc_1: 0.9997 - dense_3_acc_2: 0.9990 - dense_3_acc_3: 0.9981 - dense_3_acc_4: 0.9968 - dense_3_acc_5: 0.9928 - dense_3_acc_6: 0.9858 - dense_3_acc_7: 0.9728 - dense_3_acc_8: 0.9447 - dense_3_acc_9: 0.9050 - dense_3_acc_10: 0.8374 - dense_3_acc_11: 0.7439 - dense_3_acc_12: 0.6297 - dense_3_acc_13: 0.5146 - dense_3_acc_14: 0.4553 - dense_3_acc_15: 0.5170 - dense_3_acc_16: 0.5683 - dense_3_acc_17: 0.7307 - dense_3_acc_18: 0.8236\n",
      "Epoch 15/100\n",
      "10887/10887 [==============================] - 13s 1ms/step - loss: 10.3821 - dense_3_loss: 0.5292 - dense_3_acc: 0.9998 - dense_3_acc_1: 0.9997 - dense_3_acc_2: 0.9990 - dense_3_acc_3: 0.9982 - dense_3_acc_4: 0.9968 - dense_3_acc_5: 0.9928 - dense_3_acc_6: 0.9852 - dense_3_acc_7: 0.9734 - dense_3_acc_8: 0.9475 - dense_3_acc_9: 0.9080 - dense_3_acc_10: 0.8444 - dense_3_acc_11: 0.7570 - dense_3_acc_12: 0.6550 - dense_3_acc_13: 0.5402 - dense_3_acc_14: 0.4871 - dense_3_acc_15: 0.5507 - dense_3_acc_16: 0.6072 - dense_3_acc_17: 0.7582 - dense_3_acc_18: 0.8560\n",
      "Epoch 16/100\n",
      "10887/10887 [==============================] - 13s 1ms/step - loss: 9.9236 - dense_3_loss: 0.4837 - dense_3_acc: 0.9998 - dense_3_acc_1: 0.9997 - dense_3_acc_2: 0.9990 - dense_3_acc_3: 0.9982 - dense_3_acc_4: 0.9968 - dense_3_acc_5: 0.9927 - dense_3_acc_6: 0.9853 - dense_3_acc_7: 0.9740 - dense_3_acc_8: 0.9493 - dense_3_acc_9: 0.9098 - dense_3_acc_10: 0.8482 - dense_3_acc_11: 0.7675 - dense_3_acc_12: 0.6704 - dense_3_acc_13: 0.5589 - dense_3_acc_14: 0.5049 - dense_3_acc_15: 0.5734 - dense_3_acc_16: 0.6308 - dense_3_acc_17: 0.7776 - dense_3_acc_18: 0.8713\n",
      "Epoch 17/100\n",
      "10887/10887 [==============================] - 13s 1ms/step - loss: 9.5510 - dense_3_loss: 0.4442 - dense_3_acc: 0.9998 - dense_3_acc_1: 0.9997 - dense_3_acc_2: 0.9990 - dense_3_acc_3: 0.9982 - dense_3_acc_4: 0.9969 - dense_3_acc_5: 0.9927 - dense_3_acc_6: 0.9865 - dense_3_acc_7: 0.9738 - dense_3_acc_8: 0.9498 - dense_3_acc_9: 0.9136 - dense_3_acc_10: 0.8547 - dense_3_acc_11: 0.7756 - dense_3_acc_12: 0.6805 - dense_3_acc_13: 0.5679 - dense_3_acc_14: 0.5267 - dense_3_acc_15: 0.5969 - dense_3_acc_16: 0.6435 - dense_3_acc_17: 0.7942 - dense_3_acc_18: 0.8847\n",
      "Epoch 18/100\n",
      "10887/10887 [==============================] - 13s 1ms/step - loss: 9.2298 - dense_3_loss: 0.4171 - dense_3_acc: 0.9998 - dense_3_acc_1: 0.9997 - dense_3_acc_2: 0.9990 - dense_3_acc_3: 0.9982 - dense_3_acc_4: 0.9968 - dense_3_acc_5: 0.9929 - dense_3_acc_6: 0.9863 - dense_3_acc_7: 0.9754 - dense_3_acc_8: 0.9516 - dense_3_acc_9: 0.9154 - dense_3_acc_10: 0.8575 - dense_3_acc_11: 0.7814 - dense_3_acc_12: 0.6889 - dense_3_acc_13: 0.5840 - dense_3_acc_14: 0.5451 - dense_3_acc_15: 0.6126 - dense_3_acc_16: 0.6617 - dense_3_acc_17: 0.8048 - dense_3_acc_18: 0.8954\n",
      "Epoch 19/100\n",
      "10887/10887 [==============================] - 13s 1ms/step - loss: 9.0543 - dense_3_loss: 0.4030 - dense_3_acc: 0.9998 - dense_3_acc_1: 0.9997 - dense_3_acc_2: 0.9990 - dense_3_acc_3: 0.9982 - dense_3_acc_4: 0.9970 - dense_3_acc_5: 0.9929 - dense_3_acc_6: 0.9863 - dense_3_acc_7: 0.9752 - dense_3_acc_8: 0.9540 - dense_3_acc_9: 0.9171 - dense_3_acc_10: 0.8592 - dense_3_acc_11: 0.7841 - dense_3_acc_12: 0.6907 - dense_3_acc_13: 0.5891 - dense_3_acc_14: 0.5526 - dense_3_acc_15: 0.6174 - dense_3_acc_16: 0.6680 - dense_3_acc_17: 0.8130 - dense_3_acc_18: 0.9004\n",
      "Epoch 20/100\n",
      "10887/10887 [==============================] - 13s 1ms/step - loss: 8.7257 - dense_3_loss: 0.3772 - dense_3_acc: 0.9998 - dense_3_acc_1: 0.9997 - dense_3_acc_2: 0.9990 - dense_3_acc_3: 0.9982 - dense_3_acc_4: 0.9969 - dense_3_acc_5: 0.9929 - dense_3_acc_6: 0.9870 - dense_3_acc_7: 0.9761 - dense_3_acc_8: 0.9553 - dense_3_acc_9: 0.9183 - dense_3_acc_10: 0.8638 - dense_3_acc_11: 0.7894 - dense_3_acc_12: 0.7000 - dense_3_acc_13: 0.6034 - dense_3_acc_14: 0.5675 - dense_3_acc_15: 0.6386 - dense_3_acc_16: 0.6825 - dense_3_acc_17: 0.8300 - dense_3_acc_18: 0.9098\n",
      "Epoch 21/100\n",
      "10887/10887 [==============================] - 13s 1ms/step - loss: 8.4693 - dense_3_loss: 0.3592 - dense_3_acc: 0.9998 - dense_3_acc_1: 0.9997 - dense_3_acc_2: 0.9990 - dense_3_acc_3: 0.9982 - dense_3_acc_4: 0.9969 - dense_3_acc_5: 0.9930 - dense_3_acc_6: 0.9866 - dense_3_acc_7: 0.9764 - dense_3_acc_8: 0.9562 - dense_3_acc_9: 0.9191 - dense_3_acc_10: 0.8654 - dense_3_acc_11: 0.7976 - dense_3_acc_12: 0.7083 - dense_3_acc_13: 0.6185 - dense_3_acc_14: 0.5870 - dense_3_acc_15: 0.6485 - dense_3_acc_16: 0.6917 - dense_3_acc_17: 0.8431 - dense_3_acc_18: 0.9170\n",
      "Epoch 22/100\n",
      "10887/10887 [==============================] - 13s 1ms/step - loss: 8.2856 - dense_3_loss: 0.3462 - dense_3_acc: 0.9998 - dense_3_acc_1: 0.9997 - dense_3_acc_2: 0.9990 - dense_3_acc_3: 0.9983 - dense_3_acc_4: 0.9972 - dense_3_acc_5: 0.9934 - dense_3_acc_6: 0.9876 - dense_3_acc_7: 0.9767 - dense_3_acc_8: 0.9580 - dense_3_acc_9: 0.9216 - dense_3_acc_10: 0.8712 - dense_3_acc_11: 0.8010 - dense_3_acc_12: 0.7141 - dense_3_acc_13: 0.6266 - dense_3_acc_14: 0.5958 - dense_3_acc_15: 0.6595 - dense_3_acc_16: 0.7015 - dense_3_acc_17: 0.8515 - dense_3_acc_18: 0.9181\n",
      "Epoch 23/100\n",
      "10887/10887 [==============================] - 13s 1ms/step - loss: 8.0294 - dense_3_loss: 0.3320 - dense_3_acc: 0.9998 - dense_3_acc_1: 0.9997 - dense_3_acc_2: 0.9990 - dense_3_acc_3: 0.9983 - dense_3_acc_4: 0.9970 - dense_3_acc_5: 0.9938 - dense_3_acc_6: 0.9875 - dense_3_acc_7: 0.9773 - dense_3_acc_8: 0.9592 - dense_3_acc_9: 0.9228 - dense_3_acc_10: 0.8724 - dense_3_acc_11: 0.8074 - dense_3_acc_12: 0.7198 - dense_3_acc_13: 0.6374 - dense_3_acc_14: 0.6101 - dense_3_acc_15: 0.6721 - dense_3_acc_16: 0.7131 - dense_3_acc_17: 0.8582 - dense_3_acc_18: 0.9227\n",
      "Epoch 24/100\n",
      "10887/10887 [==============================] - 13s 1ms/step - loss: 7.8805 - dense_3_loss: 0.3265 - dense_3_acc: 0.9998 - dense_3_acc_1: 0.9997 - dense_3_acc_2: 0.9990 - dense_3_acc_3: 0.9983 - dense_3_acc_4: 0.9972 - dense_3_acc_5: 0.9937 - dense_3_acc_6: 0.9880 - dense_3_acc_7: 0.9771 - dense_3_acc_8: 0.9606 - dense_3_acc_9: 0.9234 - dense_3_acc_10: 0.8746 - dense_3_acc_11: 0.8106 - dense_3_acc_12: 0.7273 - dense_3_acc_13: 0.6429 - dense_3_acc_14: 0.6184 - dense_3_acc_15: 0.6802 - dense_3_acc_16: 0.7202 - dense_3_acc_17: 0.8642 - dense_3_acc_18: 0.9239\n",
      "Epoch 25/100\n",
      "10887/10887 [==============================] - 13s 1ms/step - loss: 7.6742 - dense_3_loss: 0.3115 - dense_3_acc: 0.9998 - dense_3_acc_1: 0.9997 - dense_3_acc_2: 0.9990 - dense_3_acc_3: 0.9983 - dense_3_acc_4: 0.9970 - dense_3_acc_5: 0.9940 - dense_3_acc_6: 0.9880 - dense_3_acc_7: 0.9780 - dense_3_acc_8: 0.9611 - dense_3_acc_9: 0.9262 - dense_3_acc_10: 0.8764 - dense_3_acc_11: 0.8169 - dense_3_acc_12: 0.7330 - dense_3_acc_13: 0.6484 - dense_3_acc_14: 0.6312 - dense_3_acc_15: 0.6915 - dense_3_acc_16: 0.7325 - dense_3_acc_17: 0.8698 - dense_3_acc_18: 0.9306\n",
      "Epoch 26/100\n",
      "10887/10887 [==============================] - 13s 1ms/step - loss: 7.4797 - dense_3_loss: 0.3009 - dense_3_acc: 0.9998 - dense_3_acc_1: 0.9997 - dense_3_acc_2: 0.9990 - dense_3_acc_3: 0.9983 - dense_3_acc_4: 0.9972 - dense_3_acc_5: 0.9936 - dense_3_acc_6: 0.9882 - dense_3_acc_7: 0.9785 - dense_3_acc_8: 0.9610 - dense_3_acc_9: 0.9276 - dense_3_acc_10: 0.8804 - dense_3_acc_11: 0.8221 - dense_3_acc_12: 0.7368 - dense_3_acc_13: 0.6580 - dense_3_acc_14: 0.6383 - dense_3_acc_15: 0.6971 - dense_3_acc_16: 0.7453 - dense_3_acc_17: 0.8799 - dense_3_acc_18: 0.9312\n",
      "Epoch 27/100\n",
      "10887/10887 [==============================] - 13s 1ms/step - loss: 7.3182 - dense_3_loss: 0.2963 - dense_3_acc: 0.9998 - dense_3_acc_1: 0.9997 - dense_3_acc_2: 0.9990 - dense_3_acc_3: 0.9983 - dense_3_acc_4: 0.9972 - dense_3_acc_5: 0.9939 - dense_3_acc_6: 0.9892 - dense_3_acc_7: 0.9787 - dense_3_acc_8: 0.9634 - dense_3_acc_9: 0.9300 - dense_3_acc_10: 0.8821 - dense_3_acc_11: 0.8267 - dense_3_acc_12: 0.7442 - dense_3_acc_13: 0.6645 - dense_3_acc_14: 0.6502 - dense_3_acc_15: 0.7061 - dense_3_acc_16: 0.7494 - dense_3_acc_17: 0.8830 - dense_3_acc_18: 0.9318\n",
      "Epoch 28/100\n",
      "10887/10887 [==============================] - 13s 1ms/step - loss: 7.1870 - dense_3_loss: 0.2846 - dense_3_acc: 0.9998 - dense_3_acc_1: 0.9997 - dense_3_acc_2: 0.9990 - dense_3_acc_3: 0.9983 - dense_3_acc_4: 0.9972 - dense_3_acc_5: 0.9939 - dense_3_acc_6: 0.9894 - dense_3_acc_7: 0.9794 - dense_3_acc_8: 0.9638 - dense_3_acc_9: 0.9318 - dense_3_acc_10: 0.8846 - dense_3_acc_11: 0.8281 - dense_3_acc_12: 0.7463 - dense_3_acc_13: 0.6687 - dense_3_acc_14: 0.6566 - dense_3_acc_15: 0.7132 - dense_3_acc_16: 0.7561 - dense_3_acc_17: 0.8890 - dense_3_acc_18: 0.9345\n",
      "Epoch 29/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10887/10887 [==============================] - 13s 1ms/step - loss: 7.0310 - dense_3_loss: 0.2766 - dense_3_acc: 0.9998 - dense_3_acc_1: 0.9997 - dense_3_acc_2: 0.9990 - dense_3_acc_3: 0.9983 - dense_3_acc_4: 0.9973 - dense_3_acc_5: 0.9939 - dense_3_acc_6: 0.9888 - dense_3_acc_7: 0.9790 - dense_3_acc_8: 0.9644 - dense_3_acc_9: 0.9323 - dense_3_acc_10: 0.8855 - dense_3_acc_11: 0.8302 - dense_3_acc_12: 0.7482 - dense_3_acc_13: 0.6773 - dense_3_acc_14: 0.6654 - dense_3_acc_15: 0.7223 - dense_3_acc_16: 0.7675 - dense_3_acc_17: 0.8907 - dense_3_acc_18: 0.9395\n",
      "Epoch 30/100\n",
      "10887/10887 [==============================] - 13s 1ms/step - loss: 6.8862 - dense_3_loss: 0.2681 - dense_3_acc: 0.9998 - dense_3_acc_1: 0.9997 - dense_3_acc_2: 0.9990 - dense_3_acc_3: 0.9983 - dense_3_acc_4: 0.9973 - dense_3_acc_5: 0.9938 - dense_3_acc_6: 0.9894 - dense_3_acc_7: 0.9794 - dense_3_acc_8: 0.9650 - dense_3_acc_9: 0.9331 - dense_3_acc_10: 0.8861 - dense_3_acc_11: 0.8307 - dense_3_acc_12: 0.7508 - dense_3_acc_13: 0.6820 - dense_3_acc_14: 0.6714 - dense_3_acc_15: 0.7266 - dense_3_acc_16: 0.7741 - dense_3_acc_17: 0.8957 - dense_3_acc_18: 0.9413\n",
      "Epoch 31/100\n",
      "10887/10887 [==============================] - 13s 1ms/step - loss: 6.7745 - dense_3_loss: 0.2687 - dense_3_acc: 0.9998 - dense_3_acc_1: 0.9997 - dense_3_acc_2: 0.9990 - dense_3_acc_3: 0.9983 - dense_3_acc_4: 0.9972 - dense_3_acc_5: 0.9945 - dense_3_acc_6: 0.9899 - dense_3_acc_7: 0.9800 - dense_3_acc_8: 0.9648 - dense_3_acc_9: 0.9352 - dense_3_acc_10: 0.8908 - dense_3_acc_11: 0.8351 - dense_3_acc_12: 0.7568 - dense_3_acc_13: 0.6891 - dense_3_acc_14: 0.6764 - dense_3_acc_15: 0.7332 - dense_3_acc_16: 0.7773 - dense_3_acc_17: 0.8991 - dense_3_acc_18: 0.9401\n",
      "Epoch 32/100\n",
      "10887/10887 [==============================] - 13s 1ms/step - loss: 6.6832 - dense_3_loss: 0.2617 - dense_3_acc: 0.9998 - dense_3_acc_1: 0.9997 - dense_3_acc_2: 0.9990 - dense_3_acc_3: 0.9983 - dense_3_acc_4: 0.9972 - dense_3_acc_5: 0.9945 - dense_3_acc_6: 0.9897 - dense_3_acc_7: 0.9801 - dense_3_acc_8: 0.9647 - dense_3_acc_9: 0.9359 - dense_3_acc_10: 0.8916 - dense_3_acc_11: 0.8372 - dense_3_acc_12: 0.7586 - dense_3_acc_13: 0.6911 - dense_3_acc_14: 0.6831 - dense_3_acc_15: 0.7379 - dense_3_acc_16: 0.7801 - dense_3_acc_17: 0.9024 - dense_3_acc_18: 0.9425\n",
      "Epoch 33/100\n",
      "10887/10887 [==============================] - 13s 1ms/step - loss: 6.5601 - dense_3_loss: 0.2537 - dense_3_acc: 0.9998 - dense_3_acc_1: 0.9997 - dense_3_acc_2: 0.9990 - dense_3_acc_3: 0.9983 - dense_3_acc_4: 0.9972 - dense_3_acc_5: 0.9940 - dense_3_acc_6: 0.9889 - dense_3_acc_7: 0.9794 - dense_3_acc_8: 0.9654 - dense_3_acc_9: 0.9365 - dense_3_acc_10: 0.8922 - dense_3_acc_11: 0.8409 - dense_3_acc_12: 0.7616 - dense_3_acc_13: 0.6928 - dense_3_acc_14: 0.6887 - dense_3_acc_15: 0.7450 - dense_3_acc_16: 0.7908 - dense_3_acc_17: 0.9055 - dense_3_acc_18: 0.9442\n",
      "Epoch 34/100\n",
      "10887/10887 [==============================] - 13s 1ms/step - loss: 6.4187 - dense_3_loss: 0.2464 - dense_3_acc: 0.9998 - dense_3_acc_1: 0.9997 - dense_3_acc_2: 0.9990 - dense_3_acc_3: 0.9983 - dense_3_acc_4: 0.9972 - dense_3_acc_5: 0.9943 - dense_3_acc_6: 0.9898 - dense_3_acc_7: 0.9803 - dense_3_acc_8: 0.9659 - dense_3_acc_9: 0.9382 - dense_3_acc_10: 0.8956 - dense_3_acc_11: 0.8439 - dense_3_acc_12: 0.7688 - dense_3_acc_13: 0.6985 - dense_3_acc_14: 0.6962 - dense_3_acc_15: 0.7517 - dense_3_acc_16: 0.7949 - dense_3_acc_17: 0.9087 - dense_3_acc_18: 0.9464\n",
      "Epoch 35/100\n",
      "10887/10887 [==============================] - 13s 1ms/step - loss: 6.3363 - dense_3_loss: 0.2418 - dense_3_acc: 0.9998 - dense_3_acc_1: 0.9997 - dense_3_acc_2: 0.9990 - dense_3_acc_3: 0.9983 - dense_3_acc_4: 0.9974 - dense_3_acc_5: 0.9945 - dense_3_acc_6: 0.9897 - dense_3_acc_7: 0.9820 - dense_3_acc_8: 0.9671 - dense_3_acc_9: 0.9400 - dense_3_acc_10: 0.8957 - dense_3_acc_11: 0.8439 - dense_3_acc_12: 0.7683 - dense_3_acc_13: 0.7041 - dense_3_acc_14: 0.6985 - dense_3_acc_15: 0.7547 - dense_3_acc_16: 0.8005 - dense_3_acc_17: 0.9113 - dense_3_acc_18: 0.9475\n",
      "Epoch 36/100\n",
      "10887/10887 [==============================] - 13s 1ms/step - loss: 6.2306 - dense_3_loss: 0.2386 - dense_3_acc: 0.9998 - dense_3_acc_1: 0.9997 - dense_3_acc_2: 0.9990 - dense_3_acc_3: 0.9983 - dense_3_acc_4: 0.9974 - dense_3_acc_5: 0.9942 - dense_3_acc_6: 0.9902 - dense_3_acc_7: 0.9808 - dense_3_acc_8: 0.9675 - dense_3_acc_9: 0.9398 - dense_3_acc_10: 0.8971 - dense_3_acc_11: 0.8462 - dense_3_acc_12: 0.7706 - dense_3_acc_13: 0.7087 - dense_3_acc_14: 0.7085 - dense_3_acc_15: 0.7656 - dense_3_acc_16: 0.8047 - dense_3_acc_17: 0.9141 - dense_3_acc_18: 0.9493\n",
      "Epoch 37/100\n",
      "10887/10887 [==============================] - 13s 1ms/step - loss: 6.1298 - dense_3_loss: 0.2331 - dense_3_acc: 0.9998 - dense_3_acc_1: 0.9997 - dense_3_acc_2: 0.9990 - dense_3_acc_3: 0.9983 - dense_3_acc_4: 0.9973 - dense_3_acc_5: 0.9944 - dense_3_acc_6: 0.9903 - dense_3_acc_7: 0.9814 - dense_3_acc_8: 0.9679 - dense_3_acc_9: 0.9408 - dense_3_acc_10: 0.8999 - dense_3_acc_11: 0.8474 - dense_3_acc_12: 0.7729 - dense_3_acc_13: 0.7119 - dense_3_acc_14: 0.7074 - dense_3_acc_15: 0.7691 - dense_3_acc_16: 0.8096 - dense_3_acc_17: 0.9180 - dense_3_acc_18: 0.9493\n",
      "Epoch 38/100\n",
      "10887/10887 [==============================] - 13s 1ms/step - loss: 6.0461 - dense_3_loss: 0.2285 - dense_3_acc: 0.9998 - dense_3_acc_1: 0.9997 - dense_3_acc_2: 0.9990 - dense_3_acc_3: 0.9983 - dense_3_acc_4: 0.9975 - dense_3_acc_5: 0.9944 - dense_3_acc_6: 0.9903 - dense_3_acc_7: 0.9818 - dense_3_acc_8: 0.9684 - dense_3_acc_9: 0.9414 - dense_3_acc_10: 0.9028 - dense_3_acc_11: 0.8509 - dense_3_acc_12: 0.7740 - dense_3_acc_13: 0.7150 - dense_3_acc_14: 0.7131 - dense_3_acc_15: 0.7717 - dense_3_acc_16: 0.8111 - dense_3_acc_17: 0.9176 - dense_3_acc_18: 0.9510\n",
      "Epoch 39/100\n",
      "10887/10887 [==============================] - 14s 1ms/step - loss: 6.0251 - dense_3_loss: 0.2312 - dense_3_acc: 0.9998 - dense_3_acc_1: 0.9997 - dense_3_acc_2: 0.9990 - dense_3_acc_3: 0.9984 - dense_3_acc_4: 0.9974 - dense_3_acc_5: 0.9946 - dense_3_acc_6: 0.9900 - dense_3_acc_7: 0.9818 - dense_3_acc_8: 0.9684 - dense_3_acc_9: 0.9404 - dense_3_acc_10: 0.9012 - dense_3_acc_11: 0.8491 - dense_3_acc_12: 0.7751 - dense_3_acc_13: 0.7154 - dense_3_acc_14: 0.7152 - dense_3_acc_15: 0.7730 - dense_3_acc_16: 0.8143 - dense_3_acc_17: 0.9171 - dense_3_acc_18: 0.9498\n",
      "Epoch 40/100\n",
      "10887/10887 [==============================] - 14s 1ms/step - loss: 5.8641 - dense_3_loss: 0.2186 - dense_3_acc: 0.9998 - dense_3_acc_1: 0.9997 - dense_3_acc_2: 0.9990 - dense_3_acc_3: 0.9983 - dense_3_acc_4: 0.9973 - dense_3_acc_5: 0.9948 - dense_3_acc_6: 0.9905 - dense_3_acc_7: 0.9823 - dense_3_acc_8: 0.9690 - dense_3_acc_9: 0.9440 - dense_3_acc_10: 0.9047 - dense_3_acc_11: 0.8548 - dense_3_acc_12: 0.7831 - dense_3_acc_13: 0.7220 - dense_3_acc_14: 0.7220 - dense_3_acc_15: 0.7812 - dense_3_acc_16: 0.8233 - dense_3_acc_17: 0.9214 - dense_3_acc_18: 0.9539\n",
      "Epoch 41/100\n",
      "10887/10887 [==============================] - 14s 1ms/step - loss: 5.7918 - dense_3_loss: 0.2148 - dense_3_acc: 0.9998 - dense_3_acc_1: 0.9997 - dense_3_acc_2: 0.9990 - dense_3_acc_3: 0.9984 - dense_3_acc_4: 0.9972 - dense_3_acc_5: 0.9947 - dense_3_acc_6: 0.9906 - dense_3_acc_7: 0.9824 - dense_3_acc_8: 0.9696 - dense_3_acc_9: 0.9450 - dense_3_acc_10: 0.9055 - dense_3_acc_11: 0.8561 - dense_3_acc_12: 0.7841 - dense_3_acc_13: 0.7248 - dense_3_acc_14: 0.7291 - dense_3_acc_15: 0.7856 - dense_3_acc_16: 0.8255 - dense_3_acc_17: 0.9236 - dense_3_acc_18: 0.9555\n",
      "Epoch 42/100\n",
      "10887/10887 [==============================] - 13s 1ms/step - loss: 5.7287 - dense_3_loss: 0.2096 - dense_3_acc: 0.9998 - dense_3_acc_1: 0.9997 - dense_3_acc_2: 0.9990 - dense_3_acc_3: 0.9984 - dense_3_acc_4: 0.9973 - dense_3_acc_5: 0.9943 - dense_3_acc_6: 0.9904 - dense_3_acc_7: 0.9836 - dense_3_acc_8: 0.9701 - dense_3_acc_9: 0.9466 - dense_3_acc_10: 0.9070 - dense_3_acc_11: 0.8563 - dense_3_acc_12: 0.7856 - dense_3_acc_13: 0.7274 - dense_3_acc_14: 0.7315 - dense_3_acc_15: 0.7903 - dense_3_acc_16: 0.8306 - dense_3_acc_17: 0.9273 - dense_3_acc_18: 0.9565\n",
      "Epoch 43/100\n",
      "10887/10887 [==============================] - 13s 1ms/step - loss: 5.6728 - dense_3_loss: 0.2097 - dense_3_acc: 0.9998 - dense_3_acc_1: 0.9997 - dense_3_acc_2: 0.9990 - dense_3_acc_3: 0.9984 - dense_3_acc_4: 0.9973 - dense_3_acc_5: 0.9946 - dense_3_acc_6: 0.9902 - dense_3_acc_7: 0.9825 - dense_3_acc_8: 0.9695 - dense_3_acc_9: 0.9472 - dense_3_acc_10: 0.9061 - dense_3_acc_11: 0.8560 - dense_3_acc_12: 0.7865 - dense_3_acc_13: 0.7314 - dense_3_acc_14: 0.7323 - dense_3_acc_15: 0.7919 - dense_3_acc_16: 0.8337 - dense_3_acc_17: 0.9258 - dense_3_acc_18: 0.9556\n",
      "Epoch 44/100\n",
      "10887/10887 [==============================] - 13s 1ms/step - loss: 5.6260 - dense_3_loss: 0.2055 - dense_3_acc: 0.9998 - dense_3_acc_1: 0.9997 - dense_3_acc_2: 0.9990 - dense_3_acc_3: 0.9984 - dense_3_acc_4: 0.9976 - dense_3_acc_5: 0.9947 - dense_3_acc_6: 0.9910 - dense_3_acc_7: 0.9830 - dense_3_acc_8: 0.9703 - dense_3_acc_9: 0.9464 - dense_3_acc_10: 0.9076 - dense_3_acc_11: 0.8584 - dense_3_acc_12: 0.7901 - dense_3_acc_13: 0.7336 - dense_3_acc_14: 0.7329 - dense_3_acc_15: 0.7922 - dense_3_acc_16: 0.8356 - dense_3_acc_17: 0.9292 - dense_3_acc_18: 0.9571\n",
      "Epoch 45/100\n",
      "10887/10887 [==============================] - 14s 1ms/step - loss: 5.5594 - dense_3_loss: 0.2048 - dense_3_acc: 0.9998 - dense_3_acc_1: 0.9997 - dense_3_acc_2: 0.9990 - dense_3_acc_3: 0.9984 - dense_3_acc_4: 0.9976 - dense_3_acc_5: 0.9946 - dense_3_acc_6: 0.9911 - dense_3_acc_7: 0.9836 - dense_3_acc_8: 0.9702 - dense_3_acc_9: 0.9478 - dense_3_acc_10: 0.9090 - dense_3_acc_11: 0.8573 - dense_3_acc_12: 0.7891 - dense_3_acc_13: 0.7342 - dense_3_acc_14: 0.7370 - dense_3_acc_15: 0.7986 - dense_3_acc_16: 0.8396 - dense_3_acc_17: 0.9269 - dense_3_acc_18: 0.9559\n",
      "Epoch 46/100\n",
      "10887/10887 [==============================] - 13s 1ms/step - loss: 5.4864 - dense_3_loss: 0.2004 - dense_3_acc: 0.9998 - dense_3_acc_1: 0.9997 - dense_3_acc_2: 0.9990 - dense_3_acc_3: 0.9984 - dense_3_acc_4: 0.9974 - dense_3_acc_5: 0.9947 - dense_3_acc_6: 0.9904 - dense_3_acc_7: 0.9832 - dense_3_acc_8: 0.9700 - dense_3_acc_9: 0.9471 - dense_3_acc_10: 0.9104 - dense_3_acc_11: 0.8612 - dense_3_acc_12: 0.7920 - dense_3_acc_13: 0.7390 - dense_3_acc_14: 0.7397 - dense_3_acc_15: 0.7988 - dense_3_acc_16: 0.8437 - dense_3_acc_17: 0.9315 - dense_3_acc_18: 0.9572\n",
      "Epoch 47/100\n",
      "10887/10887 [==============================] - 13s 1ms/step - loss: 5.4131 - dense_3_loss: 0.1950 - dense_3_acc: 0.9998 - dense_3_acc_1: 0.9997 - dense_3_acc_2: 0.9990 - dense_3_acc_3: 0.9984 - dense_3_acc_4: 0.9975 - dense_3_acc_5: 0.9949 - dense_3_acc_6: 0.9909 - dense_3_acc_7: 0.9836 - dense_3_acc_8: 0.9712 - dense_3_acc_9: 0.9487 - dense_3_acc_10: 0.9090 - dense_3_acc_11: 0.8611 - dense_3_acc_12: 0.7939 - dense_3_acc_13: 0.7411 - dense_3_acc_14: 0.7467 - dense_3_acc_15: 0.8028 - dense_3_acc_16: 0.8450 - dense_3_acc_17: 0.9318 - dense_3_acc_18: 0.9597\n",
      "Epoch 48/100\n",
      "10887/10887 [==============================] - 14s 1ms/step - loss: 5.3678 - dense_3_loss: 0.1940 - dense_3_acc: 0.9998 - dense_3_acc_1: 0.9997 - dense_3_acc_2: 0.9990 - dense_3_acc_3: 0.9985 - dense_3_acc_4: 0.9975 - dense_3_acc_5: 0.9948 - dense_3_acc_6: 0.9908 - dense_3_acc_7: 0.9846 - dense_3_acc_8: 0.9705 - dense_3_acc_9: 0.9492 - dense_3_acc_10: 0.9108 - dense_3_acc_11: 0.8614 - dense_3_acc_12: 0.7989 - dense_3_acc_13: 0.7438 - dense_3_acc_14: 0.7470 - dense_3_acc_15: 0.8071 - dense_3_acc_16: 0.8494 - dense_3_acc_17: 0.9318 - dense_3_acc_18: 0.9601\n",
      "Epoch 49/100\n",
      "10887/10887 [==============================] - 13s 1ms/step - loss: 5.3013 - dense_3_loss: 0.1929 - dense_3_acc: 0.9998 - dense_3_acc_1: 0.9997 - dense_3_acc_2: 0.9990 - dense_3_acc_3: 0.9984 - dense_3_acc_4: 0.9976 - dense_3_acc_5: 0.9950 - dense_3_acc_6: 0.9914 - dense_3_acc_7: 0.9839 - dense_3_acc_8: 0.9713 - dense_3_acc_9: 0.9504 - dense_3_acc_10: 0.9120 - dense_3_acc_11: 0.8662 - dense_3_acc_12: 0.7996 - dense_3_acc_13: 0.7446 - dense_3_acc_14: 0.7484 - dense_3_acc_15: 0.8078 - dense_3_acc_16: 0.8511 - dense_3_acc_17: 0.9345 - dense_3_acc_18: 0.9609\n",
      "Epoch 50/100\n",
      "10887/10887 [==============================] - 13s 1ms/step - loss: 5.2691 - dense_3_loss: 0.1922 - dense_3_acc: 0.9998 - dense_3_acc_1: 0.9997 - dense_3_acc_2: 0.9990 - dense_3_acc_3: 0.9984 - dense_3_acc_4: 0.9978 - dense_3_acc_5: 0.9951 - dense_3_acc_6: 0.9915 - dense_3_acc_7: 0.9853 - dense_3_acc_8: 0.9715 - dense_3_acc_9: 0.9502 - dense_3_acc_10: 0.9104 - dense_3_acc_11: 0.8628 - dense_3_acc_12: 0.8025 - dense_3_acc_13: 0.7477 - dense_3_acc_14: 0.7553 - dense_3_acc_15: 0.8075 - dense_3_acc_16: 0.8545 - dense_3_acc_17: 0.9363 - dense_3_acc_18: 0.9596\n",
      "Epoch 51/100\n",
      "10887/10887 [==============================] - 13s 1ms/step - loss: 5.1789 - dense_3_loss: 0.1846 - dense_3_acc: 0.9998 - dense_3_acc_1: 0.9997 - dense_3_acc_2: 0.9990 - dense_3_acc_3: 0.9985 - dense_3_acc_4: 0.9975 - dense_3_acc_5: 0.9951 - dense_3_acc_6: 0.9916 - dense_3_acc_7: 0.9843 - dense_3_acc_8: 0.9713 - dense_3_acc_9: 0.9510 - dense_3_acc_10: 0.9135 - dense_3_acc_11: 0.8659 - dense_3_acc_12: 0.8024 - dense_3_acc_13: 0.7517 - dense_3_acc_14: 0.7543 - dense_3_acc_15: 0.8143 - dense_3_acc_16: 0.8583 - dense_3_acc_17: 0.9387 - dense_3_acc_18: 0.9632\n",
      "Epoch 52/100\n",
      "10887/10887 [==============================] - 13s 1ms/step - loss: 5.1965 - dense_3_loss: 0.1837 - dense_3_acc: 0.9998 - dense_3_acc_1: 0.9997 - dense_3_acc_2: 0.9990 - dense_3_acc_3: 0.9984 - dense_3_acc_4: 0.9977 - dense_3_acc_5: 0.9949 - dense_3_acc_6: 0.9912 - dense_3_acc_7: 0.9845 - dense_3_acc_8: 0.9711 - dense_3_acc_9: 0.9510 - dense_3_acc_10: 0.9126 - dense_3_acc_11: 0.8631 - dense_3_acc_12: 0.8038 - dense_3_acc_13: 0.7507 - dense_3_acc_14: 0.7553 - dense_3_acc_15: 0.8155 - dense_3_acc_16: 0.8569 - dense_3_acc_17: 0.9366 - dense_3_acc_18: 0.9632\n",
      "Epoch 53/100\n",
      "10887/10887 [==============================] - 13s 1ms/step - loss: 5.1104 - dense_3_loss: 0.1842 - dense_3_acc: 0.9998 - dense_3_acc_1: 0.9997 - dense_3_acc_2: 0.9990 - dense_3_acc_3: 0.9985 - dense_3_acc_4: 0.9976 - dense_3_acc_5: 0.9950 - dense_3_acc_6: 0.9914 - dense_3_acc_7: 0.9854 - dense_3_acc_8: 0.9711 - dense_3_acc_9: 0.9520 - dense_3_acc_10: 0.9145 - dense_3_acc_11: 0.8679 - dense_3_acc_12: 0.8084 - dense_3_acc_13: 0.7526 - dense_3_acc_14: 0.7592 - dense_3_acc_15: 0.8166 - dense_3_acc_16: 0.8620 - dense_3_acc_17: 0.9380 - dense_3_acc_18: 0.9628\n",
      "Epoch 54/100\n",
      "10887/10887 [==============================] - 14s 1ms/step - loss: 5.0444 - dense_3_loss: 0.1781 - dense_3_acc: 0.9998 - dense_3_acc_1: 0.9997 - dense_3_acc_2: 0.9990 - dense_3_acc_3: 0.9985 - dense_3_acc_4: 0.9976 - dense_3_acc_5: 0.9952 - dense_3_acc_6: 0.9918 - dense_3_acc_7: 0.9851 - dense_3_acc_8: 0.9728 - dense_3_acc_9: 0.9528 - dense_3_acc_10: 0.9161 - dense_3_acc_11: 0.8684 - dense_3_acc_12: 0.8071 - dense_3_acc_13: 0.7562 - dense_3_acc_14: 0.7616 - dense_3_acc_15: 0.8191 - dense_3_acc_16: 0.8657 - dense_3_acc_17: 0.9388 - dense_3_acc_18: 0.9643\n",
      "Epoch 55/100\n",
      "10887/10887 [==============================] - 14s 1ms/step - loss: 4.9932 - dense_3_loss: 0.1760 - dense_3_acc: 0.9998 - dense_3_acc_1: 0.9997 - dense_3_acc_2: 0.9990 - dense_3_acc_3: 0.9985 - dense_3_acc_4: 0.9979 - dense_3_acc_5: 0.9949 - dense_3_acc_6: 0.9914 - dense_3_acc_7: 0.9853 - dense_3_acc_8: 0.9724 - dense_3_acc_9: 0.9530 - dense_3_acc_10: 0.9169 - dense_3_acc_11: 0.8690 - dense_3_acc_12: 0.8096 - dense_3_acc_13: 0.7615 - dense_3_acc_14: 0.7675 - dense_3_acc_15: 0.8206 - dense_3_acc_16: 0.8676 - dense_3_acc_17: 0.9405 - dense_3_acc_18: 0.9640\n",
      "Epoch 56/100\n",
      "10887/10887 [==============================] - 14s 1ms/step - loss: 4.9499 - dense_3_loss: 0.1752 - dense_3_acc: 0.9998 - dense_3_acc_1: 0.9997 - dense_3_acc_2: 0.9990 - dense_3_acc_3: 0.9986 - dense_3_acc_4: 0.9975 - dense_3_acc_5: 0.9949 - dense_3_acc_6: 0.9914 - dense_3_acc_7: 0.9854 - dense_3_acc_8: 0.9724 - dense_3_acc_9: 0.9536 - dense_3_acc_10: 0.9177 - dense_3_acc_11: 0.8702 - dense_3_acc_12: 0.8114 - dense_3_acc_13: 0.7612 - dense_3_acc_14: 0.7688 - dense_3_acc_15: 0.8228 - dense_3_acc_16: 0.8682 - dense_3_acc_17: 0.9428 - dense_3_acc_18: 0.9661\n",
      "Epoch 57/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10887/10887 [==============================] - 13s 1ms/step - loss: 4.8970 - dense_3_loss: 0.1715 - dense_3_acc: 0.9998 - dense_3_acc_1: 0.9997 - dense_3_acc_2: 0.9990 - dense_3_acc_3: 0.9986 - dense_3_acc_4: 0.9976 - dense_3_acc_5: 0.9949 - dense_3_acc_6: 0.9918 - dense_3_acc_7: 0.9848 - dense_3_acc_8: 0.9731 - dense_3_acc_9: 0.9537 - dense_3_acc_10: 0.9184 - dense_3_acc_11: 0.8714 - dense_3_acc_12: 0.8118 - dense_3_acc_13: 0.7657 - dense_3_acc_14: 0.7697 - dense_3_acc_15: 0.8253 - dense_3_acc_16: 0.8712 - dense_3_acc_17: 0.9417 - dense_3_acc_18: 0.9662\n",
      "Epoch 58/100\n",
      "10887/10887 [==============================] - 13s 1ms/step - loss: 4.8887 - dense_3_loss: 0.1729 - dense_3_acc: 0.9998 - dense_3_acc_1: 0.9997 - dense_3_acc_2: 0.9990 - dense_3_acc_3: 0.9986 - dense_3_acc_4: 0.9976 - dense_3_acc_5: 0.9949 - dense_3_acc_6: 0.9919 - dense_3_acc_7: 0.9849 - dense_3_acc_8: 0.9726 - dense_3_acc_9: 0.9527 - dense_3_acc_10: 0.9169 - dense_3_acc_11: 0.8728 - dense_3_acc_12: 0.8124 - dense_3_acc_13: 0.7638 - dense_3_acc_14: 0.7715 - dense_3_acc_15: 0.8242 - dense_3_acc_16: 0.8683 - dense_3_acc_17: 0.9412 - dense_3_acc_18: 0.9669\n",
      "Epoch 59/100\n",
      "10887/10887 [==============================] - 13s 1ms/step - loss: 4.8102 - dense_3_loss: 0.1669 - dense_3_acc: 0.9998 - dense_3_acc_1: 0.9997 - dense_3_acc_2: 0.9990 - dense_3_acc_3: 0.9986 - dense_3_acc_4: 0.9977 - dense_3_acc_5: 0.9953 - dense_3_acc_6: 0.9919 - dense_3_acc_7: 0.9858 - dense_3_acc_8: 0.9732 - dense_3_acc_9: 0.9557 - dense_3_acc_10: 0.9180 - dense_3_acc_11: 0.8743 - dense_3_acc_12: 0.8174 - dense_3_acc_13: 0.7705 - dense_3_acc_14: 0.7790 - dense_3_acc_15: 0.8268 - dense_3_acc_16: 0.8726 - dense_3_acc_17: 0.9439 - dense_3_acc_18: 0.9679\n",
      "Epoch 60/100\n",
      "10887/10887 [==============================] - 13s 1ms/step - loss: 4.7770 - dense_3_loss: 0.1652 - dense_3_acc: 0.9998 - dense_3_acc_1: 0.9997 - dense_3_acc_2: 0.9990 - dense_3_acc_3: 0.9988 - dense_3_acc_4: 0.9976 - dense_3_acc_5: 0.9950 - dense_3_acc_6: 0.9921 - dense_3_acc_7: 0.9858 - dense_3_acc_8: 0.9729 - dense_3_acc_9: 0.9554 - dense_3_acc_10: 0.9195 - dense_3_acc_11: 0.8743 - dense_3_acc_12: 0.8168 - dense_3_acc_13: 0.7671 - dense_3_acc_14: 0.7752 - dense_3_acc_15: 0.8311 - dense_3_acc_16: 0.8716 - dense_3_acc_17: 0.9455 - dense_3_acc_18: 0.9685\n",
      "Epoch 61/100\n",
      "10887/10887 [==============================] - 13s 1ms/step - loss: 4.7538 - dense_3_loss: 0.1655 - dense_3_acc: 0.9998 - dense_3_acc_1: 0.9997 - dense_3_acc_2: 0.9990 - dense_3_acc_3: 0.9984 - dense_3_acc_4: 0.9978 - dense_3_acc_5: 0.9953 - dense_3_acc_6: 0.9921 - dense_3_acc_7: 0.9862 - dense_3_acc_8: 0.9736 - dense_3_acc_9: 0.9558 - dense_3_acc_10: 0.9206 - dense_3_acc_11: 0.8754 - dense_3_acc_12: 0.8191 - dense_3_acc_13: 0.7714 - dense_3_acc_14: 0.7737 - dense_3_acc_15: 0.8321 - dense_3_acc_16: 0.8757 - dense_3_acc_17: 0.9459 - dense_3_acc_18: 0.9659\n",
      "Epoch 62/100\n",
      "10887/10887 [==============================] - 13s 1ms/step - loss: 4.7383 - dense_3_loss: 0.1661 - dense_3_acc: 0.9998 - dense_3_acc_1: 0.9997 - dense_3_acc_2: 0.9990 - dense_3_acc_3: 0.9986 - dense_3_acc_4: 0.9977 - dense_3_acc_5: 0.9949 - dense_3_acc_6: 0.9921 - dense_3_acc_7: 0.9857 - dense_3_acc_8: 0.9738 - dense_3_acc_9: 0.9556 - dense_3_acc_10: 0.9194 - dense_3_acc_11: 0.8742 - dense_3_acc_12: 0.8168 - dense_3_acc_13: 0.7706 - dense_3_acc_14: 0.7766 - dense_3_acc_15: 0.8310 - dense_3_acc_16: 0.8799 - dense_3_acc_17: 0.9454 - dense_3_acc_18: 0.9667\n",
      "Epoch 63/100\n",
      "10887/10887 [==============================] - 14s 1ms/step - loss: 4.6617 - dense_3_loss: 0.1582 - dense_3_acc: 0.9998 - dense_3_acc_1: 0.9997 - dense_3_acc_2: 0.9990 - dense_3_acc_3: 0.9986 - dense_3_acc_4: 0.9977 - dense_3_acc_5: 0.9954 - dense_3_acc_6: 0.9918 - dense_3_acc_7: 0.9861 - dense_3_acc_8: 0.9746 - dense_3_acc_9: 0.9560 - dense_3_acc_10: 0.9214 - dense_3_acc_11: 0.8762 - dense_3_acc_12: 0.8213 - dense_3_acc_13: 0.7760 - dense_3_acc_14: 0.7807 - dense_3_acc_15: 0.8347 - dense_3_acc_16: 0.8783 - dense_3_acc_17: 0.9471 - dense_3_acc_18: 0.9691\n",
      "Epoch 64/100\n",
      "10887/10887 [==============================] - 13s 1ms/step - loss: 4.6286 - dense_3_loss: 0.1601 - dense_3_acc: 0.9998 - dense_3_acc_1: 0.9997 - dense_3_acc_2: 0.9990 - dense_3_acc_3: 0.9987 - dense_3_acc_4: 0.9978 - dense_3_acc_5: 0.9953 - dense_3_acc_6: 0.9918 - dense_3_acc_7: 0.9866 - dense_3_acc_8: 0.9747 - dense_3_acc_9: 0.9577 - dense_3_acc_10: 0.9220 - dense_3_acc_11: 0.8769 - dense_3_acc_12: 0.8229 - dense_3_acc_13: 0.7776 - dense_3_acc_14: 0.7830 - dense_3_acc_15: 0.8385 - dense_3_acc_16: 0.8814 - dense_3_acc_17: 0.9458 - dense_3_acc_18: 0.9686\n",
      "Epoch 65/100\n",
      "10887/10887 [==============================] - 13s 1ms/step - loss: 4.5780 - dense_3_loss: 0.1557 - dense_3_acc: 0.9998 - dense_3_acc_1: 0.9997 - dense_3_acc_2: 0.9990 - dense_3_acc_3: 0.9987 - dense_3_acc_4: 0.9977 - dense_3_acc_5: 0.9956 - dense_3_acc_6: 0.9927 - dense_3_acc_7: 0.9865 - dense_3_acc_8: 0.9753 - dense_3_acc_9: 0.9562 - dense_3_acc_10: 0.9216 - dense_3_acc_11: 0.8772 - dense_3_acc_12: 0.8261 - dense_3_acc_13: 0.7791 - dense_3_acc_14: 0.7841 - dense_3_acc_15: 0.8371 - dense_3_acc_16: 0.8824 - dense_3_acc_17: 0.9490 - dense_3_acc_18: 0.9698\n",
      "Epoch 66/100\n",
      "10887/10887 [==============================] - 13s 1ms/step - loss: 4.5622 - dense_3_loss: 0.1549 - dense_3_acc: 0.9998 - dense_3_acc_1: 0.9997 - dense_3_acc_2: 0.9990 - dense_3_acc_3: 0.9986 - dense_3_acc_4: 0.9977 - dense_3_acc_5: 0.9953 - dense_3_acc_6: 0.9920 - dense_3_acc_7: 0.9865 - dense_3_acc_8: 0.9747 - dense_3_acc_9: 0.9563 - dense_3_acc_10: 0.9242 - dense_3_acc_11: 0.8791 - dense_3_acc_12: 0.8258 - dense_3_acc_13: 0.7810 - dense_3_acc_14: 0.7852 - dense_3_acc_15: 0.8380 - dense_3_acc_16: 0.8809 - dense_3_acc_17: 0.9484 - dense_3_acc_18: 0.9699\n",
      "Epoch 67/100\n",
      "10887/10887 [==============================] - 13s 1ms/step - loss: 4.5242 - dense_3_loss: 0.1537 - dense_3_acc: 0.9998 - dense_3_acc_1: 0.9997 - dense_3_acc_2: 0.9990 - dense_3_acc_3: 0.9987 - dense_3_acc_4: 0.9977 - dense_3_acc_5: 0.9954 - dense_3_acc_6: 0.9924 - dense_3_acc_7: 0.9866 - dense_3_acc_8: 0.9756 - dense_3_acc_9: 0.9564 - dense_3_acc_10: 0.9240 - dense_3_acc_11: 0.8782 - dense_3_acc_12: 0.8271 - dense_3_acc_13: 0.7812 - dense_3_acc_14: 0.7863 - dense_3_acc_15: 0.8408 - dense_3_acc_16: 0.8848 - dense_3_acc_17: 0.9506 - dense_3_acc_18: 0.9712\n",
      "Epoch 68/100\n",
      "10887/10887 [==============================] - 13s 1ms/step - loss: 4.4969 - dense_3_loss: 0.1530 - dense_3_acc: 0.9998 - dense_3_acc_1: 0.9997 - dense_3_acc_2: 0.9990 - dense_3_acc_3: 0.9986 - dense_3_acc_4: 0.9977 - dense_3_acc_5: 0.9952 - dense_3_acc_6: 0.9926 - dense_3_acc_7: 0.9869 - dense_3_acc_8: 0.9758 - dense_3_acc_9: 0.9579 - dense_3_acc_10: 0.9227 - dense_3_acc_11: 0.8791 - dense_3_acc_12: 0.8281 - dense_3_acc_13: 0.7854 - dense_3_acc_14: 0.7880 - dense_3_acc_15: 0.8390 - dense_3_acc_16: 0.8833 - dense_3_acc_17: 0.9492 - dense_3_acc_18: 0.9690\n",
      "Epoch 69/100\n",
      "10887/10887 [==============================] - 13s 1ms/step - loss: 4.4508 - dense_3_loss: 0.1507 - dense_3_acc: 0.9998 - dense_3_acc_1: 0.9997 - dense_3_acc_2: 0.9990 - dense_3_acc_3: 0.9986 - dense_3_acc_4: 0.9978 - dense_3_acc_5: 0.9955 - dense_3_acc_6: 0.9924 - dense_3_acc_7: 0.9866 - dense_3_acc_8: 0.9756 - dense_3_acc_9: 0.9578 - dense_3_acc_10: 0.9236 - dense_3_acc_11: 0.8804 - dense_3_acc_12: 0.8281 - dense_3_acc_13: 0.7867 - dense_3_acc_14: 0.7901 - dense_3_acc_15: 0.8444 - dense_3_acc_16: 0.8843 - dense_3_acc_17: 0.9509 - dense_3_acc_18: 0.9704\n",
      "Epoch 70/100\n",
      "10887/10887 [==============================] - 13s 1ms/step - loss: 4.4330 - dense_3_loss: 0.1505 - dense_3_acc: 0.9998 - dense_3_acc_1: 0.9997 - dense_3_acc_2: 0.9990 - dense_3_acc_3: 0.9987 - dense_3_acc_4: 0.9977 - dense_3_acc_5: 0.9957 - dense_3_acc_6: 0.9920 - dense_3_acc_7: 0.9868 - dense_3_acc_8: 0.9747 - dense_3_acc_9: 0.9588 - dense_3_acc_10: 0.9232 - dense_3_acc_11: 0.8811 - dense_3_acc_12: 0.8298 - dense_3_acc_13: 0.7890 - dense_3_acc_14: 0.7908 - dense_3_acc_15: 0.8468 - dense_3_acc_16: 0.8883 - dense_3_acc_17: 0.9527 - dense_3_acc_18: 0.9702\n",
      "Epoch 71/100\n",
      "10887/10887 [==============================] - 14s 1ms/step - loss: 4.3943 - dense_3_loss: 0.1472 - dense_3_acc: 0.9998 - dense_3_acc_1: 0.9997 - dense_3_acc_2: 0.9990 - dense_3_acc_3: 0.9987 - dense_3_acc_4: 0.9977 - dense_3_acc_5: 0.9957 - dense_3_acc_6: 0.9925 - dense_3_acc_7: 0.9863 - dense_3_acc_8: 0.9759 - dense_3_acc_9: 0.9592 - dense_3_acc_10: 0.9250 - dense_3_acc_11: 0.8814 - dense_3_acc_12: 0.8298 - dense_3_acc_13: 0.7908 - dense_3_acc_14: 0.7919 - dense_3_acc_15: 0.8468 - dense_3_acc_16: 0.8866 - dense_3_acc_17: 0.9514 - dense_3_acc_18: 0.9713\n",
      "Epoch 72/100\n",
      "10887/10887 [==============================] - 13s 1ms/step - loss: 4.3674 - dense_3_loss: 0.1476 - dense_3_acc: 0.9998 - dense_3_acc_1: 0.9997 - dense_3_acc_2: 0.9990 - dense_3_acc_3: 0.9987 - dense_3_acc_4: 0.9978 - dense_3_acc_5: 0.9954 - dense_3_acc_6: 0.9925 - dense_3_acc_7: 0.9868 - dense_3_acc_8: 0.9766 - dense_3_acc_9: 0.9588 - dense_3_acc_10: 0.9249 - dense_3_acc_11: 0.8820 - dense_3_acc_12: 0.8306 - dense_3_acc_13: 0.7904 - dense_3_acc_14: 0.7956 - dense_3_acc_15: 0.8447 - dense_3_acc_16: 0.8874 - dense_3_acc_17: 0.9507 - dense_3_acc_18: 0.9705\n",
      "Epoch 73/100\n",
      "10887/10887 [==============================] - 13s 1ms/step - loss: 4.3350 - dense_3_loss: 0.1444 - dense_3_acc: 0.9998 - dense_3_acc_1: 0.9997 - dense_3_acc_2: 0.9990 - dense_3_acc_3: 0.9987 - dense_3_acc_4: 0.9977 - dense_3_acc_5: 0.9958 - dense_3_acc_6: 0.9924 - dense_3_acc_7: 0.9871 - dense_3_acc_8: 0.9766 - dense_3_acc_9: 0.9588 - dense_3_acc_10: 0.9272 - dense_3_acc_11: 0.8830 - dense_3_acc_12: 0.8319 - dense_3_acc_13: 0.7905 - dense_3_acc_14: 0.7964 - dense_3_acc_15: 0.8466 - dense_3_acc_16: 0.8892 - dense_3_acc_17: 0.9540 - dense_3_acc_18: 0.9716\n",
      "Epoch 74/100\n",
      "10887/10887 [==============================] - 13s 1ms/step - loss: 4.3230 - dense_3_loss: 0.1421 - dense_3_acc: 0.9998 - dense_3_acc_1: 0.9997 - dense_3_acc_2: 0.9990 - dense_3_acc_3: 0.9988 - dense_3_acc_4: 0.9980 - dense_3_acc_5: 0.9958 - dense_3_acc_6: 0.9927 - dense_3_acc_7: 0.9870 - dense_3_acc_8: 0.9757 - dense_3_acc_9: 0.9585 - dense_3_acc_10: 0.9266 - dense_3_acc_11: 0.8837 - dense_3_acc_12: 0.8346 - dense_3_acc_13: 0.7928 - dense_3_acc_14: 0.7957 - dense_3_acc_15: 0.8482 - dense_3_acc_16: 0.8896 - dense_3_acc_17: 0.9512 - dense_3_acc_18: 0.9735\n",
      "Epoch 75/100\n",
      "10887/10887 [==============================] - 13s 1ms/step - loss: 4.2945 - dense_3_loss: 0.1426 - dense_3_acc: 0.9998 - dense_3_acc_1: 0.9997 - dense_3_acc_2: 0.9990 - dense_3_acc_3: 0.9987 - dense_3_acc_4: 0.9979 - dense_3_acc_5: 0.9957 - dense_3_acc_6: 0.9932 - dense_3_acc_7: 0.9870 - dense_3_acc_8: 0.9766 - dense_3_acc_9: 0.9594 - dense_3_acc_10: 0.9259 - dense_3_acc_11: 0.8809 - dense_3_acc_12: 0.8346 - dense_3_acc_13: 0.7939 - dense_3_acc_14: 0.7982 - dense_3_acc_15: 0.8484 - dense_3_acc_16: 0.8924 - dense_3_acc_17: 0.9540 - dense_3_acc_18: 0.9717\n",
      "Epoch 76/100\n",
      "10887/10887 [==============================] - 13s 1ms/step - loss: 4.2653 - dense_3_loss: 0.1423 - dense_3_acc: 0.9998 - dense_3_acc_1: 0.9997 - dense_3_acc_2: 0.9990 - dense_3_acc_3: 0.9987 - dense_3_acc_4: 0.9978 - dense_3_acc_5: 0.9959 - dense_3_acc_6: 0.9930 - dense_3_acc_7: 0.9867 - dense_3_acc_8: 0.9763 - dense_3_acc_9: 0.9601 - dense_3_acc_10: 0.9265 - dense_3_acc_11: 0.8828 - dense_3_acc_12: 0.8338 - dense_3_acc_13: 0.7947 - dense_3_acc_14: 0.8014 - dense_3_acc_15: 0.8495 - dense_3_acc_16: 0.8912 - dense_3_acc_17: 0.9537 - dense_3_acc_18: 0.9717\n",
      "Epoch 77/100\n",
      "10887/10887 [==============================] - 13s 1ms/step - loss: 4.2164 - dense_3_loss: 0.1392 - dense_3_acc: 0.9998 - dense_3_acc_1: 0.9997 - dense_3_acc_2: 0.9990 - dense_3_acc_3: 0.9987 - dense_3_acc_4: 0.9979 - dense_3_acc_5: 0.9955 - dense_3_acc_6: 0.9933 - dense_3_acc_7: 0.9868 - dense_3_acc_8: 0.9768 - dense_3_acc_9: 0.9607 - dense_3_acc_10: 0.9276 - dense_3_acc_11: 0.8854 - dense_3_acc_12: 0.8355 - dense_3_acc_13: 0.7998 - dense_3_acc_14: 0.8032 - dense_3_acc_15: 0.8529 - dense_3_acc_16: 0.8941 - dense_3_acc_17: 0.9544 - dense_3_acc_18: 0.9728\n",
      "Epoch 78/100\n",
      "10887/10887 [==============================] - 13s 1ms/step - loss: 4.2003 - dense_3_loss: 0.1360 - dense_3_acc: 0.9998 - dense_3_acc_1: 0.9997 - dense_3_acc_2: 0.9990 - dense_3_acc_3: 0.9987 - dense_3_acc_4: 0.9978 - dense_3_acc_5: 0.9957 - dense_3_acc_6: 0.9928 - dense_3_acc_7: 0.9871 - dense_3_acc_8: 0.9763 - dense_3_acc_9: 0.9613 - dense_3_acc_10: 0.9271 - dense_3_acc_11: 0.8846 - dense_3_acc_12: 0.8372 - dense_3_acc_13: 0.7965 - dense_3_acc_14: 0.8025 - dense_3_acc_15: 0.8512 - dense_3_acc_16: 0.8935 - dense_3_acc_17: 0.9562 - dense_3_acc_18: 0.9737\n",
      "Epoch 79/100\n",
      "10887/10887 [==============================] - 13s 1ms/step - loss: 4.1602 - dense_3_loss: 0.1359 - dense_3_acc: 0.9998 - dense_3_acc_1: 0.9997 - dense_3_acc_2: 0.9990 - dense_3_acc_3: 0.9987 - dense_3_acc_4: 0.9978 - dense_3_acc_5: 0.9959 - dense_3_acc_6: 0.9934 - dense_3_acc_7: 0.9871 - dense_3_acc_8: 0.9769 - dense_3_acc_9: 0.9607 - dense_3_acc_10: 0.9281 - dense_3_acc_11: 0.8856 - dense_3_acc_12: 0.8396 - dense_3_acc_13: 0.8014 - dense_3_acc_14: 0.8052 - dense_3_acc_15: 0.8549 - dense_3_acc_16: 0.8937 - dense_3_acc_17: 0.9555 - dense_3_acc_18: 0.9739\n",
      "Epoch 80/100\n",
      "10887/10887 [==============================] - 13s 1ms/step - loss: 4.1571 - dense_3_loss: 0.1353 - dense_3_acc: 0.9998 - dense_3_acc_1: 0.9997 - dense_3_acc_2: 0.9990 - dense_3_acc_3: 0.9988 - dense_3_acc_4: 0.9979 - dense_3_acc_5: 0.9959 - dense_3_acc_6: 0.9930 - dense_3_acc_7: 0.9876 - dense_3_acc_8: 0.9777 - dense_3_acc_9: 0.9596 - dense_3_acc_10: 0.9271 - dense_3_acc_11: 0.8878 - dense_3_acc_12: 0.8373 - dense_3_acc_13: 0.7999 - dense_3_acc_14: 0.8034 - dense_3_acc_15: 0.8563 - dense_3_acc_16: 0.8951 - dense_3_acc_17: 0.9550 - dense_3_acc_18: 0.9746\n",
      "Epoch 81/100\n",
      "10887/10887 [==============================] - 13s 1ms/step - loss: 4.1356 - dense_3_loss: 0.1332 - dense_3_acc: 0.9998 - dense_3_acc_1: 0.9997 - dense_3_acc_2: 0.9990 - dense_3_acc_3: 0.9988 - dense_3_acc_4: 0.9978 - dense_3_acc_5: 0.9957 - dense_3_acc_6: 0.9928 - dense_3_acc_7: 0.9871 - dense_3_acc_8: 0.9768 - dense_3_acc_9: 0.9610 - dense_3_acc_10: 0.9295 - dense_3_acc_11: 0.8871 - dense_3_acc_12: 0.8392 - dense_3_acc_13: 0.8016 - dense_3_acc_14: 0.8054 - dense_3_acc_15: 0.8559 - dense_3_acc_16: 0.8968 - dense_3_acc_17: 0.9566 - dense_3_acc_18: 0.9738\n",
      "Epoch 82/100\n",
      "10887/10887 [==============================] - 13s 1ms/step - loss: 4.1478 - dense_3_loss: 0.1401 - dense_3_acc: 0.9998 - dense_3_acc_1: 0.9997 - dense_3_acc_2: 0.9990 - dense_3_acc_3: 0.9987 - dense_3_acc_4: 0.9980 - dense_3_acc_5: 0.9957 - dense_3_acc_6: 0.9933 - dense_3_acc_7: 0.9870 - dense_3_acc_8: 0.9757 - dense_3_acc_9: 0.9597 - dense_3_acc_10: 0.9276 - dense_3_acc_11: 0.8855 - dense_3_acc_12: 0.8397 - dense_3_acc_13: 0.8012 - dense_3_acc_14: 0.8053 - dense_3_acc_15: 0.8531 - dense_3_acc_16: 0.8933 - dense_3_acc_17: 0.9550 - dense_3_acc_18: 0.9705\n",
      "Epoch 83/100\n",
      "10887/10887 [==============================] - 13s 1ms/step - loss: 4.0834 - dense_3_loss: 0.1302 - dense_3_acc: 0.9998 - dense_3_acc_1: 0.9997 - dense_3_acc_2: 0.9990 - dense_3_acc_3: 0.9986 - dense_3_acc_4: 0.9982 - dense_3_acc_5: 0.9962 - dense_3_acc_6: 0.9930 - dense_3_acc_7: 0.9873 - dense_3_acc_8: 0.9769 - dense_3_acc_9: 0.9614 - dense_3_acc_10: 0.9284 - dense_3_acc_11: 0.8882 - dense_3_acc_12: 0.8419 - dense_3_acc_13: 0.8033 - dense_3_acc_14: 0.8095 - dense_3_acc_15: 0.8604 - dense_3_acc_16: 0.8982 - dense_3_acc_17: 0.9574 - dense_3_acc_18: 0.9753\n",
      "Epoch 84/100\n",
      "10887/10887 [==============================] - 13s 1ms/step - loss: 4.0461 - dense_3_loss: 0.1310 - dense_3_acc: 0.9998 - dense_3_acc_1: 0.9997 - dense_3_acc_2: 0.9990 - dense_3_acc_3: 0.9987 - dense_3_acc_4: 0.9980 - dense_3_acc_5: 0.9961 - dense_3_acc_6: 0.9930 - dense_3_acc_7: 0.9877 - dense_3_acc_8: 0.9776 - dense_3_acc_9: 0.9621 - dense_3_acc_10: 0.9302 - dense_3_acc_11: 0.8885 - dense_3_acc_12: 0.8434 - dense_3_acc_13: 0.8051 - dense_3_acc_14: 0.8120 - dense_3_acc_15: 0.8593 - dense_3_acc_16: 0.8990 - dense_3_acc_17: 0.9565 - dense_3_acc_18: 0.9746\n",
      "Epoch 85/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10887/10887 [==============================] - 13s 1ms/step - loss: 4.0184 - dense_3_loss: 0.1302 - dense_3_acc: 0.9998 - dense_3_acc_1: 0.9997 - dense_3_acc_2: 0.9990 - dense_3_acc_3: 0.9988 - dense_3_acc_4: 0.9980 - dense_3_acc_5: 0.9959 - dense_3_acc_6: 0.9933 - dense_3_acc_7: 0.9876 - dense_3_acc_8: 0.9766 - dense_3_acc_9: 0.9610 - dense_3_acc_10: 0.9300 - dense_3_acc_11: 0.8891 - dense_3_acc_12: 0.8428 - dense_3_acc_13: 0.8058 - dense_3_acc_14: 0.8136 - dense_3_acc_15: 0.8619 - dense_3_acc_16: 0.8991 - dense_3_acc_17: 0.9588 - dense_3_acc_18: 0.9745\n",
      "Epoch 86/100\n",
      "10887/10887 [==============================] - 13s 1ms/step - loss: 4.0032 - dense_3_loss: 0.1304 - dense_3_acc: 0.9998 - dense_3_acc_1: 0.9997 - dense_3_acc_2: 0.9990 - dense_3_acc_3: 0.9986 - dense_3_acc_4: 0.9982 - dense_3_acc_5: 0.9958 - dense_3_acc_6: 0.9934 - dense_3_acc_7: 0.9877 - dense_3_acc_8: 0.9781 - dense_3_acc_9: 0.9612 - dense_3_acc_10: 0.9294 - dense_3_acc_11: 0.8888 - dense_3_acc_12: 0.8449 - dense_3_acc_13: 0.8080 - dense_3_acc_14: 0.8145 - dense_3_acc_15: 0.8607 - dense_3_acc_16: 0.8995 - dense_3_acc_17: 0.9598 - dense_3_acc_18: 0.9754\n",
      "Epoch 87/100\n",
      "10887/10887 [==============================] - 13s 1ms/step - loss: 3.9904 - dense_3_loss: 0.1270 - dense_3_acc: 0.9998 - dense_3_acc_1: 0.9997 - dense_3_acc_2: 0.9990 - dense_3_acc_3: 0.9987 - dense_3_acc_4: 0.9979 - dense_3_acc_5: 0.9960 - dense_3_acc_6: 0.9934 - dense_3_acc_7: 0.9875 - dense_3_acc_8: 0.9780 - dense_3_acc_9: 0.9611 - dense_3_acc_10: 0.9301 - dense_3_acc_11: 0.8891 - dense_3_acc_12: 0.8456 - dense_3_acc_13: 0.8098 - dense_3_acc_14: 0.8138 - dense_3_acc_15: 0.8611 - dense_3_acc_16: 0.9012 - dense_3_acc_17: 0.9570 - dense_3_acc_18: 0.9759\n",
      "Epoch 88/100\n",
      "10887/10887 [==============================] - 13s 1ms/step - loss: 3.9529 - dense_3_loss: 0.1260 - dense_3_acc: 0.9998 - dense_3_acc_1: 0.9997 - dense_3_acc_2: 0.9990 - dense_3_acc_3: 0.9986 - dense_3_acc_4: 0.9981 - dense_3_acc_5: 0.9958 - dense_3_acc_6: 0.9931 - dense_3_acc_7: 0.9880 - dense_3_acc_8: 0.9767 - dense_3_acc_9: 0.9610 - dense_3_acc_10: 0.9307 - dense_3_acc_11: 0.8883 - dense_3_acc_12: 0.8457 - dense_3_acc_13: 0.8112 - dense_3_acc_14: 0.8154 - dense_3_acc_15: 0.8644 - dense_3_acc_16: 0.9023 - dense_3_acc_17: 0.9586 - dense_3_acc_18: 0.9758\n",
      "Epoch 89/100\n",
      "10887/10887 [==============================] - 13s 1ms/step - loss: 3.9329 - dense_3_loss: 0.1262 - dense_3_acc: 0.9998 - dense_3_acc_1: 0.9997 - dense_3_acc_2: 0.9990 - dense_3_acc_3: 0.9987 - dense_3_acc_4: 0.9979 - dense_3_acc_5: 0.9961 - dense_3_acc_6: 0.9937 - dense_3_acc_7: 0.9880 - dense_3_acc_8: 0.9779 - dense_3_acc_9: 0.9617 - dense_3_acc_10: 0.9304 - dense_3_acc_11: 0.8909 - dense_3_acc_12: 0.8470 - dense_3_acc_13: 0.8123 - dense_3_acc_14: 0.8148 - dense_3_acc_15: 0.8627 - dense_3_acc_16: 0.9036 - dense_3_acc_17: 0.9578 - dense_3_acc_18: 0.9759\n",
      "Epoch 90/100\n",
      "10887/10887 [==============================] - 13s 1ms/step - loss: 3.9221 - dense_3_loss: 0.1277 - dense_3_acc: 0.9998 - dense_3_acc_1: 0.9997 - dense_3_acc_2: 0.9990 - dense_3_acc_3: 0.9987 - dense_3_acc_4: 0.9981 - dense_3_acc_5: 0.9961 - dense_3_acc_6: 0.9934 - dense_3_acc_7: 0.9878 - dense_3_acc_8: 0.9778 - dense_3_acc_9: 0.9629 - dense_3_acc_10: 0.9307 - dense_3_acc_11: 0.8923 - dense_3_acc_12: 0.8473 - dense_3_acc_13: 0.8134 - dense_3_acc_14: 0.8179 - dense_3_acc_15: 0.8651 - dense_3_acc_16: 0.9027 - dense_3_acc_17: 0.9577 - dense_3_acc_18: 0.9747\n",
      "Epoch 91/100\n",
      "10887/10887 [==============================] - 13s 1ms/step - loss: 3.8933 - dense_3_loss: 0.1235 - dense_3_acc: 0.9998 - dense_3_acc_1: 0.9997 - dense_3_acc_2: 0.9990 - dense_3_acc_3: 0.9986 - dense_3_acc_4: 0.9979 - dense_3_acc_5: 0.9958 - dense_3_acc_6: 0.9936 - dense_3_acc_7: 0.9881 - dense_3_acc_8: 0.9771 - dense_3_acc_9: 0.9622 - dense_3_acc_10: 0.9318 - dense_3_acc_11: 0.8913 - dense_3_acc_12: 0.8488 - dense_3_acc_13: 0.8134 - dense_3_acc_14: 0.8178 - dense_3_acc_15: 0.8641 - dense_3_acc_16: 0.9049 - dense_3_acc_17: 0.9601 - dense_3_acc_18: 0.9762\n",
      "Epoch 92/100\n",
      "10887/10887 [==============================] - 13s 1ms/step - loss: 3.8750 - dense_3_loss: 0.1238 - dense_3_acc: 0.9998 - dense_3_acc_1: 0.9997 - dense_3_acc_2: 0.9990 - dense_3_acc_3: 0.9987 - dense_3_acc_4: 0.9980 - dense_3_acc_5: 0.9960 - dense_3_acc_6: 0.9929 - dense_3_acc_7: 0.9882 - dense_3_acc_8: 0.9784 - dense_3_acc_9: 0.9623 - dense_3_acc_10: 0.9337 - dense_3_acc_11: 0.8916 - dense_3_acc_12: 0.8470 - dense_3_acc_13: 0.8157 - dense_3_acc_14: 0.8182 - dense_3_acc_15: 0.8639 - dense_3_acc_16: 0.9046 - dense_3_acc_17: 0.9592 - dense_3_acc_18: 0.9769\n",
      "Epoch 93/100\n",
      "10887/10887 [==============================] - 13s 1ms/step - loss: 3.8497 - dense_3_loss: 0.1239 - dense_3_acc: 0.9998 - dense_3_acc_1: 0.9997 - dense_3_acc_2: 0.9990 - dense_3_acc_3: 0.9987 - dense_3_acc_4: 0.9982 - dense_3_acc_5: 0.9964 - dense_3_acc_6: 0.9936 - dense_3_acc_7: 0.9881 - dense_3_acc_8: 0.9780 - dense_3_acc_9: 0.9625 - dense_3_acc_10: 0.9331 - dense_3_acc_11: 0.8922 - dense_3_acc_12: 0.8490 - dense_3_acc_13: 0.8165 - dense_3_acc_14: 0.8216 - dense_3_acc_15: 0.8686 - dense_3_acc_16: 0.9067 - dense_3_acc_17: 0.9598 - dense_3_acc_18: 0.9758\n",
      "Epoch 94/100\n",
      "10887/10887 [==============================] - 13s 1ms/step - loss: 3.8227 - dense_3_loss: 0.1204 - dense_3_acc: 0.9998 - dense_3_acc_1: 0.9997 - dense_3_acc_2: 0.9990 - dense_3_acc_3: 0.9987 - dense_3_acc_4: 0.9983 - dense_3_acc_5: 0.9961 - dense_3_acc_6: 0.9936 - dense_3_acc_7: 0.9888 - dense_3_acc_8: 0.9781 - dense_3_acc_9: 0.9645 - dense_3_acc_10: 0.9350 - dense_3_acc_11: 0.8931 - dense_3_acc_12: 0.8495 - dense_3_acc_13: 0.8159 - dense_3_acc_14: 0.8236 - dense_3_acc_15: 0.8669 - dense_3_acc_16: 0.9067 - dense_3_acc_17: 0.9613 - dense_3_acc_18: 0.9764\n",
      "Epoch 95/100\n",
      "10887/10887 [==============================] - 14s 1ms/step - loss: 3.8205 - dense_3_loss: 0.1204 - dense_3_acc: 0.9998 - dense_3_acc_1: 0.9997 - dense_3_acc_2: 0.9990 - dense_3_acc_3: 0.9988 - dense_3_acc_4: 0.9981 - dense_3_acc_5: 0.9964 - dense_3_acc_6: 0.9934 - dense_3_acc_7: 0.9880 - dense_3_acc_8: 0.9784 - dense_3_acc_9: 0.9630 - dense_3_acc_10: 0.9340 - dense_3_acc_11: 0.8931 - dense_3_acc_12: 0.8494 - dense_3_acc_13: 0.8195 - dense_3_acc_14: 0.8220 - dense_3_acc_15: 0.8687 - dense_3_acc_16: 0.9070 - dense_3_acc_17: 0.9599 - dense_3_acc_18: 0.9767\n",
      "Epoch 96/100\n",
      "10887/10887 [==============================] - 14s 1ms/step - loss: 3.7852 - dense_3_loss: 0.1194 - dense_3_acc: 0.9998 - dense_3_acc_1: 0.9997 - dense_3_acc_2: 0.9990 - dense_3_acc_3: 0.9987 - dense_3_acc_4: 0.9981 - dense_3_acc_5: 0.9962 - dense_3_acc_6: 0.9938 - dense_3_acc_7: 0.9881 - dense_3_acc_8: 0.9780 - dense_3_acc_9: 0.9634 - dense_3_acc_10: 0.9351 - dense_3_acc_11: 0.8933 - dense_3_acc_12: 0.8505 - dense_3_acc_13: 0.8194 - dense_3_acc_14: 0.8247 - dense_3_acc_15: 0.8703 - dense_3_acc_16: 0.9094 - dense_3_acc_17: 0.9609 - dense_3_acc_18: 0.9771\n",
      "Epoch 97/100\n",
      "10887/10887 [==============================] - 14s 1ms/step - loss: 3.7942 - dense_3_loss: 0.1202 - dense_3_acc: 0.9998 - dense_3_acc_1: 0.9997 - dense_3_acc_2: 0.9990 - dense_3_acc_3: 0.9987 - dense_3_acc_4: 0.9983 - dense_3_acc_5: 0.9963 - dense_3_acc_6: 0.9934 - dense_3_acc_7: 0.9885 - dense_3_acc_8: 0.9775 - dense_3_acc_9: 0.9636 - dense_3_acc_10: 0.9341 - dense_3_acc_11: 0.8928 - dense_3_acc_12: 0.8533 - dense_3_acc_13: 0.8190 - dense_3_acc_14: 0.8217 - dense_3_acc_15: 0.8676 - dense_3_acc_16: 0.9087 - dense_3_acc_17: 0.9613 - dense_3_acc_18: 0.9766\n",
      "Epoch 98/100\n",
      "10887/10887 [==============================] - 13s 1ms/step - loss: 3.7623 - dense_3_loss: 0.1189 - dense_3_acc: 0.9998 - dense_3_acc_1: 0.9997 - dense_3_acc_2: 0.9990 - dense_3_acc_3: 0.9987 - dense_3_acc_4: 0.9983 - dense_3_acc_5: 0.9961 - dense_3_acc_6: 0.9937 - dense_3_acc_7: 0.9882 - dense_3_acc_8: 0.9786 - dense_3_acc_9: 0.9642 - dense_3_acc_10: 0.9356 - dense_3_acc_11: 0.8946 - dense_3_acc_12: 0.8524 - dense_3_acc_13: 0.8212 - dense_3_acc_14: 0.8267 - dense_3_acc_15: 0.8712 - dense_3_acc_16: 0.9096 - dense_3_acc_17: 0.9609 - dense_3_acc_18: 0.9774\n",
      "Epoch 99/100\n",
      "10887/10887 [==============================] - 13s 1ms/step - loss: 3.7270 - dense_3_loss: 0.1190 - dense_3_acc: 0.9998 - dense_3_acc_1: 0.9997 - dense_3_acc_2: 0.9990 - dense_3_acc_3: 0.9988 - dense_3_acc_4: 0.9982 - dense_3_acc_5: 0.9961 - dense_3_acc_6: 0.9937 - dense_3_acc_7: 0.9885 - dense_3_acc_8: 0.9780 - dense_3_acc_9: 0.9649 - dense_3_acc_10: 0.9374 - dense_3_acc_11: 0.8953 - dense_3_acc_12: 0.8543 - dense_3_acc_13: 0.8228 - dense_3_acc_14: 0.8265 - dense_3_acc_15: 0.8711 - dense_3_acc_16: 0.9107 - dense_3_acc_17: 0.9615 - dense_3_acc_18: 0.9766\n",
      "Epoch 100/100\n",
      "10887/10887 [==============================] - 13s 1ms/step - loss: 3.7228 - dense_3_loss: 0.1186 - dense_3_acc: 0.9998 - dense_3_acc_1: 0.9997 - dense_3_acc_2: 0.9990 - dense_3_acc_3: 0.9987 - dense_3_acc_4: 0.9983 - dense_3_acc_5: 0.9962 - dense_3_acc_6: 0.9935 - dense_3_acc_7: 0.9889 - dense_3_acc_8: 0.9789 - dense_3_acc_9: 0.9643 - dense_3_acc_10: 0.9364 - dense_3_acc_11: 0.8974 - dense_3_acc_12: 0.8524 - dense_3_acc_13: 0.8237 - dense_3_acc_14: 0.8267 - dense_3_acc_15: 0.8739 - dense_3_acc_16: 0.9107 - dense_3_acc_17: 0.9619 - dense_3_acc_18: 0.9769\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f98802db390>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit([X, s0, c0], outputs, epochs=100, batch_size=120)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Thai-Script to Roman-Script Translation\n",
    "* Task 4: Test your model on 5 examples of your choice including your name! (1 point)\n",
    "* Task 5: Show your visualization of attention scores on one of your example (1 point)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10, 20, 66)\n"
     ]
    }
   ],
   "source": [
    "#task 4\n",
    "#fill your code here\n",
    "test = [\"ภาคิน\",\"ดีศรี\",\"พิสิษฐ์\",\"วจนสาระ\",\"ปวินท์\",\"เปี่ยมไทย\",\"นิธิวุฒิ\",\"วิไลนุช\",\"ชวิศ\",\"สกุลยืนยง\"]\n",
    "def prep_input(input_list):\n",
    "    X = []\n",
    "    for line in input_list:\n",
    "        temp=[]\n",
    "        for char in line:\n",
    "            temp.append(input_dict[char])\n",
    "        X.append(temp)\n",
    "    X = pad_sequences(X,maxlen=max_len)\n",
    "    X= to_categorical(X,vocab_size)\n",
    "    X=X.reshape(len(input_list),max_len ,vocab_size)\n",
    "    \n",
    "    return X\n",
    "EXAMPLES = prep_input(test)\n",
    "print(EXAMPLES.shape)\n",
    "prediction = model.predict([EXAMPLES, s0, c0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 ภาคิน => phakhin\n",
      "1 ดีศรี => iisi\n",
      "2 พิสิษฐ์ => phisit\n",
      "3 วจนสาระ => wantttana\n",
      "4 ปวินท์ => pawin\n",
      "5 เปี่ยมไทย => piyathai\n",
      "6 นิธิวุฒิ => wittwuttthi\n",
      "7 วิไลนุช => wirannut\n",
      "8 ชวิศ => chawit\n",
      "9 สกุลยืนยง => suaanggnnnyang\n"
     ]
    }
   ],
   "source": [
    "prediction = np.swapaxes(prediction,0,1)\n",
    "y_pred = prediction\n",
    "prediction = np.argmax(prediction, axis = -1)\n",
    "for j in range(len(prediction)):\n",
    "    output = \"\".join([rev_output[int(i)] if int(i) else '' for i in prediction[j]])\n",
    "    print(j,test[j],'=>',output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot the attention map\n",
    "* If you need to install thai font: sudo apt install xfonts-thai\n",
    "* this is what your visualization might look like:\n",
    "<img src=\"https://raw.githubusercontent.com/ekapolc/nlp_2019/master/HW8/images/attn_viz_sample.png\"  style=\"width: 350px;\"/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "metadata": {},
   "outputs": [],
   "source": [
    "#task 5\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "plt.rcParams['font.family']='Loma' #you can change to other font that works for you\n",
    "#fill your code here\n",
    "sns.set()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_output_layer(model, layer_name):\n",
    "    # get the symbolic outputs of each \"key\" layer (we gave them unique names).\n",
    "    layer_dict = dict([(layer.name, layer) for layer in model.layers])\n",
    "    layer = layer_dict[layer_name]\n",
    "    return layer\n",
    "\n",
    "att_layer = get_output_layer(model, \"attention_scores\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(19, 1, 1, 20, 1)"
      ]
     },
     "execution_count": 289,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras import backend as K\n",
    "percent = []\n",
    "for i in range(output_max_len):\n",
    "    output_fn = K.function([model.layers[0].input], [att_layer.get_output_at(i)])\n",
    "    percent.append(output_fn([EXAMPLES[:1], s0, c0]))\n",
    "percent = np.array(percent)\n",
    "percent.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Try to get attention scores from attention_scores layer but it is all the same outputs with max input lenght."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[[[0.07491666],\n",
       "          [0.07316309],\n",
       "          [0.06811915],\n",
       "          [0.05944665],\n",
       "          [0.05329936]]]],\n",
       "\n",
       "\n",
       "\n",
       "       [[[[0.07491666],\n",
       "          [0.07316309],\n",
       "          [0.06811915],\n",
       "          [0.05944665],\n",
       "          [0.05329936]]]]], dtype=float32)"
      ]
     },
     "execution_count": 294,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "percent[:2,:,:1,:5] # Same outputs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 1, 20, 19)"
      ]
     },
     "execution_count": 295,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tmp = percent[0]\n",
    "for i in percent[1:]:\n",
    "    tmp = np.concatenate((tmp,i),axis = -1)\n",
    "tmp = np.array(tmp)\n",
    "tmp.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 347,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20 19\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "inp = [\"<PAD>\"]*15+list(\"ภาคิน\")\n",
    "out = [\"<PAD>\"]*12+list(\"Phakhin\")\n",
    "print(len(inp),len(out))\n",
    "df = pd.DataFrame(tmp[0][0],index= inp, columns=out)\n",
    "plt.rcParams['font.family']='Loma'\n",
    "ax = sns.heatmap(df[-7:])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
